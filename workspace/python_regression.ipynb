{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3d3815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4d0c9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]] [[ 3]\n",
      " [ 5]\n",
      " [ 7]\n",
      " [ 9]\n",
      " [11]]\n",
      "(5, 1) (5, 1)\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array([1, 2, 3, 4, 5]).reshape(5, 1)\n",
    "t_data = np.array([3, 5, 7, 9, 11]).reshape(5, 1)\n",
    "\n",
    "print(x_data, t_data)\n",
    "print(x_data.shape, t_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6529603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.64592896]] [0.55786245]\n"
     ]
    }
   ],
   "source": [
    "w = np.random.rand(1, 1)    # x와 t가 2차원 자료이기 때문에 얘도 2차원 자료여야 함\n",
    "b = np.random.rand(1)\n",
    "\n",
    "print(w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d9b5ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(x, t):\n",
    "    y = np.dot(x, w) + b\n",
    "    return np.sum((y - t) ** 2) / (len(x))    # np.mean((y - t) ** 2)와 같은 식임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55de2eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f, x): \n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=[['readwrite']])\n",
    "    while not it.finished: \n",
    "        idx = it.multi_index \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x \n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        x[idx] = float(tmp_val) - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1-fx2) / (2*delta_x)\n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71195a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    return np.dot(x, w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca182ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Loss: 23.956191725520732 Weight: [[0.64592896]] Bias: [0.55786245]\n",
      "Step: 0 Loss: 14.09511226586505 Weight: [[0.97035284]] Bias: [0.62848403]\n",
      "Step: 10 Loss: 0.07317287853437648 Weight: [[1.96230532]] Bias: [0.84788392]\n",
      "Step: 20 Loss: 0.0034679799033868032 Weight: [[2.03105132]] Bias: [0.86760816]\n",
      "Step: 30 Loss: 0.0029275981109745906 Weight: [[2.03475762]] Bias: [0.87311268]\n",
      "Step: 40 Loss: 0.002732262638145715 Weight: [[2.03391761]] Bias: [0.8774757]\n",
      "Step: 50 Loss: 0.002550663493035764 Weight: [[2.03279435]] Bias: [0.88162383]\n",
      "Step: 60 Loss: 0.002381088033359186 Weight: [[2.03168711]] Bias: [0.88562696]\n",
      "Step: 70 Loss: 0.0022227828206611558 Weight: [[2.03061576]] Bias: [0.88949439]\n",
      "Step: 80 Loss: 0.0020750021865130136 Weight: [[2.02958053]] Bias: [0.89323102]\n",
      "Step: 90 Loss: 0.001937046658955981 Weight: [[2.0285803]] Bias: [0.89684131]\n",
      "Step: 100 Loss: 0.001808263037487216 Weight: [[2.02761389]] Bias: [0.90032951]\n",
      "Step: 110 Loss: 0.0016880415334715143 Weight: [[2.02668015]] Bias: [0.90369976]\n",
      "Step: 120 Loss: 0.0015758128987000731 Weight: [[2.02577799]] Bias: [0.90695605]\n",
      "Step: 130 Loss: 0.0014710457310857818 Weight: [[2.02490633]] Bias: [0.91010224]\n",
      "Step: 140 Loss: 0.0013732439585504284 Weight: [[2.02406415]] Bias: [0.91314204]\n",
      "Step: 150 Loss: 0.0012819444901304381 Weight: [[2.02325045]] Bias: [0.91607905]\n",
      "Step: 160 Loss: 0.0011967150232437347 Weight: [[2.02246426]] Bias: [0.91891675]\n",
      "Step: 170 Loss: 0.0011171519967385218 Weight: [[2.02170465]] Bias: [0.92165849]\n",
      "Step: 180 Loss: 0.0010428786800337308 Weight: [[2.02097073]] Bias: [0.92430753]\n",
      "Step: 190 Loss: 0.0009735433893006245 Weight: [[2.02026163]] Bias: [0.92686699]\n",
      "Step: 200 Loss: 0.000908817822242086 Weight: [[2.0195765]] Bias: [0.92933991]\n",
      "Step: 210 Loss: 0.0008483955035821661 Weight: [[2.01891455]] Bias: [0.9317292]\n",
      "Step: 220 Loss: 0.0007919903339073695 Weight: [[2.01827497]] Bias: [0.93403771]\n",
      "Step: 230 Loss: 0.0007393352349868504 Weight: [[2.01765702]] Bias: [0.93626815]\n",
      "Step: 240 Loss: 0.0006901808851583485 Weight: [[2.01705997]] Bias: [0.93842318]\n",
      "Step: 250 Loss: 0.0006442945387912165 Weight: [[2.0164831]] Bias: [0.94050534]\n",
      "Step: 260 Loss: 0.0006014589242369281 Weight: [[2.01592574]] Bias: [0.94251708]\n",
      "Step: 270 Loss: 0.0005614712150486213 Weight: [[2.01538723]] Bias: [0.94446081]\n",
      "Step: 280 Loss: 0.0005241420695986439 Weight: [[2.01486693]] Bias: [0.94633881]\n",
      "Step: 290 Loss: 0.0004892947345472681 Weight: [[2.01436422]] Bias: [0.94815331]\n",
      "Step: 300 Loss: 0.00045676420791599585 Weight: [[2.01387851]] Bias: [0.94990645]\n",
      "Step: 310 Loss: 0.00042639645780401654 Weight: [[2.01340922]] Bias: [0.95160031]\n",
      "Step: 320 Loss: 0.0003980476930479024 Weight: [[2.0129558]] Bias: [0.95323689]\n",
      "Step: 330 Loss: 0.00037158368237105277 Weight: [[2.01251771]] Bias: [0.95481814]\n",
      "Step: 340 Loss: 0.0003468791187989411 Weight: [[2.01209444]] Bias: [0.95634592]\n",
      "Step: 350 Loss: 0.00032381702633160184 Weight: [[2.01168548]] Bias: [0.95782203]\n",
      "Step: 360 Loss: 0.000302288206062387 Weight: [[2.01129035]] Bias: [0.95924824]\n",
      "Step: 370 Loss: 0.0002821907191218855 Weight: [[2.01090858]] Bias: [0.96062622]\n",
      "Step: 380 Loss: 0.00026342940399762726 Weight: [[2.01053971]] Bias: [0.9619576]\n",
      "Step: 390 Loss: 0.000245915425944838 Weight: [[2.01018333]] Bias: [0.96324396]\n",
      "Step: 400 Loss: 0.00022956585635437732 Weight: [[2.00983899]] Bias: [0.96448683]\n",
      "Step: 410 Loss: 0.00021430328008596855 Weight: [[2.00950629]] Bias: [0.96568767]\n",
      "Step: 420 Loss: 0.0002000554289079982 Weight: [[2.00918485]] Bias: [0.96684791]\n",
      "Step: 430 Loss: 0.00018675483930762445 Weight: [[2.00887427]] Bias: [0.96796891]\n",
      "Step: 440 Loss: 0.0001743385330515781 Weight: [[2.0085742]] Bias: [0.96905201]\n",
      "Step: 450 Loss: 0.000162747718984217 Weight: [[2.00828427]] Bias: [0.97009848]\n",
      "Step: 460 Loss: 0.00015192751465175963 Weight: [[2.00800414]] Bias: [0.97110957]\n",
      "Step: 470 Loss: 0.00014182668643423802 Weight: [[2.00773349]] Bias: [0.97208647]\n",
      "Step: 480 Loss: 0.0001323974069543691 Weight: [[2.00747199]] Bias: [0.97303034]\n",
      "Step: 490 Loss: 0.0001235950286152171 Weight: [[2.00721934]] Bias: [0.97394229]\n",
      "Step: 500 Loss: 0.00011537787219398796 Weight: [[2.00697522]] Bias: [0.9748234]\n",
      "Step: 510 Loss: 0.00010770702949109317 Weight: [[2.00673936]] Bias: [0.97567472]\n",
      "Step: 520 Loss: 0.00010054617910002127 Weight: [[2.00651148]] Bias: [0.97649726]\n",
      "Step: 530 Loss: 9.386141442558729e-05 Weight: [[2.0062913]] Bias: [0.97729198]\n",
      "Step: 540 Loss: 8.762108313642482e-05 Weight: [[2.00607856]] Bias: [0.97805982]\n",
      "Step: 550 Loss: 8.179563729125659e-05 Weight: [[2.00587302]] Bias: [0.97880171]\n",
      "Step: 560 Loss: 7.635749342958388e-05 Weight: [[2.00567443]] Bias: [0.97951851]\n",
      "Step: 570 Loss: 7.128090196411381e-05 Weight: [[2.00548256]] Bias: [0.98021107]\n",
      "Step: 580 Loss: 6.654182525651742e-05 Weight: [[2.00529717]] Bias: [0.98088021]\n",
      "Step: 590 Loss: 6.211782379938896e-05 Weight: [[2.00511805]] Bias: [0.98152672]\n",
      "Step: 600 Loss: 5.7987949965266226e-05 Weight: [[2.00494499]] Bias: [0.98215138]\n",
      "Step: 610 Loss: 5.413264881966283e-05 Weight: [[2.00477778]] Bias: [0.98275491]\n",
      "Step: 620 Loss: 5.053366552857748e-05 Weight: [[2.00461623]] Bias: [0.98333804]\n",
      "Step: 630 Loss: 4.717395892193641e-05 Weight: [[2.00446013]] Bias: [0.98390144]\n",
      "Step: 640 Loss: 4.403762080370346e-05 Weight: [[2.00430932]] Bias: [0.9844458]\n",
      "Step: 650 Loss: 4.110980062665227e-05 Weight: [[2.0041636]] Bias: [0.98497175]\n",
      "Step: 660 Loss: 3.837663517510533e-05 Weight: [[2.00402282]] Bias: [0.98547991]\n",
      "Step: 670 Loss: 3.582518292263247e-05 Weight: [[2.00388679]] Bias: [0.98597089]\n",
      "Step: 680 Loss: 3.344336275403667e-05 Weight: [[2.00375536]] Bias: [0.98644527]\n",
      "Step: 690 Loss: 3.121989676126266e-05 Weight: [[2.00362838]] Bias: [0.98690361]\n",
      "Step: 700 Loss: 2.914425684260245e-05 Weight: [[2.00350569]] Bias: [0.98734645]\n",
      "Step: 710 Loss: 2.7206614852149514e-05 Weight: [[2.00338715]] Bias: [0.98777432]\n",
      "Step: 720 Loss: 2.5397796063587805e-05 Weight: [[2.00327261]] Bias: [0.98818772]\n",
      "Step: 730 Loss: 2.3709235727889492e-05 Weight: [[2.00316195]] Bias: [0.98858714]\n",
      "Step: 740 Loss: 2.2132938519280145e-05 Weight: [[2.00305504]] Bias: [0.98897305]\n",
      "Step: 750 Loss: 2.0661440677403376e-05 Weight: [[2.00295173]] Bias: [0.98934592]\n",
      "Step: 760 Loss: 1.9287774666432964e-05 Weight: [[2.00285192]] Bias: [0.98970617]\n",
      "Step: 770 Loss: 1.8005436183828735e-05 Weight: [[2.00275549]] Bias: [0.99005425]\n",
      "Step: 780 Loss: 1.6808353362517374e-05 Weight: [[2.00266231]] Bias: [0.99039055]\n",
      "Step: 790 Loss: 1.5690858020586893e-05 Weight: [[2.00257229]] Bias: [0.99071549]\n",
      "Step: 800 Loss: 1.4647658822504976e-05 Weight: [[2.00248531]] Bias: [0.99102943]\n",
      "Step: 810 Loss: 1.3673816224640305e-05 Weight: [[2.00240127]] Bias: [0.99133276]\n",
      "Step: 820 Loss: 1.2764719086580725e-05 Weight: [[2.00232008]] Bias: [0.99162584]\n",
      "Step: 830 Loss: 1.1916062837350121e-05 Weight: [[2.00224163]] Bias: [0.991909]\n",
      "Step: 840 Loss: 1.1123829093352373e-05 Weight: [[2.00216583]] Bias: [0.99218259]\n",
      "Step: 850 Loss: 1.038426663127394e-05 Weight: [[2.00209259]] Bias: [0.99244693]\n",
      "Step: 860 Loss: 9.693873626113958e-06 Weight: [[2.00202183]] Bias: [0.99270233]\n",
      "Step: 870 Loss: 9.049381070014444e-06 Weight: [[2.00195347]] Bias: [0.99294909]\n",
      "Step: 880 Loss: 8.447737293554696e-06 Weight: [[2.00188741]] Bias: [0.99318751]\n",
      "Step: 890 Loss: 7.88609351609579e-06 Weight: [[2.00182359]] Bias: [0.99341787]\n",
      "Step: 900 Loss: 7.361790356815706e-06 Weight: [[2.00176193]] Bias: [0.99364043]\n",
      "Step: 910 Loss: 6.872345242560048e-06 Weight: [[2.00170235]] Bias: [0.99385548]\n",
      "Step: 920 Loss: 6.415440652857025e-06 Weight: [[2.00164479]] Bias: [0.99406325]\n",
      "Step: 930 Loss: 5.988913146481825e-06 Weight: [[2.00158917]] Bias: [0.99426399]\n",
      "Step: 940 Loss: 5.590743117563648e-06 Weight: [[2.00153544]] Bias: [0.99445795]\n",
      "Step: 950 Loss: 5.219045232763955e-06 Weight: [[2.00148352]] Bias: [0.99464535]\n",
      "Step: 960 Loss: 4.87205950423088e-06 Weight: [[2.00143335]] Bias: [0.99482641]\n",
      "Step: 970 Loss: 4.548142956061995e-06 Weight: [[2.00138489]] Bias: [0.99500135]\n",
      "Step: 980 Loss: 4.245761844824201e-06 Weight: [[2.00133806]] Bias: [0.99517037]\n",
      "Step: 990 Loss: 3.963484397284179e-06 Weight: [[2.00129281]] Bias: [0.99533368]\n",
      "Step: 1000 Loss: 3.6999740309654462e-06 Weight: [[2.0012491]] Bias: [0.99549147]\n",
      "Step: 1010 Loss: 3.453983025441998e-06 Weight: [[2.00120686]] Bias: [0.99564392]\n",
      "Step: 1020 Loss: 3.2243466143787682e-06 Weight: [[2.00116605]] Bias: [0.99579122]\n",
      "Step: 1030 Loss: 3.0099774703803836e-06 Weight: [[2.00112662]] Bias: [0.99593353]\n",
      "Step: 1040 Loss: 2.8098605564915333e-06 Weight: [[2.00108853]] Bias: [0.99607103]\n",
      "Step: 1050 Loss: 2.6230483200039875e-06 Weight: [[2.00105172]] Bias: [0.99620389]\n",
      "Step: 1060 Loss: 2.4486562057940546e-06 Weight: [[2.00101616]] Bias: [0.99633225]\n",
      "Step: 1070 Loss: 2.2858584679703455e-06 Weight: [[2.0009818]] Bias: [0.99645627]\n",
      "Step: 1080 Loss: 2.133884259957307e-06 Weight: [[2.0009486]] Bias: [0.9965761]\n",
      "Step: 1090 Loss: 1.992013984547383e-06 Weight: [[2.00091652]] Bias: [0.99669187]\n",
      "Step: 1100 Loss: 1.859575886611061e-06 Weight: [[2.00088553]] Bias: [0.99680374]\n",
      "Step: 1110 Loss: 1.735942872334174e-06 Weight: [[2.00085559]] Bias: [0.99691181]\n",
      "Step: 1120 Loss: 1.6205295399354e-06 Weight: [[2.00082666]] Bias: [0.99701624]\n",
      "Step: 1130 Loss: 1.512789407794676e-06 Weight: [[2.0007987]] Bias: [0.99711713]\n",
      "Step: 1140 Loss: 1.412212326859498e-06 Weight: [[2.0007717]] Bias: [0.99721461]\n",
      "Step: 1150 Loss: 1.3183220650928416e-06 Weight: [[2.0007456]] Bias: [0.9973088]\n",
      "Step: 1160 Loss: 1.230674052516789e-06 Weight: [[2.00072039]] Bias: [0.9973998]\n",
      "Step: 1170 Loss: 1.1488532761766555e-06 Weight: [[2.00069603]] Bias: [0.99748772]\n",
      "Step: 1180 Loss: 1.0724723150559956e-06 Weight: [[2.0006725]] Bias: [0.99757267]\n",
      "Step: 1190 Loss: 1.0011695056385289e-06 Weight: [[2.00064976]] Bias: [0.99765475]\n",
      "Step: 1200 Loss: 9.346072294357904e-07 Weight: [[2.00062779]] Bias: [0.99773405]\n",
      "Step: 1210 Loss: 8.724703143616564e-07 Weight: [[2.00060656]] Bias: [0.99781067]\n",
      "Step: 1220 Loss: 8.144645423951758e-07 Weight: [[2.00058605]] Bias: [0.9978847]\n",
      "Step: 1230 Loss: 7.603152564622198e-07 Weight: [[2.00056623]] Bias: [0.99795623]\n",
      "Step: 1240 Loss: 7.097660599300134e-07 Weight: [[2.00054708]] Bias: [0.99802534]\n",
      "Step: 1250 Loss: 6.625776025762118e-07 Weight: [[2.00052859]] Bias: [0.99809211]\n",
      "Step: 1260 Loss: 6.185264472632135e-07 Weight: [[2.00051071]] Bias: [0.99815662]\n",
      "Step: 1270 Loss: 5.774040119617575e-07 Weight: [[2.00049344]] Bias: [0.99821895]\n",
      "Step: 1280 Loss: 5.390155821219852e-07 Weight: [[2.00047676]] Bias: [0.99827918]\n",
      "Step: 1290 Loss: 5.031793886970403e-07 Weight: [[2.00046064]] Bias: [0.99833736]\n",
      "Step: 1300 Loss: 4.6972574746877253e-07 Weight: [[2.00044506]] Bias: [0.99839358]\n",
      "Step: 1310 Loss: 4.384962555925986e-07 Weight: [[2.00043001]] Bias: [0.9984479]\n",
      "Step: 1320 Loss: 4.0934304156259384e-07 Weight: [[2.00041547]] Bias: [0.99850039]\n",
      "Step: 1330 Loss: 3.821280650369336e-07 Weight: [[2.00040142]] Bias: [0.99855109]\n",
      "Step: 1340 Loss: 3.5672246322150803e-07 Weight: [[2.00038785]] Bias: [0.99860009]\n",
      "Step: 1350 Loss: 3.33005940703591e-07 Weight: [[2.00037473]] Bias: [0.99864742]\n",
      "Step: 1360 Loss: 3.1086619985296547e-07 Weight: [[2.00036206]] Bias: [0.99869316]\n",
      "Step: 1370 Loss: 2.9019840909424103e-07 Weight: [[2.00034982]] Bias: [0.99873735]\n",
      "Step: 1380 Loss: 2.709047065280596e-07 Weight: [[2.00033799]] Bias: [0.99878004]\n",
      "Step: 1390 Loss: 2.528937365583507e-07 Weight: [[2.00032656]] Bias: [0.9988213]\n",
      "Step: 1400 Loss: 2.360802173211378e-07 Weight: [[2.00031552]] Bias: [0.99886115]\n",
      "Step: 1410 Loss: 2.203845368765062e-07 Weight: [[2.00030485]] Bias: [0.99889966]\n",
      "Step: 1420 Loss: 2.0573237624653753e-07 Weight: [[2.00029454]] Bias: [0.99893687]\n",
      "Step: 1430 Loss: 1.9205435751498293e-07 Weight: [[2.00028458]] Bias: [0.99897282]\n",
      "Step: 1440 Loss: 1.7928571532340126e-07 Weight: [[2.00027496]] Bias: [0.99900755]\n",
      "Step: 1450 Loss: 1.673659902060197e-07 Weight: [[2.00026566]] Bias: [0.99904111]\n",
      "Step: 1460 Loss: 1.5623874231841476e-07 Weight: [[2.00025668]] Bias: [0.99907353]\n",
      "Step: 1470 Loss: 1.4585128418950162e-07 Weight: [[2.000248]] Bias: [0.99910486]\n",
      "Step: 1480 Loss: 1.3615443125105743e-07 Weight: [[2.00023961]] Bias: [0.99913513]\n",
      "Step: 1490 Loss: 1.2710226894634154e-07 Weight: [[2.00023151]] Bias: [0.99916437]\n",
      "Step: 1500 Loss: 1.1865193532770623e-07 Weight: [[2.00022368]] Bias: [0.99919263]\n",
      "Step: 1510 Loss: 1.1076341810191938e-07 Weight: [[2.00021612]] Bias: [0.99921993]\n",
      "Step: 1520 Loss: 1.0339936517427364e-07 Weight: [[2.00020881]] Bias: [0.99924631]\n",
      "Step: 1530 Loss: 9.652490778691995e-08 Weight: [[2.00020175]] Bias: [0.99927179]\n",
      "Step: 1540 Loss: 9.010749541454466e-08 Weight: [[2.00019493]] Bias: [0.99929642]\n",
      "Step: 1550 Loss: 8.411674163692511e-08 Weight: [[2.00018834]] Bias: [0.99932021]\n",
      "Step: 1560 Loss: 7.852428026206362e-08 Weight: [[2.00018197]] Bias: [0.99934319]\n",
      "Step: 1570 Loss: 7.330363100940402e-08 Weight: [[2.00017582]] Bias: [0.9993654]\n",
      "Step: 1580 Loss: 6.84300741276988e-08 Weight: [[2.00016987]] Bias: [0.99938686]\n",
      "Step: 1590 Loss: 6.388053334660907e-08 Weight: [[2.00016413]] Bias: [0.99940759]\n",
      "Step: 1600 Loss: 5.963346661046919e-08 Weight: [[2.00015858]] Bias: [0.99942762]\n",
      "Step: 1610 Loss: 5.566876407705969e-08 Weight: [[2.00015322]] Bias: [0.99944698]\n",
      "Step: 1620 Loss: 5.196765289701295e-08 Weight: [[2.00014803]] Bias: [0.99946568]\n",
      "Step: 1630 Loss: 4.8512608325470405e-08 Weight: [[2.00014303]] Bias: [0.99948375]\n",
      "Step: 1640 Loss: 4.528727074124015e-08 Weight: [[2.00013819]] Bias: [0.9995012]\n",
      "Step: 1650 Loss: 4.227636818519359e-08 Weight: [[2.00013352]] Bias: [0.99951807]\n",
      "Step: 1660 Loss: 3.946564404691592e-08 Weight: [[2.000129]] Bias: [0.99953437]\n",
      "Step: 1670 Loss: 3.684178955974539e-08 Weight: [[2.00012464]] Bias: [0.99955011]\n",
      "Step: 1680 Loss: 3.439238078479822e-08 Weight: [[2.00012043]] Bias: [0.99956532]\n",
      "Step: 1690 Loss: 3.2105819781690247e-08 Weight: [[2.00011636]] Bias: [0.99958002]\n",
      "Step: 1700 Loss: 2.997127969429143e-08 Weight: [[2.00011242]] Bias: [0.99959422]\n",
      "Step: 1710 Loss: 2.7978653484718648e-08 Weight: [[2.00010862]] Bias: [0.99960794]\n",
      "Step: 1720 Loss: 2.6118506076528287e-08 Weight: [[2.00010495]] Bias: [0.9996212]\n",
      "Step: 1730 Loss: 2.4382029680113953e-08 Weight: [[2.0001014]] Bias: [0.99963401]\n",
      "Step: 1740 Loss: 2.2761002087032535e-08 Weight: [[2.00009797]] Bias: [0.99964638]\n",
      "Step: 1750 Loss: 2.124774773901125e-08 Weight: [[2.00009466]] Bias: [0.99965834]\n",
      "Step: 1760 Loss: 1.9835101383212013e-08 Weight: [[2.00009146]] Bias: [0.99966989]\n",
      "Step: 1770 Loss: 1.8516374145227212e-08 Weight: [[2.00008836]] Bias: [0.99968106]\n",
      "Step: 1780 Loss: 1.7285321857673864e-08 Weight: [[2.00008538]] Bias: [0.99969184]\n",
      "Step: 1790 Loss: 1.6136115493344437e-08 Weight: [[2.00008249]] Bias: [0.99970226]\n",
      "Step: 1800 Loss: 1.5063313564942353e-08 Weight: [[2.0000797]] Bias: [0.99971233]\n",
      "Step: 1810 Loss: 1.4061836360082862e-08 Weight: [[2.000077]] Bias: [0.99972206]\n",
      "Step: 1820 Loss: 1.3126941888659118e-08 Weight: [[2.0000744]] Bias: [0.99973145]\n",
      "Step: 1830 Loss: 1.225420342958976e-08 Weight: [[2.00007189]] Bias: [0.99974054]\n",
      "Step: 1840 Loss: 1.1439488569937673e-08 Weight: [[2.00006945]] Bias: [0.99974931]\n",
      "Step: 1850 Loss: 1.0678939638356638e-08 Weight: [[2.00006711]] Bias: [0.99975779]\n",
      "Step: 1860 Loss: 9.968955439041149e-09 Weight: [[2.00006484]] Bias: [0.99976598]\n",
      "Step: 1870 Loss: 9.306174200107264e-09 Weight: [[2.00006264]] Bias: [0.99977389]\n",
      "Step: 1880 Loss: 8.68745765500377e-09 Weight: [[2.00006053]] Bias: [0.99978153]\n",
      "Step: 1890 Loss: 8.109876183869149e-09 Weight: [[2.00005848]] Bias: [0.99978892]\n",
      "Step: 1900 Loss: 7.570694940840437e-09 Weight: [[2.0000565]] Bias: [0.99979606]\n",
      "Step: 1910 Loss: 7.067360905211419e-09 Weight: [[2.00005459]] Bias: [0.99980296]\n",
      "Step: 1920 Loss: 6.597490792345975e-09 Weight: [[2.00005275]] Bias: [0.99980962]\n",
      "Step: 1930 Loss: 6.158859769385823e-09 Weight: [[2.00005096]] Bias: [0.99981606]\n",
      "Step: 1940 Loss: 5.7493909204487985e-09 Weight: [[2.00004924]] Bias: [0.99982228]\n",
      "Step: 1950 Loss: 5.367145412253416e-09 Weight: [[2.00004757]] Bias: [0.99982829]\n",
      "Step: 1960 Loss: 5.010313314078029e-09 Weight: [[2.00004597]] Bias: [0.99983409]\n",
      "Step: 1970 Loss: 4.6772050274122596e-09 Weight: [[2.00004441]] Bias: [0.9998397]\n",
      "Step: 1980 Loss: 4.366243286019554e-09 Weight: [[2.00004291]] Bias: [0.99984512]\n",
      "Step: 1990 Loss: 4.075955687481951e-09 Weight: [[2.00004146]] Bias: [0.99985036]\n",
      "Step: 2000 Loss: 3.804967721159051e-09 Weight: [[2.00004006]] Bias: [0.99985542]\n",
      "Step: 2010 Loss: 3.5519962602557738e-09 Weight: [[2.0000387]] Bias: [0.99986031]\n",
      "Step: 2020 Loss: 3.3158434861519252e-09 Weight: [[2.00003739]] Bias: [0.99986503]\n",
      "Step: 2030 Loss: 3.0953912163154076e-09 Weight: [[2.00003613]] Bias: [0.9998696]\n",
      "Step: 2040 Loss: 2.8895956103280236e-09 Weight: [[2.00003491]] Bias: [0.999874]\n",
      "Step: 2050 Loss: 2.697482226907534e-09 Weight: [[2.00003373]] Bias: [0.99987827]\n",
      "Step: 2060 Loss: 2.518141409937032e-09 Weight: [[2.00003259]] Bias: [0.99988238]\n",
      "Step: 2070 Loss: 2.3507239815564643e-09 Weight: [[2.00003148]] Bias: [0.99988636]\n",
      "Step: 2080 Loss: 2.1944372208156027e-09 Weight: [[2.00003042]] Bias: [0.9998902]\n",
      "Step: 2090 Loss: 2.0485411107499524e-09 Weight: [[2.00002939]] Bias: [0.99989391]\n",
      "Step: 2100 Loss: 1.912344833871686e-09 Weight: [[2.0000284]] Bias: [0.9998975]\n",
      "Step: 2110 Loss: 1.7852035013234616e-09 Weight: [[2.00002744]] Bias: [0.99990097]\n",
      "Step: 2120 Loss: 1.6665150995428246e-09 Weight: [[2.00002651]] Bias: [0.99990432]\n",
      "Step: 2130 Loss: 1.5557176394547744e-09 Weight: [[2.00002561]] Bias: [0.99990755]\n",
      "Step: 2140 Loss: 1.4522864955293809e-09 Weight: [[2.00002475]] Bias: [0.99991068]\n",
      "Step: 2150 Loss: 1.3557319218105467e-09 Weight: [[2.00002391]] Bias: [0.9999137]\n",
      "Step: 2160 Loss: 1.2655967327680023e-09 Weight: [[2.0000231]] Bias: [0.99991662]\n",
      "Step: 2170 Loss: 1.1814541387361873e-09 Weight: [[2.00002232]] Bias: [0.99991944]\n",
      "Step: 2180 Loss: 1.1029057248675818e-09 Weight: [[2.00002157]] Bias: [0.99992216]\n",
      "Step: 2190 Loss: 1.0295795647309927e-09 Weight: [[2.00002084]] Bias: [0.99992479]\n",
      "Step: 2200 Loss: 9.611284593090915e-10 Weight: [[2.00002013]] Bias: [0.99992733]\n",
      "Step: 2210 Loss: 8.972282929463967e-10 Weight: [[2.00001945]] Bias: [0.99992979]\n",
      "Step: 2220 Loss: 8.375764986060142e-10 Weight: [[2.00001879]] Bias: [0.99993217]\n",
      "Step: 2230 Loss: 7.81890625319533e-10 Weight: [[2.00001816]] Bias: [0.99993446]\n",
      "Step: 2240 Loss: 7.29907000690641e-10 Weight: [[2.00001754]] Bias: [0.99993668]\n",
      "Step: 2250 Loss: 6.813794824913066e-10 Weight: [[2.00001695]] Bias: [0.99993882]\n",
      "Step: 2260 Loss: 6.360782931815298e-10 Weight: [[2.00001638]] Bias: [0.99994089]\n",
      "Step: 2270 Loss: 5.937889318015142e-10 Weight: [[2.00001582]] Bias: [0.99994288]\n",
      "Step: 2280 Loss: 5.543111583901467e-10 Weight: [[2.00001529]] Bias: [0.99994482]\n",
      "Step: 2290 Loss: 5.174580458881201e-10 Weight: [[2.00001477]] Bias: [0.99994668]\n",
      "Step: 2300 Loss: 4.830550949543423e-10 Weight: [[2.00001427]] Bias: [0.99994848]\n",
      "Step: 2310 Loss: 4.509394077729407e-10 Weight: [[2.00001379]] Bias: [0.99995023]\n",
      "Step: 2320 Loss: 4.209589167148939e-10 Weight: [[2.00001332]] Bias: [0.99995191]\n",
      "Step: 2330 Loss: 3.9297166428078317e-10 Weight: [[2.00001287]] Bias: [0.99995354]\n",
      "Step: 2340 Loss: 3.6684513093815733e-10 Weight: [[2.00001244]] Bias: [0.99995511]\n",
      "Step: 2350 Loss: 3.4245560770040074e-10 Weight: [[2.00001202]] Bias: [0.99995663]\n",
      "Step: 2360 Loss: 3.1968761027344437e-10 Weight: [[2.00001161]] Bias: [0.99995809]\n",
      "Step: 2370 Loss: 2.984333322538064e-10 Weight: [[2.00001122]] Bias: [0.99995951]\n",
      "Step: 2380 Loss: 2.7859213474937856e-10 Weight: [[2.00001084]] Bias: [0.99996088]\n",
      "Step: 2390 Loss: 2.6007006978662226e-10 Weight: [[2.00001047]] Bias: [0.9999622]\n",
      "Step: 2400 Loss: 2.427794354536406e-10 Weight: [[2.00001012]] Bias: [0.99996348]\n",
      "Step: 2410 Loss: 2.266383606955242e-10 Weight: [[2.00000978]] Bias: [0.99996471]\n",
      "Step: 2420 Loss: 2.1157041757121056e-10 Weight: [[2.00000945]] Bias: [0.99996591]\n",
      "Step: 2430 Loss: 1.975042594569615e-10 Weight: [[2.00000913]] Bias: [0.99996706]\n",
      "Step: 2440 Loss: 1.843732831325869e-10 Weight: [[2.00000882]] Bias: [0.99996817]\n",
      "Step: 2450 Loss: 1.7211531350203905e-10 Weight: [[2.00000852]] Bias: [0.99996925]\n",
      "Step: 2460 Loss: 1.6067230913046746e-10 Weight: [[2.00000823]] Bias: [0.99997029]\n",
      "Step: 2470 Loss: 1.4999008743568494e-10 Weight: [[2.00000795]] Bias: [0.99997129]\n",
      "Step: 2480 Loss: 1.4001806813776062e-10 Weight: [[2.00000768]] Bias: [0.99997227]\n",
      "Step: 2490 Loss: 1.307090337792982e-10 Weight: [[2.00000742]] Bias: [0.9999732]\n",
      "Step: 2500 Loss: 1.2201890612495337e-10 Weight: [[2.00000717]] Bias: [0.99997411]\n",
      "Step: 2510 Loss: 1.1390653745319588e-10 Weight: [[2.00000693]] Bias: [0.99997498]\n",
      "Step: 2520 Loss: 1.0633351573874637e-10 Weight: [[2.0000067]] Bias: [0.99997583]\n",
      "Step: 2530 Loss: 9.926398275769386e-11 Weight: [[2.00000647]] Bias: [0.99997665]\n",
      "Step: 2540 Loss: 9.266446429838098e-11 Weight: [[2.00000625]] Bias: [0.99997744]\n",
      "Step: 2550 Loss: 8.650371165687608e-11 Weight: [[2.00000604]] Bias: [0.9999782]\n",
      "Step: 2560 Loss: 8.075255372153935e-11 Weight: [[2.00000584]] Bias: [0.99997894]\n",
      "Step: 2570 Loss: 7.538375877471994e-11 Weight: [[2.00000564]] Bias: [0.99997965]\n",
      "Step: 2580 Loss: 7.037190558791432e-11 Weight: [[2.00000545]] Bias: [0.99998034]\n",
      "Step: 2590 Loss: 6.569326307860399e-11 Weight: [[2.00000526]] Bias: [0.999981]\n",
      "Step: 2600 Loss: 6.132567786669706e-11 Weight: [[2.00000509]] Bias: [0.99998164]\n",
      "Step: 2610 Loss: 5.7248469473923733e-11 Weight: [[2.00000491]] Bias: [0.99998227]\n",
      "Step: 2620 Loss: 5.344233233551809e-11 Weight: [[2.00000475]] Bias: [0.99998287]\n",
      "Step: 2630 Loss: 4.9889244410285246e-11 Weight: [[2.00000459]] Bias: [0.99998344]\n",
      "Step: 2640 Loss: 4.657238182544761e-11 Weight: [[2.00000443]] Bias: [0.999984]\n",
      "Step: 2650 Loss: 4.3476039277563384e-11 Weight: [[2.00000428]] Bias: [0.99998455]\n",
      "Step: 2660 Loss: 4.058555557760105e-11 Weight: [[2.00000414]] Bias: [0.99998507]\n",
      "Step: 2670 Loss: 3.7887244307131253e-11 Weight: [[2.000004]] Bias: [0.99998557]\n",
      "Step: 2680 Loss: 3.536832897198856e-11 Weight: [[2.00000386]] Bias: [0.99998606]\n",
      "Step: 2690 Loss: 3.301688252739969e-11 Weight: [[2.00000373]] Bias: [0.99998653]\n",
      "Step: 2700 Loss: 3.082177086290156e-11 Weight: [[2.00000361]] Bias: [0.99998699]\n",
      "Step: 2710 Loss: 2.8772600156628568e-11 Weight: [[2.00000348]] Bias: [0.99998743]\n",
      "Step: 2720 Loss: 2.6859667583497644e-11 Weight: [[2.00000337]] Bias: [0.99998785]\n",
      "Step: 2730 Loss: 2.507391541576112e-11 Weight: [[2.00000325]] Bias: [0.99998826]\n",
      "Step: 2740 Loss: 2.3406888130571523e-11 Weight: [[2.00000314]] Bias: [0.99998866]\n",
      "Step: 2750 Loss: 2.185069235719205e-11 Weight: [[2.00000304]] Bias: [0.99998904]\n",
      "Step: 2760 Loss: 2.0397959515810685e-11 Weight: [[2.00000293]] Bias: [0.99998941]\n",
      "Step: 2770 Loss: 1.9041810925798685e-11 Weight: [[2.00000283]] Bias: [0.99998977]\n",
      "Step: 2780 Loss: 1.7775825224233293e-11 Weight: [[2.00000274]] Bias: [0.99999012]\n",
      "Step: 2790 Loss: 1.659400797865579e-11 Weight: [[2.00000265]] Bias: [0.99999045]\n",
      "Step: 2800 Loss: 1.549076328278708e-11 Weight: [[2.00000256]] Bias: [0.99999077]\n",
      "Step: 2810 Loss: 1.4460867289565037e-11 Weight: [[2.00000247]] Bias: [0.99999109]\n",
      "Step: 2820 Loss: 1.3499443438422721e-11 Weight: [[2.00000239]] Bias: [0.99999139]\n",
      "Step: 2830 Loss: 1.2601939389941757e-11 Weight: [[2.00000231]] Bias: [0.99999168]\n",
      "Step: 2840 Loss: 1.1764105470792357e-11 Weight: [[2.00000223]] Bias: [0.99999196]\n",
      "Step: 2850 Loss: 1.098197454081534e-11 Weight: [[2.00000215]] Bias: [0.99999223]\n",
      "Step: 2860 Loss: 1.0251843213270589e-11 Weight: [[2.00000208]] Bias: [0.9999925]\n",
      "Step: 2870 Loss: 9.570254313439252e-12 Weight: [[2.00000201]] Bias: [0.99999275]\n",
      "Step: 2880 Loss: 8.933980528610963e-12 Weight: [[2.00000194]] Bias: [0.99999299]\n",
      "Step: 2890 Loss: 8.340009102885727e-12 Weight: [[2.00000188]] Bias: [0.99999323]\n",
      "Step: 2900 Loss: 7.785527582976364e-12 Weight: [[2.00000181]] Bias: [0.99999346]\n",
      "Step: 2910 Loss: 7.267910501131201e-12 Weight: [[2.00000175]] Bias: [0.99999368]\n",
      "Step: 2920 Loss: 6.784706946008842e-12 Weight: [[2.00000169]] Bias: [0.99999389]\n",
      "Step: 2930 Loss: 6.33362894432547e-12 Weight: [[2.00000163]] Bias: [0.9999941]\n",
      "Step: 2940 Loss: 5.912540650000984e-12 Weight: [[2.00000158]] Bias: [0.9999943]\n",
      "Step: 2950 Loss: 5.519448209871861e-12 Weight: [[2.00000153]] Bias: [0.99999449]\n",
      "Step: 2960 Loss: 5.152490331691192e-12 Weight: [[2.00000147]] Bias: [0.99999468]\n",
      "Step: 2970 Loss: 4.809929474826309e-12 Weight: [[2.00000142]] Bias: [0.99999486]\n",
      "Step: 2980 Loss: 4.490143611620808e-12 Weight: [[2.00000138]] Bias: [0.99999503]\n",
      "Step: 2990 Loss: 4.191618560379615e-12 Weight: [[2.00000133]] Bias: [0.9999952]\n",
      "Step: 3000 Loss: 3.91294080252823e-12 Weight: [[2.00000128]] Bias: [0.99999536]\n",
      "Step: 3010 Loss: 3.652790802203747e-12 Weight: [[2.00000124]] Bias: [0.99999552]\n",
      "Step: 3020 Loss: 3.4099367507953253e-12 Weight: [[2.0000012]] Bias: [0.99999567]\n",
      "Step: 3030 Loss: 3.1832287373843494e-12 Weight: [[2.00000116]] Bias: [0.99999582]\n",
      "Step: 3040 Loss: 2.9715932933740544e-12 Weight: [[2.00000112]] Bias: [0.99999596]\n",
      "Step: 3050 Loss: 2.7740283332840037e-12 Weight: [[2.00000108]] Bias: [0.9999961]\n",
      "Step: 3060 Loss: 2.589598383409732e-12 Weight: [[2.00000104]] Bias: [0.99999623]\n",
      "Step: 3070 Loss: 2.4174301735370255e-12 Weight: [[2.00000101]] Bias: [0.99999636]\n",
      "Step: 3080 Loss: 2.256708483213677e-12 Weight: [[2.00000098]] Bias: [0.99999648]\n",
      "Step: 3090 Loss: 2.1066722977744125e-12 Weight: [[2.00000094]] Bias: [0.9999966]\n",
      "Step: 3100 Loss: 1.9666111965401322e-12 Weight: [[2.00000091]] Bias: [0.99999671]\n",
      "Step: 3110 Loss: 1.8358619912162286e-12 Weight: [[2.00000088]] Bias: [0.99999682]\n",
      "Step: 3120 Loss: 1.7138055835506696e-12 Weight: [[2.00000085]] Bias: [0.99999693]\n",
      "Step: 3130 Loss: 1.5998640377689358e-12 Weight: [[2.00000082]] Bias: [0.99999704]\n",
      "Step: 3140 Loss: 1.4934978427508278e-12 Weight: [[2.00000079]] Bias: [0.99999714]\n",
      "Step: 3150 Loss: 1.394203351245871e-12 Weight: [[2.00000077]] Bias: [0.99999723]\n",
      "Step: 3160 Loss: 1.3015104075413875e-12 Weight: [[2.00000074]] Bias: [0.99999733]\n",
      "Step: 3170 Loss: 1.2149801099313637e-12 Weight: [[2.00000072]] Bias: [0.99999742]\n",
      "Step: 3180 Loss: 1.1342027369978554e-12 Weight: [[2.00000069]] Bias: [0.9999975]\n",
      "Step: 3190 Loss: 1.058795810438667e-12 Weight: [[2.00000067]] Bias: [0.99999759]\n",
      "Step: 3200 Loss: 9.88402277537608e-13 Weight: [[2.00000065]] Bias: [0.99999767]\n",
      "Step: 3210 Loss: 9.226888235877023e-13 Weight: [[2.00000062]] Bias: [0.99999775]\n",
      "Step: 3220 Loss: 8.613442981504098e-13 Weight: [[2.0000006]] Bias: [0.99999782]\n",
      "Step: 3230 Loss: 8.040782343067457e-13 Weight: [[2.00000058]] Bias: [0.9999979]\n",
      "Step: 3240 Loss: 7.506194766735914e-13 Weight: [[2.00000056]] Bias: [0.99999797]\n",
      "Step: 3250 Loss: 7.007148990036688e-13 Weight: [[2.00000054]] Bias: [0.99999804]\n",
      "Step: 3260 Loss: 6.541282042688682e-13 Weight: [[2.00000053]] Bias: [0.9999981]\n",
      "Step: 3270 Loss: 6.106388028684918e-13 Weight: [[2.00000051]] Bias: [0.99999817]\n",
      "Step: 3280 Loss: 5.700407743473792e-13 Weight: [[2.00000049]] Bias: [0.99999823]\n",
      "Step: 3290 Loss: 5.32141885141275e-13 Weight: [[2.00000047]] Bias: [0.99999829]\n",
      "Step: 3300 Loss: 4.967626865104402e-13 Weight: [[2.00000046]] Bias: [0.99999835]\n",
      "Step: 3310 Loss: 4.637356567976587e-13 Weight: [[2.00000044]] Bias: [0.9999984]\n",
      "Step: 3320 Loss: 4.329044130669513e-13 Weight: [[2.00000043]] Bias: [0.99999846]\n",
      "Step: 3330 Loss: 4.041229697029737e-13 Weight: [[2.00000041]] Bias: [0.99999851]\n",
      "Step: 3340 Loss: 3.772550477228083e-13 Weight: [[2.0000004]] Bias: [0.99999856]\n",
      "Step: 3350 Loss: 3.5217342561303904e-13 Weight: [[2.00000039]] Bias: [0.99999861]\n",
      "Step: 3360 Loss: 3.287593442759625e-13 Weight: [[2.00000037]] Bias: [0.99999866]\n",
      "Step: 3370 Loss: 3.069019359434742e-13 Weight: [[2.00000036]] Bias: [0.9999987]\n",
      "Step: 3380 Loss: 2.864977079084243e-13 Weight: [[2.00000035]] Bias: [0.99999875]\n",
      "Step: 3390 Loss: 2.674500442879993e-13 Weight: [[2.00000034]] Bias: [0.99999879]\n",
      "Step: 3400 Loss: 2.4966875593198185e-13 Weight: [[2.00000032]] Bias: [0.99999883]\n",
      "Step: 3410 Loss: 2.3306964810873073e-13 Weight: [[2.00000031]] Bias: [0.99999887]\n",
      "Step: 3420 Loss: 2.1757412389482807e-13 Weight: [[2.0000003]] Bias: [0.99999891]\n",
      "Step: 3430 Loss: 2.0310881156667925e-13 Weight: [[2.00000029]] Bias: [0.99999894]\n",
      "Step: 3440 Loss: 1.896052198016897e-13 Weight: [[2.00000028]] Bias: [0.99999898]\n",
      "Step: 3450 Loss: 1.769994072330917e-13 Weight: [[2.00000027]] Bias: [0.99999901]\n",
      "Step: 3460 Loss: 1.652316859605599e-13 Weight: [[2.00000026]] Bias: [0.99999905]\n",
      "Step: 3470 Loss: 1.5424633665089943e-13 Weight: [[2.00000026]] Bias: [0.99999908]\n",
      "Step: 3480 Loss: 1.4399134229377834e-13 Weight: [[2.00000025]] Bias: [0.99999911]\n",
      "Step: 3490 Loss: 1.3441814693969562e-13 Weight: [[2.00000024]] Bias: [0.99999914]\n",
      "Step: 3500 Loss: 1.2548142070434824e-13 Weight: [[2.00000023]] Bias: [0.99999917]\n",
      "Step: 3510 Loss: 1.1713884829409583e-13 Weight: [[2.00000022]] Bias: [0.9999992]\n",
      "Step: 3520 Loss: 1.0935092789989852e-13 Weight: [[2.00000021]] Bias: [0.99999922]\n",
      "Step: 3530 Loss: 1.0208078377116035e-13 Weight: [[2.00000021]] Bias: [0.99999925]\n",
      "Step: 3540 Loss: 9.529399182704614e-14 Weight: [[2.0000002]] Bias: [0.99999928]\n",
      "Step: 3550 Loss: 8.895841650202201e-14 Weight: [[2.00000019]] Bias: [0.9999993]\n",
      "Step: 3560 Loss: 8.304405846434981e-14 Weight: [[2.00000019]] Bias: [0.99999932]\n",
      "Step: 3570 Loss: 7.752291385552786e-14 Weight: [[2.00000018]] Bias: [0.99999935]\n",
      "Step: 3580 Loss: 7.236884027588514e-14 Weight: [[2.00000017]] Bias: [0.99999937]\n",
      "Step: 3590 Loss: 6.755743246921238e-14 Weight: [[2.00000017]] Bias: [0.99999939]\n",
      "Step: 3600 Loss: 6.306590867521418e-14 Weight: [[2.00000016]] Bias: [0.99999941]\n",
      "Step: 3610 Loss: 5.887300184657181e-14 Weight: [[2.00000016]] Bias: [0.99999943]\n",
      "Step: 3620 Loss: 5.495885856158296e-14 Weight: [[2.00000015]] Bias: [0.99999945]\n",
      "Step: 3630 Loss: 5.1304945129806967e-14 Weight: [[2.00000015]] Bias: [0.99999947]\n",
      "Step: 3640 Loss: 4.789396044153479e-14 Weight: [[2.00000014]] Bias: [0.99999949]\n",
      "Step: 3650 Loss: 4.470975310568439e-14 Weight: [[2.00000014]] Bias: [0.9999995]\n",
      "Step: 3660 Loss: 4.1737246670201064e-14 Weight: [[2.00000013]] Bias: [0.99999952]\n",
      "Step: 3670 Loss: 3.89623657312016e-14 Weight: [[2.00000013]] Bias: [0.99999954]\n",
      "Step: 3680 Loss: 3.6371971478051165e-14 Weight: [[2.00000012]] Bias: [0.99999955]\n",
      "Step: 3690 Loss: 3.395379828853424e-14 Weight: [[2.00000012]] Bias: [0.99999957]\n",
      "Step: 3700 Loss: 3.169639630041928e-14 Weight: [[2.00000012]] Bias: [0.99999958]\n",
      "Step: 3710 Loss: 2.9589076420813034e-14 Weight: [[2.00000011]] Bias: [0.9999996]\n",
      "Step: 3720 Loss: 2.762186096943046e-14 Weight: [[2.00000011]] Bias: [0.99999961]\n",
      "Step: 3730 Loss: 2.5785434653265395e-14 Weight: [[2.0000001]] Bias: [0.99999962]\n",
      "Step: 3740 Loss: 2.4071102366189275e-14 Weight: [[2.0000001]] Bias: [0.99999964]\n",
      "Step: 3750 Loss: 2.2470746625724933e-14 Weight: [[2.0000001]] Bias: [0.99999965]\n",
      "Step: 3760 Loss: 2.0976789736625534e-14 Weight: [[2.00000009]] Bias: [0.99999966]\n",
      "Step: 3770 Loss: 1.9582157863560937e-14 Weight: [[2.00000009]] Bias: [0.99999967]\n",
      "Step: 3780 Loss: 1.828024751934339e-14 Weight: [[2.00000009]] Bias: [0.99999968]\n",
      "Step: 3790 Loss: 1.7064893968506717e-14 Weight: [[2.00000008]] Bias: [0.99999969]\n",
      "Step: 3800 Loss: 1.5930342580996968e-14 Weight: [[2.00000008]] Bias: [0.9999997]\n",
      "Step: 3810 Loss: 1.487122132036481e-14 Weight: [[2.00000008]] Bias: [0.99999971]\n",
      "Step: 3820 Loss: 1.388251529568582e-14 Weight: [[2.00000008]] Bias: [0.99999972]\n",
      "Step: 3830 Loss: 1.2959542881644879e-14 Weight: [[2.00000007]] Bias: [0.99999973]\n",
      "Step: 3840 Loss: 1.2097933859825068e-14 Weight: [[2.00000007]] Bias: [0.99999974]\n",
      "Step: 3850 Loss: 1.1293608457886044e-14 Weight: [[2.00000007]] Bias: [0.99999975]\n",
      "Step: 3860 Loss: 1.054275825772867e-14 Weight: [[2.00000007]] Bias: [0.99999976]\n",
      "Step: 3870 Loss: 9.841828055199054e-15 Weight: [[2.00000006]] Bias: [0.99999977]\n",
      "Step: 3880 Loss: 9.18749881650145e-15 Weight: [[2.00000006]] Bias: [0.99999978]\n",
      "Step: 3890 Loss: 8.576672326321582e-15 Weight: [[2.00000006]] Bias: [0.99999978]\n",
      "Step: 3900 Loss: 8.006456414333689e-15 Weight: [[2.00000006]] Bias: [0.99999979]\n",
      "Step: 3910 Loss: 7.474150949431532e-15 Weight: [[2.00000006]] Bias: [0.9999998]\n",
      "Step: 3920 Loss: 6.977235652743712e-15 Weight: [[2.00000005]] Bias: [0.9999998]\n",
      "Step: 3930 Loss: 6.51335746110153e-15 Weight: [[2.00000005]] Bias: [0.99999981]\n",
      "Step: 3940 Loss: 6.080319964488857e-15 Weight: [[2.00000005]] Bias: [0.99999982]\n",
      "Step: 3950 Loss: 5.6760728032574e-15 Weight: [[2.00000005]] Bias: [0.99999982]\n",
      "Step: 3960 Loss: 5.2987018090372635e-15 Weight: [[2.00000005]] Bias: [0.99999983]\n",
      "Step: 3970 Loss: 4.946420119305413e-15 Weight: [[2.00000005]] Bias: [0.99999984]\n",
      "Step: 3980 Loss: 4.6175598283174655e-15 Weight: [[2.00000004]] Bias: [0.99999984]\n",
      "Step: 3990 Loss: 4.31056351788626e-15 Weight: [[2.00000004]] Bias: [0.99999985]\n",
      "Step: 4000 Loss: 4.02397777555751e-15 Weight: [[2.00000004]] Bias: [0.99999985]\n",
      "Step: 4010 Loss: 3.7564455020056305e-15 Weight: [[2.00000004]] Bias: [0.99999986]\n",
      "Step: 4020 Loss: 3.5067000077745176e-15 Weight: [[2.00000004]] Bias: [0.99999986]\n",
      "Step: 4030 Loss: 3.2735587603897783e-15 Weight: [[2.00000004]] Bias: [0.99999987]\n",
      "Step: 4040 Loss: 3.0559177853225966e-15 Weight: [[2.00000004]] Bias: [0.99999987]\n",
      "Step: 4050 Loss: 2.8527465538226285e-15 Weight: [[2.00000003]] Bias: [0.99999987]\n",
      "Step: 4060 Loss: 2.6630830676912575e-15 Weight: [[2.00000003]] Bias: [0.99999988]\n",
      "Step: 4070 Loss: 2.486029213446042e-15 Weight: [[2.00000003]] Bias: [0.99999988]\n",
      "Step: 4080 Loss: 2.3207467651545026e-15 Weight: [[2.00000003]] Bias: [0.99999989]\n",
      "Step: 4090 Loss: 2.1664530275548264e-15 Weight: [[2.00000003]] Bias: [0.99999989]\n",
      "Step: 4100 Loss: 2.0224174503467997e-15 Weight: [[2.00000003]] Bias: [0.99999989]\n",
      "Step: 4110 Loss: 1.8879579884498102e-15 Weight: [[2.00000003]] Bias: [0.9999999]\n",
      "Step: 4120 Loss: 1.7624379859621633e-15 Weight: [[2.00000003]] Bias: [0.9999999]\n",
      "Step: 4130 Loss: 1.645263136675255e-15 Weight: [[2.00000003]] Bias: [0.9999999]\n",
      "Step: 4140 Loss: 1.5358786008842305e-15 Weight: [[2.00000003]] Bias: [0.99999991]\n",
      "Step: 4150 Loss: 1.4337664617055227e-15 Weight: [[2.00000002]] Bias: [0.99999991]\n",
      "Step: 4160 Loss: 1.3384431896065252e-15 Weight: [[2.00000002]] Bias: [0.99999991]\n",
      "Step: 4170 Loss: 1.249457412711888e-15 Weight: [[2.00000002]] Bias: [0.99999992]\n",
      "Step: 4180 Loss: 1.1663878155073642e-15 Weight: [[2.00000002]] Bias: [0.99999992]\n",
      "Step: 4190 Loss: 1.0888411003314249e-15 Weight: [[2.00000002]] Bias: [0.99999992]\n",
      "Step: 4200 Loss: 1.0164499980139417e-15 Weight: [[2.00000002]] Bias: [0.99999993]\n",
      "Step: 4210 Loss: 9.488718263398507e-16 Weight: [[2.00000002]] Bias: [0.99999993]\n",
      "Step: 4220 Loss: 8.85786535715117e-16 Weight: [[2.00000002]] Bias: [0.99999993]\n",
      "Step: 4230 Loss: 8.268954232805886e-16 Weight: [[2.00000002]] Bias: [0.99999993]\n",
      "Step: 4240 Loss: 7.719196921173918e-16 Weight: [[2.00000002]] Bias: [0.99999993]\n",
      "Step: 4250 Loss: 7.205989710254975e-16 Weight: [[2.00000002]] Bias: [0.99999994]\n",
      "Step: 4260 Loss: 6.726903040563189e-16 Weight: [[2.00000002]] Bias: [0.99999994]\n",
      "Step: 4270 Loss: 6.279667941617996e-16 Weight: [[2.00000002]] Bias: [0.99999994]\n",
      "Step: 4280 Loss: 5.86216737693898e-16 Weight: [[2.00000002]] Bias: [0.99999994]\n",
      "Step: 4290 Loss: 5.472424039779449e-16 Weight: [[2.00000002]] Bias: [0.99999995]\n",
      "Step: 4300 Loss: 5.108592599486116e-16 Weight: [[2.00000001]] Bias: [0.99999995]\n",
      "Step: 4310 Loss: 4.76895000215208e-16 Weight: [[2.00000001]] Bias: [0.99999995]\n",
      "Step: 4320 Loss: 4.451888714784185e-16 Weight: [[2.00000001]] Bias: [0.99999995]\n",
      "Step: 4330 Loss: 4.1559069428577085e-16 Weight: [[2.00000001]] Bias: [0.99999995]\n",
      "Step: 4340 Loss: 3.879603361217609e-16 Weight: [[2.00000001]] Bias: [0.99999995]\n",
      "Step: 4350 Loss: 3.62166989395003e-16 Weight: [[2.00000001]] Bias: [0.99999996]\n",
      "Step: 4360 Loss: 3.3808849474116785e-16 Weight: [[2.00000001]] Bias: [0.99999996]\n",
      "Step: 4370 Loss: 3.15610835529866e-16 Weight: [[2.00000001]] Bias: [0.99999996]\n",
      "Step: 4380 Loss: 2.9462760126622377e-16 Weight: [[2.00000001]] Bias: [0.99999996]\n",
      "Step: 4390 Loss: 2.750394205216562e-16 Weight: [[2.00000001]] Bias: [0.99999996]\n",
      "Step: 4400 Loss: 2.56753567045669e-16 Weight: [[2.00000001]] Bias: [0.99999996]\n",
      "Step: 4410 Loss: 2.3968342911080087e-16 Weight: [[2.00000001]] Bias: [0.99999996]\n",
      "Step: 4420 Loss: 2.2374818702517433e-16 Weight: [[2.00000001]] Bias: [0.99999996]\n",
      "Step: 4430 Loss: 2.0887240213284053e-16 Weight: [[2.00000001]] Bias: [0.99999997]\n",
      "Step: 4440 Loss: 1.9498560532779075e-16 Weight: [[2.00000001]] Bias: [0.99999997]\n",
      "Step: 4450 Loss: 1.8202208027057162e-16 Weight: [[2.00000001]] Bias: [0.99999997]\n",
      "Step: 4460 Loss: 1.6992043133863304e-16 Weight: [[2.00000001]] Bias: [0.99999997]\n",
      "Step: 4470 Loss: 1.586233442115439e-16 Weight: [[2.00000001]] Bias: [0.99999997]\n",
      "Step: 4480 Loss: 1.4807735831062017e-16 Weight: [[2.00000001]] Bias: [0.99999997]\n",
      "Step: 4490 Loss: 1.3823250171453386e-16 Weight: [[2.00000001]] Bias: [0.99999997]\n",
      "Step: 4500 Loss: 1.2904218236970076e-16 Weight: [[2.00000001]] Bias: [0.99999997]\n",
      "Step: 4510 Loss: 1.2046286886675732e-16 Weight: [[2.00000001]] Bias: [0.99999997]\n",
      "Step: 4520 Loss: 1.1245395242681628e-16 Weight: [[2.00000001]] Bias: [0.99999998]\n",
      "Step: 4530 Loss: 1.0497750298845446e-16 Weight: [[2.00000001]] Bias: [0.99999998]\n",
      "Step: 4540 Loss: 9.799812583849694e-17 Weight: [[2.00000001]] Bias: [0.99999998]\n",
      "Step: 4550 Loss: 9.148277124749643e-17 Weight: [[2.00000001]] Bias: [0.99999998]\n",
      "Step: 4560 Loss: 8.540057608595107e-17 Weight: [[2.00000001]] Bias: [0.99999998]\n",
      "Step: 4570 Loss: 7.972275902006667e-17 Weight: [[2.00000001]] Bias: [0.99999998]\n",
      "Step: 4580 Loss: 7.442243444950893e-17 Weight: [[2.00000001]] Bias: [0.99999998]\n",
      "Step: 4590 Loss: 6.947448989877232e-17 Weight: [[2.00000001]] Bias: [0.99999998]\n",
      "Step: 4600 Loss: 6.485551015604104e-17 Weight: [[2.00000001]] Bias: [0.99999998]\n",
      "Step: 4610 Loss: 6.05436246501208e-17 Weight: [[2.00000001]] Bias: [0.99999998]\n",
      "Step: 4620 Loss: 5.651840827383751e-17 Weight: [[2.]] Bias: [0.99999998]\n",
      "Step: 4630 Loss: 5.276081110433844e-17 Weight: [[2.]] Bias: [0.99999998]\n",
      "Step: 4640 Loss: 4.9253037910115023e-17 Weight: [[2.]] Bias: [0.99999998]\n",
      "Step: 4650 Loss: 4.597846855822386e-17 Weight: [[2.]] Bias: [0.99999998]\n",
      "Step: 4660 Loss: 4.29216096903109e-17 Weight: [[2.]] Bias: [0.99999998]\n",
      "Step: 4670 Loss: 4.006798745998409e-17 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4680 Loss: 3.740408739327062e-17 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4690 Loss: 3.49172905836942e-17 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4700 Loss: 3.259583191078971e-17 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4710 Loss: 3.04287140171665e-17 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4720 Loss: 2.840567265883079e-17 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4730 Loss: 2.6517135984668655e-17 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4740 Loss: 2.475415638185252e-17 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4750 Loss: 2.31083874546821e-17 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4760 Loss: 2.1572039018390736e-17 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4770 Loss: 2.013782861369683e-17 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4780 Loss: 1.8798975329090304e-17 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4790 Loss: 1.7549131733829e-17 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4800 Loss: 1.6382389592540174e-17 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4810 Loss: 1.52932128128513e-17 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4820 Loss: 1.4276451349053195e-17 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4830 Loss: 1.3327288106940013e-17 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4840 Loss: 1.2441228618073937e-17 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4850 Loss: 1.1614077994134958e-17 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4860 Loss: 1.0841923452725029e-17 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4870 Loss: 1.0121102731775513e-17 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4880 Loss: 9.448202990862816e-18 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4890 Loss: 8.820044775318536e-18 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4900 Loss: 8.233649327874605e-18 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4910 Loss: 7.686239156084827e-18 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4920 Loss: 7.17522222858018e-18 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4930 Loss: 6.698182025361782e-18 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4940 Loss: 6.2528561401028916e-18 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4950 Loss: 5.837136435664365e-18 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4960 Loss: 5.449056927721578e-18 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4970 Loss: 5.086778136508315e-18 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4980 Loss: 4.748586575123526e-18 Weight: [[2.]] Bias: [0.99999999]\n",
      "Step: 4990 Loss: 4.432878368688452e-18 Weight: [[2.]] Bias: [1.]\n",
      "Step: 5000 Loss: 4.13816119561443e-18 Weight: [[2.]] Bias: [1.]\n"
     ]
    }
   ],
   "source": [
    "# Training Loof\n",
    "\n",
    "learning_rate = 1e-2\n",
    "cost_list = []\n",
    "\n",
    "f = lambda x: loss_func(x_data, t_data)\n",
    "print(\"Initial Loss:\", loss_func(x_data, t_data), \"Weight:\", w, \"Bias:\", b)\n",
    "\n",
    "# Gradient Descent\n",
    "for step in range(5001):\n",
    "    w -= learning_rate * numerical_derivative(f, w)\n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "    cost = loss_func(x_data, t_data)\n",
    "    cost_list.append([step, cost])\n",
    "\n",
    "    if step % 10 == 0:\n",
    "        print(\"Step:\", step, \"Loss:\", cost, \"Weight:\", w, \"Bias:\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c281618f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6, 7, 8에 대한 예측값: [13.         15.         17.00000001]\n"
     ]
    }
   ],
   "source": [
    "predicted = predict(np.array([[6], [7], [8]]))\n",
    "print(\"6, 7, 8에 대한 예측값:\", predicted.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5b75ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Step')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(cost_list)[:, 0], np.array(cost_list)[:, 1])\n",
    "plt.xlabel('Step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83ea8772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 73.  80.  75.]\n",
      " [ 93.  88.  93.]\n",
      " [ 89.  91.  90.]\n",
      " [ 96.  98. 100.]\n",
      " [ 73.  66.  70.]]\n",
      "[[152.]\n",
      " [185.]\n",
      " [180.]\n",
      " [196.]\n",
      " [142.]]\n",
      "(5, 3) (5, 1)\n"
     ]
    }
   ],
   "source": [
    "# 다중선형회귀(다항모형)\n",
    "\n",
    "x_data1 = [[73., 80., 75.], [93., 88., 93.], [89., 91., 90.], [96., 98., 100.], [73., 66., 70.]] \n",
    "t_data1 = [[152.],[185.],[180.],[196.],[142.]]\n",
    "\n",
    "x_data = np.array(x_data1)\n",
    "t_data = np.array(t_data1)\n",
    "\n",
    "print(x_data)\n",
    "print(t_data)\n",
    "print(x_data.shape, t_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "604a65fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.81421871]\n",
      " [0.37287863]\n",
      " [0.0252036 ]] [0.30379794]\n"
     ]
    }
   ],
   "source": [
    "w = np.random.rand(3, 1)\n",
    "b = np.random.rand(1)\n",
    "print(w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ac0a562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Loss: 4687.87832904448 Weight: [[0.81421871]\n",
      " [0.37287863]\n",
      " [0.0252036 ]] Bias: [0.30379794]\n"
     ]
    }
   ],
   "source": [
    "# Training Loof\n",
    "\n",
    "learning_rate = 1e-6\n",
    "cost_list = []\n",
    "\n",
    "f = lambda x: loss_func(x_data, t_data)\n",
    "print(\"Initial Loss:\", loss_func(x_data, t_data), \"Weight:\", w, \"Bias:\", b)\n",
    "\n",
    "# # Gradient Descent\n",
    "# step = 0\n",
    "# while True:\n",
    "#     step += 1\n",
    "#     w -= learning_rate * numerical_derivative(f, w)\n",
    "#     b -= learning_rate * numerical_derivative(f, b)\n",
    "#     cost = loss_func(x_data, t_data)\n",
    "#     cost_list.append([step, cost])\n",
    "\n",
    "#     if step % 1000 == 0:\n",
    "#         print(\"Step:\", step, \"Loss:\", cost)\n",
    "#         print(\"Weight:\", w)\n",
    "#         print(\"Bias:\", b)\n",
    "\n",
    "#     if cost < 0.15: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29ba3de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.array(cost_list)[:, 0], np.array(cost_list)[:, 1])\n",
    "# plt.xlabel('Step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fa2f776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 73,  80,  75, 152],\n",
       "       [ 93,  88,  93, 185],\n",
       "       [ 89,  91,  90, 180],\n",
       "       [ 96,  98, 100, 196],\n",
       "       [ 73,  66,  70, 142],\n",
       "       [ 53,  46,  55, 101],\n",
       "       [ 69,  74,  77, 149],\n",
       "       [ 47,  56,  60, 115],\n",
       "       [ 87,  79,  90, 175],\n",
       "       [ 79,  70,  88, 164],\n",
       "       [ 69,  70,  73, 141],\n",
       "       [ 70,  65,  74, 141],\n",
       "       [ 93,  95,  91, 184],\n",
       "       [ 79,  80,  73, 152],\n",
       "       [ 70,  73,  78, 148],\n",
       "       [ 93,  89,  96, 192],\n",
       "       [ 78,  75,  68, 147],\n",
       "       [ 81,  90,  93, 183],\n",
       "       [ 88,  92,  86, 177],\n",
       "       [ 78,  83,  77, 159],\n",
       "       [ 82,  86,  90, 177],\n",
       "       [ 86,  82,  89, 175],\n",
       "       [ 78,  83,  85, 175],\n",
       "       [ 76,  83,  71, 149],\n",
       "       [ 96,  93,  95, 192]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  실습\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/data-01-test-score.csv', header=None)\n",
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79699f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = df.values[:, :-1]\n",
    "t_data = df.values[:, -1].reshape(-1, 1)    # 행은 그냥 알아서 맞춰달라는 뜻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92fa5c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Loss: 35.560807110183546 Weight: [[0.7492305 ]\n",
      " [0.93851102]\n",
      " [0.30124831]] Bias: [0.65424223]\n",
      "Step: 100 Loss: 26.185637577374877\n",
      "Weight: [[0.76029201]\n",
      " [0.94847085]\n",
      " [0.31700056]]\n",
      "Bias: [0.65439154]\n",
      "Step: 200 Loss: 26.015541015325837\n",
      "Weight: [[0.75943372]\n",
      " [0.94645317]\n",
      " [0.32047111]]\n",
      "Bias: [0.65439881]\n",
      "Step: 300 Loss: 25.849971865055323\n",
      "Weight: [[0.7583597 ]\n",
      " [0.94422643]\n",
      " [0.32370303]]\n",
      "Bias: [0.65440338]\n",
      "Step: 400 Loss: 25.685821068065128\n",
      "Weight: [[0.75728468]\n",
      " [0.9420065 ]\n",
      " [0.32691732]]\n",
      "Bias: [0.65440781]\n",
      "Step: 500 Loss: 25.52307527721621\n",
      "Weight: [[0.75621258]\n",
      " [0.93979727]\n",
      " [0.33011807]]\n",
      "Bias: [0.65441215]\n",
      "Step: 600 Loss: 25.361722294898737\n",
      "Weight: [[0.75514347]\n",
      " [0.93759878]\n",
      " [0.33330543]]\n",
      "Bias: [0.65441639]\n",
      "Step: 700 Loss: 25.201750030622396\n",
      "Weight: [[0.75407733]\n",
      " [0.93541098]\n",
      " [0.33647945]]\n",
      "Bias: [0.65442053]\n",
      "Step: 800 Loss: 25.04314649972806\n",
      "Weight: [[0.75301417]\n",
      " [0.93323381]\n",
      " [0.33964019]]\n",
      "Bias: [0.65442458]\n",
      "Step: 900 Loss: 24.885899822457453\n",
      "Weight: [[0.75195398]\n",
      " [0.93106723]\n",
      " [0.3427877 ]]\n",
      "Bias: [0.65442854]\n",
      "Step: 1000 Loss: 24.729998223029934\n",
      "Weight: [[0.75089673]\n",
      " [0.92891118]\n",
      " [0.34592205]]\n",
      "Bias: [0.65443241]\n",
      "Step: 1100 Loss: 24.575430028728174\n",
      "Weight: [[0.74984243]\n",
      " [0.92676563]\n",
      " [0.3490433 ]]\n",
      "Bias: [0.65443618]\n",
      "Step: 1200 Loss: 24.422183668992\n",
      "Weight: [[0.74879107]\n",
      " [0.92463051]\n",
      " [0.35215148]]\n",
      "Bias: [0.65443986]\n",
      "Step: 1300 Loss: 24.270247674519556\n",
      "Weight: [[0.74774264]\n",
      " [0.92250578]\n",
      " [0.35524667]]\n",
      "Bias: [0.65444345]\n",
      "Step: 1400 Loss: 24.119610676377032\n",
      "Weight: [[0.74669712]\n",
      " [0.92039139]\n",
      " [0.35832892]]\n",
      "Bias: [0.65444695]\n",
      "Step: 1500 Loss: 23.97026140511615\n",
      "Weight: [[0.74565452]\n",
      " [0.9182873 ]\n",
      " [0.36139828]]\n",
      "Bias: [0.65445036]\n",
      "Step: 1600 Loss: 23.822188689899125\n",
      "Weight: [[0.74461481]\n",
      " [0.91619345]\n",
      " [0.36445481]]\n",
      "Bias: [0.65445367]\n",
      "Step: 1700 Loss: 23.67538145763125\n",
      "Weight: [[0.743578  ]\n",
      " [0.9141098 ]\n",
      " [0.36749857]]\n",
      "Bias: [0.6544569]\n",
      "Step: 1800 Loss: 23.52982873210215\n",
      "Weight: [[0.74254408]\n",
      " [0.9120363 ]\n",
      " [0.3705296 ]]\n",
      "Bias: [0.65446004]\n",
      "Step: 1900 Loss: 23.385519633132894\n",
      "Weight: [[0.74151303]\n",
      " [0.90997291]\n",
      " [0.37354796]]\n",
      "Bias: [0.65446308]\n",
      "Step: 2000 Loss: 23.24244337573219\n",
      "Weight: [[0.74048484]\n",
      " [0.90791957]\n",
      " [0.37655372]]\n",
      "Bias: [0.65446604]\n",
      "Step: 2100 Loss: 23.10058926925946\n",
      "Weight: [[0.73945952]\n",
      " [0.90587624]\n",
      " [0.37954691]]\n",
      "Bias: [0.65446891]\n",
      "Step: 2200 Loss: 22.959946716595073\n",
      "Weight: [[0.73843705]\n",
      " [0.90384288]\n",
      " [0.3825276 ]]\n",
      "Bias: [0.65447169]\n",
      "Step: 2300 Loss: 22.82050521331788\n",
      "Weight: [[0.73741742]\n",
      " [0.90181943]\n",
      " [0.38549583]]\n",
      "Bias: [0.65447438]\n",
      "Step: 2400 Loss: 22.682254346890744\n",
      "Weight: [[0.73640062]\n",
      " [0.89980585]\n",
      " [0.38845167]]\n",
      "Bias: [0.65447699]\n",
      "Step: 2500 Loss: 22.545183795851937\n",
      "Weight: [[0.73538665]\n",
      " [0.89780209]\n",
      " [0.39139516]]\n",
      "Bias: [0.6544795]\n",
      "Step: 2600 Loss: 22.409283329015253\n",
      "Weight: [[0.7343755 ]\n",
      " [0.89580811]\n",
      " [0.39432636]]\n",
      "Bias: [0.65448193]\n",
      "Step: 2700 Loss: 22.274542804675846\n",
      "Weight: [[0.73336716]\n",
      " [0.89382387]\n",
      " [0.39724532]]\n",
      "Bias: [0.65448428]\n",
      "Step: 2800 Loss: 22.14095216982366\n",
      "Weight: [[0.73236161]\n",
      " [0.89184931]\n",
      " [0.4001521 ]]\n",
      "Bias: [0.65448654]\n",
      "Step: 2900 Loss: 22.008501459363774\n",
      "Weight: [[0.73135886]\n",
      " [0.8898844 ]\n",
      " [0.40304674]]\n",
      "Bias: [0.65448871]\n",
      "Step: 3000 Loss: 21.877180795343524\n",
      "Weight: [[0.73035889]\n",
      " [0.88792908]\n",
      " [0.40592929]]\n",
      "Bias: [0.65449079]\n",
      "Step: 3100 Loss: 21.746980386186728\n",
      "Weight: [[0.7293617 ]\n",
      " [0.88598331]\n",
      " [0.40879981]]\n",
      "Bias: [0.6544928]\n",
      "Step: 3200 Loss: 21.617890525933696\n",
      "Weight: [[0.72836728]\n",
      " [0.88404706]\n",
      " [0.41165836]]\n",
      "Bias: [0.65449471]\n",
      "Step: 3300 Loss: 21.489901593489726\n",
      "Weight: [[0.72737562]\n",
      " [0.88212026]\n",
      " [0.41450497]]\n",
      "Bias: [0.65449654]\n",
      "Step: 3400 Loss: 21.363004051878175\n",
      "Weight: [[0.7263867 ]\n",
      " [0.88020289]\n",
      " [0.41733971]]\n",
      "Bias: [0.65449829]\n",
      "Step: 3500 Loss: 21.237188447501627\n",
      "Weight: [[0.72540054]\n",
      " [0.87829489]\n",
      " [0.42016262]]\n",
      "Bias: [0.65449996]\n",
      "Step: 3600 Loss: 21.11244540940899\n",
      "Weight: [[0.7244171 ]\n",
      " [0.87639622]\n",
      " [0.42297375]]\n",
      "Bias: [0.65450154]\n",
      "Step: 3700 Loss: 20.988765648568833\n",
      "Weight: [[0.7234364 ]\n",
      " [0.87450684]\n",
      " [0.42577316]]\n",
      "Bias: [0.65450303]\n",
      "Step: 3800 Loss: 20.86613995714988\n",
      "Weight: [[0.72245841]\n",
      " [0.87262671]\n",
      " [0.42856089]]\n",
      "Bias: [0.65450445]\n",
      "Step: 3900 Loss: 20.744559207806866\n",
      "Weight: [[0.72148314]\n",
      " [0.87075577]\n",
      " [0.43133699]]\n",
      "Bias: [0.65450578]\n",
      "Step: 4000 Loss: 20.624014352973454\n",
      "Weight: [[0.72051057]\n",
      " [0.868894  ]\n",
      " [0.43410152]]\n",
      "Bias: [0.65450703]\n",
      "Step: 4100 Loss: 20.50449642416117\n",
      "Weight: [[0.71954069]\n",
      " [0.86704134]\n",
      " [0.43685453]]\n",
      "Bias: [0.6545082]\n",
      "Step: 4200 Loss: 20.38599653126435\n",
      "Weight: [[0.7185735 ]\n",
      " [0.86519775]\n",
      " [0.43959605]]\n",
      "Bias: [0.65450929]\n",
      "Step: 4300 Loss: 20.26850586187147\n",
      "Weight: [[0.71760899]\n",
      " [0.8633632 ]\n",
      " [0.44232615]]\n",
      "Bias: [0.6545103]\n",
      "Step: 4400 Loss: 20.15201568058225\n",
      "Weight: [[0.71664715]\n",
      " [0.86153763]\n",
      " [0.44504487]]\n",
      "Bias: [0.65451122]\n",
      "Step: 4500 Loss: 20.036517328330977\n",
      "Weight: [[0.71568798]\n",
      " [0.85972101]\n",
      " [0.44775225]]\n",
      "Bias: [0.65451207]\n",
      "Step: 4600 Loss: 19.922002221715992\n",
      "Weight: [[0.71473146]\n",
      " [0.8579133 ]\n",
      " [0.45044836]]\n",
      "Bias: [0.65451283]\n",
      "Step: 4700 Loss: 19.808461852334442\n",
      "Weight: [[0.71377759]\n",
      " [0.85611445]\n",
      " [0.45313323]]\n",
      "Bias: [0.65451352]\n",
      "Step: 4800 Loss: 19.695887786123784\n",
      "Weight: [[0.71282637]\n",
      " [0.85432442]\n",
      " [0.45580691]]\n",
      "Bias: [0.65451413]\n",
      "Step: 4900 Loss: 19.584271662708176\n",
      "Weight: [[0.71187777]\n",
      " [0.85254317]\n",
      " [0.45846946]]\n",
      "Bias: [0.65451465]\n",
      "Step: 5000 Loss: 19.473605194751237\n",
      "Weight: [[0.7109318 ]\n",
      " [0.85077066]\n",
      " [0.46112091]]\n",
      "Bias: [0.6545151]\n",
      "Step: 5100 Loss: 19.363880167314562\n",
      "Weight: [[0.70998845]\n",
      " [0.84900685]\n",
      " [0.46376133]]\n",
      "Bias: [0.65451547]\n",
      "Step: 5200 Loss: 19.25508843722123\n",
      "Weight: [[0.7090477 ]\n",
      " [0.8472517 ]\n",
      " [0.46639074]]\n",
      "Bias: [0.65451577]\n",
      "Step: 5300 Loss: 19.14722193242575\n",
      "Weight: [[0.70810956]\n",
      " [0.84550516]\n",
      " [0.46900921]]\n",
      "Bias: [0.65451598]\n",
      "Step: 5400 Loss: 19.040272651389152\n",
      "Weight: [[0.70717401]\n",
      " [0.8437672 ]\n",
      " [0.47161677]]\n",
      "Bias: [0.65451612]\n",
      "Step: 5500 Loss: 18.934232662459195\n",
      "Weight: [[0.70624105]\n",
      " [0.84203778]\n",
      " [0.47421348]]\n",
      "Bias: [0.65451618]\n",
      "Step: 5600 Loss: 18.829094103257138\n",
      "Weight: [[0.70531067]\n",
      " [0.84031686]\n",
      " [0.47679938]]\n",
      "Bias: [0.65451616]\n",
      "Step: 5700 Loss: 18.72484918006857\n",
      "Weight: [[0.70438286]\n",
      " [0.83860439]\n",
      " [0.47937452]]\n",
      "Bias: [0.65451607]\n",
      "Step: 5800 Loss: 18.621490167240587\n",
      "Weight: [[0.70345762]\n",
      " [0.83690035]\n",
      " [0.48193894]]\n",
      "Bias: [0.6545159]\n",
      "Step: 5900 Loss: 18.519009406584086\n",
      "Weight: [[0.70253493]\n",
      " [0.83520468]\n",
      " [0.48449269]]\n",
      "Bias: [0.65451566]\n",
      "Step: 6000 Loss: 18.417399306780784\n",
      "Weight: [[0.70161479]\n",
      " [0.83351735]\n",
      " [0.48703581]]\n",
      "Bias: [0.65451534]\n",
      "Step: 6100 Loss: 18.316652342796434\n",
      "Weight: [[0.7006972 ]\n",
      " [0.83183832]\n",
      " [0.48956835]]\n",
      "Bias: [0.65451494]\n",
      "Step: 6200 Loss: 18.216761055298136\n",
      "Weight: [[0.69978213]\n",
      " [0.83016755]\n",
      " [0.49209036]]\n",
      "Bias: [0.65451447]\n",
      "Step: 6300 Loss: 18.11771805007757\n",
      "Weight: [[0.6988696 ]\n",
      " [0.828505  ]\n",
      " [0.49460188]]\n",
      "Bias: [0.65451393]\n",
      "Step: 6400 Loss: 18.01951599747914\n",
      "Weight: [[0.69795958]\n",
      " [0.82685064]\n",
      " [0.49710295]]\n",
      "Bias: [0.65451331]\n",
      "Step: 6500 Loss: 17.92214763183291\n",
      "Weight: [[0.69705208]\n",
      " [0.82520443]\n",
      " [0.49959362]]\n",
      "Bias: [0.65451262]\n",
      "Step: 6600 Loss: 17.825605750892535\n",
      "Weight: [[0.69614708]\n",
      " [0.82356632]\n",
      " [0.50207393]]\n",
      "Bias: [0.65451185]\n",
      "Step: 6700 Loss: 17.729883215278786\n",
      "Weight: [[0.69524457]\n",
      " [0.82193628]\n",
      " [0.50454393]]\n",
      "Bias: [0.65451101]\n",
      "Step: 6800 Loss: 17.634972947926954\n",
      "Weight: [[0.69434456]\n",
      " [0.82031427]\n",
      " [0.50700367]]\n",
      "Bias: [0.6545101]\n",
      "Step: 6900 Loss: 17.54086793354006\n",
      "Weight: [[0.69344703]\n",
      " [0.81870026]\n",
      " [0.50945318]]\n",
      "Bias: [0.65450912]\n",
      "Step: 7000 Loss: 17.447561218046243\n",
      "Weight: [[0.69255198]\n",
      " [0.81709421]\n",
      " [0.5118925 ]]\n",
      "Bias: [0.65450806]\n",
      "Step: 7100 Loss: 17.355045908061296\n",
      "Weight: [[0.69165939]\n",
      " [0.81549607]\n",
      " [0.5143217 ]]\n",
      "Bias: [0.65450693]\n",
      "Step: 7200 Loss: 17.26331517035615\n",
      "Weight: [[0.69076927]\n",
      " [0.81390582]\n",
      " [0.51674079]]\n",
      "Bias: [0.65450573]\n",
      "Step: 7300 Loss: 17.172362231327714\n",
      "Weight: [[0.6898816 ]\n",
      " [0.81232341]\n",
      " [0.51914984]]\n",
      "Bias: [0.65450446]\n",
      "Step: 7400 Loss: 17.0821803764765\n",
      "Weight: [[0.68899638]\n",
      " [0.81074881]\n",
      " [0.52154888]]\n",
      "Bias: [0.65450311]\n",
      "Step: 7500 Loss: 16.992762949886988\n",
      "Weight: [[0.6881136 ]\n",
      " [0.80918199]\n",
      " [0.52393795]]\n",
      "Bias: [0.6545017]\n",
      "Step: 7600 Loss: 16.904103353713722\n",
      "Weight: [[0.68723325]\n",
      " [0.8076229 ]\n",
      " [0.5263171 ]]\n",
      "Bias: [0.65450021]\n",
      "Step: 7700 Loss: 16.816195047671414\n",
      "Weight: [[0.68635532]\n",
      " [0.80607151]\n",
      " [0.52868637]]\n",
      "Bias: [0.65449866]\n",
      "Step: 7800 Loss: 16.729031548529473\n",
      "Weight: [[0.68547982]\n",
      " [0.80452778]\n",
      " [0.5310458 ]]\n",
      "Bias: [0.65449703]\n",
      "Step: 7900 Loss: 16.642606429611362\n",
      "Weight: [[0.68460672]\n",
      " [0.80299168]\n",
      " [0.53339543]]\n",
      "Bias: [0.65449533]\n",
      "Step: 8000 Loss: 16.556913320298207\n",
      "Weight: [[0.68373603]\n",
      " [0.80146317]\n",
      " [0.53573531]]\n",
      "Bias: [0.65449357]\n",
      "Step: 8100 Loss: 16.47194590553644\n",
      "Weight: [[0.68286774]\n",
      " [0.79994222]\n",
      " [0.53806548]]\n",
      "Bias: [0.65449174]\n",
      "Step: 8200 Loss: 16.387697925350267\n",
      "Weight: [[0.68200184]\n",
      " [0.79842879]\n",
      " [0.54038598]]\n",
      "Bias: [0.65448983]\n",
      "Step: 8300 Loss: 16.304163174358454\n",
      "Weight: [[0.68113832]\n",
      " [0.79692284]\n",
      " [0.54269684]]\n",
      "Bias: [0.65448786]\n",
      "Step: 8400 Loss: 16.22133550129479\n",
      "Weight: [[0.68027718]\n",
      " [0.79542435]\n",
      " [0.54499812]]\n",
      "Bias: [0.65448582]\n",
      "Step: 8500 Loss: 16.139208808533322\n",
      "Weight: [[0.67941841]\n",
      " [0.79393327]\n",
      " [0.54728985]]\n",
      "Bias: [0.65448371]\n",
      "Step: 8600 Loss: 16.05777705161763\n",
      "Weight: [[0.678562  ]\n",
      " [0.79244957]\n",
      " [0.54957207]]\n",
      "Bias: [0.65448154]\n",
      "Step: 8700 Loss: 15.977034238794031\n",
      "Weight: [[0.67770794]\n",
      " [0.79097321]\n",
      " [0.55184482]]\n",
      "Bias: [0.65447929]\n",
      "Step: 8800 Loss: 15.89697443054935\n",
      "Weight: [[0.67685624]\n",
      " [0.78950417]\n",
      " [0.55410814]]\n",
      "Bias: [0.65447698]\n",
      "Step: 8900 Loss: 15.81759173915217\n",
      "Weight: [[0.67600688]\n",
      " [0.7880424 ]\n",
      " [0.55636208]]\n",
      "Bias: [0.65447461]\n",
      "Step: 9000 Loss: 15.73888032819884\n",
      "Weight: [[0.67515985]\n",
      " [0.78658788]\n",
      " [0.55860668]]\n",
      "Bias: [0.65447216]\n",
      "Step: 9100 Loss: 15.660834412162503\n",
      "Weight: [[0.67431515]\n",
      " [0.78514056]\n",
      " [0.56084196]]\n",
      "Bias: [0.65446965]\n",
      "Step: 9200 Loss: 15.583448255947204\n",
      "Weight: [[0.67347277]\n",
      " [0.78370042]\n",
      " [0.56306798]]\n",
      "Bias: [0.65446708]\n",
      "Step: 9300 Loss: 15.506716174445138\n",
      "Weight: [[0.67263271]\n",
      " [0.78226742]\n",
      " [0.56528477]]\n",
      "Bias: [0.65446444]\n",
      "Step: 9400 Loss: 15.430632532098175\n",
      "Weight: [[0.67179496]\n",
      " [0.78084153]\n",
      " [0.56749238]]\n",
      "Bias: [0.65446173]\n",
      "Step: 9500 Loss: 15.35519174246302\n",
      "Weight: [[0.67095951]\n",
      " [0.77942272]\n",
      " [0.56969083]]\n",
      "Bias: [0.65445896]\n",
      "Step: 9600 Loss: 15.280388267780273\n",
      "Weight: [[0.67012635]\n",
      " [0.77801094]\n",
      " [0.57188017]]\n",
      "Bias: [0.65445612]\n",
      "Step: 9700 Loss: 15.206216618547609\n",
      "Weight: [[0.66929549]\n",
      " [0.77660617]\n",
      " [0.57406045]]\n",
      "Bias: [0.65445321]\n",
      "Step: 9800 Loss: 15.132671353096008\n",
      "Weight: [[0.6684669 ]\n",
      " [0.77520838]\n",
      " [0.57623169]]\n",
      "Bias: [0.65445025]\n",
      "Step: 9900 Loss: 15.059747077170512\n",
      "Weight: [[0.66764059]\n",
      " [0.77381753]\n",
      " [0.57839393]]\n",
      "Bias: [0.65444722]\n",
      "Step: 10000 Loss: 14.987438443514034\n",
      "Weight: [[0.66681655]\n",
      " [0.77243359]\n",
      " [0.58054722]]\n",
      "Bias: [0.65444412]\n",
      "Step: 10100 Loss: 14.915740151455232\n",
      "Weight: [[0.66599477]\n",
      " [0.77105652]\n",
      " [0.58269159]]\n",
      "Bias: [0.65444096]\n",
      "Step: 10200 Loss: 14.84464694649981\n",
      "Weight: [[0.66517524]\n",
      " [0.7696863 ]\n",
      " [0.58482708]]\n",
      "Bias: [0.65443774]\n",
      "Step: 10300 Loss: 14.774153619925633\n",
      "Weight: [[0.66435796]\n",
      " [0.7683229 ]\n",
      " [0.58695373]]\n",
      "Bias: [0.65443446]\n",
      "Step: 10400 Loss: 14.704255008381\n",
      "Weight: [[0.66354293]\n",
      " [0.76696627]\n",
      " [0.58907158]]\n",
      "Bias: [0.65443111]\n",
      "Step: 10500 Loss: 14.634945993486904\n",
      "Weight: [[0.66273013]\n",
      " [0.76561639]\n",
      " [0.59118066]]\n",
      "Bias: [0.6544277]\n",
      "Step: 10600 Loss: 14.566221501442678\n",
      "Weight: [[0.66191956]\n",
      " [0.76427323]\n",
      " [0.59328101]]\n",
      "Bias: [0.65442422]\n",
      "Step: 10700 Loss: 14.498076502634792\n",
      "Weight: [[0.66111122]\n",
      " [0.76293675]\n",
      " [0.59537267]]\n",
      "Bias: [0.65442069]\n",
      "Step: 10800 Loss: 14.430506011249546\n",
      "Weight: [[0.66030509]\n",
      " [0.76160693]\n",
      " [0.59745567]]\n",
      "Bias: [0.65441709]\n",
      "Step: 10900 Loss: 14.36350508488894\n",
      "Weight: [[0.65950117]\n",
      " [0.76028373]\n",
      " [0.59953005]]\n",
      "Bias: [0.65441343]\n",
      "Step: 11000 Loss: 14.297068824189678\n",
      "Weight: [[0.65869945]\n",
      " [0.75896712]\n",
      " [0.60159585]]\n",
      "Bias: [0.65440971]\n",
      "Step: 11100 Loss: 14.231192372446365\n",
      "Weight: [[0.65789994]\n",
      " [0.75765707]\n",
      " [0.60365311]]\n",
      "Bias: [0.65440593]\n",
      "Step: 11200 Loss: 14.165870915236924\n",
      "Weight: [[0.65710261]\n",
      " [0.75635355]\n",
      " [0.60570185]]\n",
      "Bias: [0.65440209]\n",
      "Step: 11300 Loss: 14.101099680052096\n",
      "Weight: [[0.65630747]\n",
      " [0.75505653]\n",
      " [0.60774213]]\n",
      "Bias: [0.65439819]\n",
      "Step: 11400 Loss: 14.03687393592802\n",
      "Weight: [[0.6555145 ]\n",
      " [0.75376597]\n",
      " [0.60977397]]\n",
      "Bias: [0.65439422]\n",
      "Step: 11500 Loss: 13.973188993081713\n",
      "Weight: [[0.65472371]\n",
      " [0.75248186]\n",
      " [0.6117974 ]]\n",
      "Bias: [0.6543902]\n",
      "Step: 11600 Loss: 13.910040202550324\n",
      "Weight: [[0.65393508]\n",
      " [0.75120415]\n",
      " [0.61381247]]\n",
      "Bias: [0.65438612]\n",
      "Step: 11700 Loss: 13.847422955833093\n",
      "Weight: [[0.65314861]\n",
      " [0.74993282]\n",
      " [0.61581922]]\n",
      "Bias: [0.65438198]\n",
      "Step: 11800 Loss: 13.785332684536716\n",
      "Weight: [[0.6523643 ]\n",
      " [0.74866783]\n",
      " [0.61781766]]\n",
      "Bias: [0.65437778]\n",
      "Step: 11900 Loss: 13.723764860023575\n",
      "Weight: [[0.65158213]\n",
      " [0.74740916]\n",
      " [0.61980785]]\n",
      "Bias: [0.65437351]\n",
      "Step: 12000 Loss: 13.662714993063673\n",
      "Weight: [[0.65080211]\n",
      " [0.74615678]\n",
      " [0.62178982]]\n",
      "Bias: [0.6543692]\n",
      "Step: 12100 Loss: 13.602178633488613\n",
      "Weight: [[0.65002421]\n",
      " [0.74491066]\n",
      " [0.62376359]]\n",
      "Bias: [0.65436482]\n",
      "Step: 12200 Loss: 13.542151369849593\n",
      "Weight: [[0.64924845]\n",
      " [0.74367076]\n",
      " [0.62572922]]\n",
      "Bias: [0.65436038]\n",
      "Step: 12300 Loss: 13.482628829078138\n",
      "Weight: [[0.64847481]\n",
      " [0.74243706]\n",
      " [0.62768672]]\n",
      "Bias: [0.65435589]\n",
      "Step: 12400 Loss: 13.423606676149229\n",
      "Weight: [[0.64770329]\n",
      " [0.74120954]\n",
      " [0.62963614]]\n",
      "Bias: [0.65435133]\n",
      "Step: 12500 Loss: 13.365080613748427\n",
      "Weight: [[0.64693387]\n",
      " [0.73998815]\n",
      " [0.63157751]]\n",
      "Bias: [0.65434672]\n",
      "Step: 12600 Loss: 13.30704638194091\n",
      "Weight: [[0.64616656]\n",
      " [0.73877287]\n",
      " [0.63351086]]\n",
      "Bias: [0.65434206]\n",
      "Step: 12700 Loss: 13.249499757844251\n",
      "Weight: [[0.64540135]\n",
      " [0.73756368]\n",
      " [0.63543623]]\n",
      "Bias: [0.65433733]\n",
      "Step: 12800 Loss: 13.192436555303559\n",
      "Weight: [[0.64463823]\n",
      " [0.73636054]\n",
      " [0.63735365]]\n",
      "Bias: [0.65433255]\n",
      "Step: 12900 Loss: 13.135852624569463\n",
      "Weight: [[0.64387719]\n",
      " [0.73516342]\n",
      " [0.63926316]]\n",
      "Bias: [0.65432771]\n",
      "Step: 13000 Loss: 13.079743851979595\n",
      "Weight: [[0.64311824]\n",
      " [0.7339723 ]\n",
      " [0.64116479]]\n",
      "Bias: [0.65432282]\n",
      "Step: 13100 Loss: 13.024106159641757\n",
      "Weight: [[0.64236135]\n",
      " [0.73278715]\n",
      " [0.64305857]]\n",
      "Bias: [0.65431786]\n",
      "Step: 13200 Loss: 12.968935505121031\n",
      "Weight: [[0.64160654]\n",
      " [0.73160794]\n",
      " [0.64494454]]\n",
      "Bias: [0.65431286]\n",
      "Step: 13300 Loss: 12.914227881128868\n",
      "Weight: [[0.64085379]\n",
      " [0.73043465]\n",
      " [0.64682272]]\n",
      "Bias: [0.65430779]\n",
      "Step: 13400 Loss: 12.859979315215085\n",
      "Weight: [[0.64010309]\n",
      " [0.72926723]\n",
      " [0.64869316]]\n",
      "Bias: [0.65430268]\n",
      "Step: 13500 Loss: 12.806185869462881\n",
      "Weight: [[0.63935445]\n",
      " [0.72810568]\n",
      " [0.65055588]]\n",
      "Bias: [0.6542975]\n",
      "Step: 13600 Loss: 12.752843640186194\n",
      "Weight: [[0.63860785]\n",
      " [0.72694995]\n",
      " [0.65241093]]\n",
      "Bias: [0.65429227]\n",
      "Step: 13700 Loss: 12.699948757629766\n",
      "Weight: [[0.63786328]\n",
      " [0.72580002]\n",
      " [0.65425832]]\n",
      "Bias: [0.65428699]\n",
      "Step: 13800 Loss: 12.647497385672073\n",
      "Weight: [[0.63712075]\n",
      " [0.72465587]\n",
      " [0.65609809]]\n",
      "Bias: [0.65428165]\n",
      "Step: 13900 Loss: 12.595485721530354\n",
      "Weight: [[0.63638025]\n",
      " [0.72351746]\n",
      " [0.65793028]]\n",
      "Bias: [0.65427626]\n",
      "Step: 14000 Loss: 12.543909995469114\n",
      "Weight: [[0.63564176]\n",
      " [0.72238478]\n",
      " [0.65975492]]\n",
      "Bias: [0.65427081]\n",
      "Step: 14100 Loss: 12.492766470510242\n",
      "Weight: [[0.63490529]\n",
      " [0.72125778]\n",
      " [0.66157204]]\n",
      "Bias: [0.65426531]\n",
      "Step: 14200 Loss: 12.44205144214639\n",
      "Weight: [[0.63417084]\n",
      " [0.72013645]\n",
      " [0.66338167]]\n",
      "Bias: [0.65425976]\n",
      "Step: 14300 Loss: 12.391761238056244\n",
      "Weight: [[0.63343838]\n",
      " [0.71902076]\n",
      " [0.66518385]]\n",
      "Bias: [0.65425415]\n",
      "Step: 14400 Loss: 12.34189221782307\n",
      "Weight: [[0.63270792]\n",
      " [0.71791068]\n",
      " [0.66697859]]\n",
      "Bias: [0.65424849]\n",
      "Step: 14500 Loss: 12.292440772654972\n",
      "Weight: [[0.63197945]\n",
      " [0.71680619]\n",
      " [0.66876595]]\n",
      "Bias: [0.65424277]\n",
      "Step: 14600 Loss: 12.243403325108089\n",
      "Weight: [[0.63125297]\n",
      " [0.71570726]\n",
      " [0.67054594]]\n",
      "Bias: [0.654237]\n",
      "Step: 14700 Loss: 12.19477632881216\n",
      "Weight: [[0.63052847]\n",
      " [0.71461386]\n",
      " [0.67231861]]\n",
      "Bias: [0.65423118]\n",
      "Step: 14800 Loss: 12.146556268198285\n",
      "Weight: [[0.62980595]\n",
      " [0.71352596]\n",
      " [0.67408397]]\n",
      "Bias: [0.65422531]\n",
      "Step: 14900 Loss: 12.098739658229274\n",
      "Weight: [[0.62908539]\n",
      " [0.71244355]\n",
      " [0.67584206]]\n",
      "Bias: [0.65421939]\n",
      "Step: 15000 Loss: 12.051323044132339\n",
      "Weight: [[0.6283668 ]\n",
      " [0.71136659]\n",
      " [0.67759292]]\n",
      "Bias: [0.65421341]\n",
      "Step: 15100 Loss: 12.004303001134184\n",
      "Weight: [[0.62765016]\n",
      " [0.71029506]\n",
      " [0.67933657]]\n",
      "Bias: [0.65420738]\n",
      "Step: 15200 Loss: 11.957676134198225\n",
      "Weight: [[0.62693548]\n",
      " [0.70922893]\n",
      " [0.68107305]]\n",
      "Bias: [0.6542013]\n",
      "Step: 15300 Loss: 11.91143907776445\n",
      "Weight: [[0.62622275]\n",
      " [0.70816818]\n",
      " [0.68280237]]\n",
      "Bias: [0.65419517]\n",
      "Step: 15400 Loss: 11.865588495491084\n",
      "Weight: [[0.62551195]\n",
      " [0.70711278]\n",
      " [0.68452458]]\n",
      "Bias: [0.65418898]\n",
      "Step: 15500 Loss: 11.820121079999197\n",
      "Weight: [[0.62480309]\n",
      " [0.70606271]\n",
      " [0.68623971]]\n",
      "Bias: [0.65418275]\n",
      "Step: 15600 Loss: 11.775033552618748\n",
      "Weight: [[0.62409616]\n",
      " [0.70501793]\n",
      " [0.68794778]]\n",
      "Bias: [0.65417647]\n",
      "Step: 15700 Loss: 11.730322663137745\n",
      "Weight: [[0.62339116]\n",
      " [0.70397844]\n",
      " [0.68964883]]\n",
      "Bias: [0.65417013]\n",
      "Step: 15800 Loss: 11.685985189552737\n",
      "Weight: [[0.62268807]\n",
      " [0.7029442 ]\n",
      " [0.69134288]]\n",
      "Bias: [0.65416375]\n",
      "Step: 15900 Loss: 11.642017937822343\n",
      "Weight: [[0.6219869 ]\n",
      " [0.70191518]\n",
      " [0.69302996]]\n",
      "Bias: [0.65415731]\n",
      "Step: 16000 Loss: 11.598417741622065\n",
      "Weight: [[0.62128763]\n",
      " [0.70089136]\n",
      " [0.6947101 ]]\n",
      "Bias: [0.65415083]\n",
      "Step: 16100 Loss: 11.555181462102139\n",
      "Weight: [[0.62059027]\n",
      " [0.69987273]\n",
      " [0.69638334]]\n",
      "Bias: [0.65414429]\n",
      "Step: 16200 Loss: 11.512305987646812\n",
      "Weight: [[0.6198948 ]\n",
      " [0.69885924]\n",
      " [0.69804971]]\n",
      "Bias: [0.65413771]\n",
      "Step: 16300 Loss: 11.469788233636212\n",
      "Weight: [[0.61920123]\n",
      " [0.69785088]\n",
      " [0.69970922]]\n",
      "Bias: [0.65413107]\n",
      "Step: 16400 Loss: 11.427625142210074\n",
      "Weight: [[0.61850954]\n",
      " [0.69684763]\n",
      " [0.70136191]]\n",
      "Bias: [0.65412439]\n",
      "Step: 16500 Loss: 11.385813682033474\n",
      "Weight: [[0.61781973]\n",
      " [0.69584945]\n",
      " [0.70300781]]\n",
      "Bias: [0.65411766]\n",
      "Step: 16600 Loss: 11.344350848064957\n",
      "Weight: [[0.6171318 ]\n",
      " [0.69485633]\n",
      " [0.70464695]]\n",
      "Bias: [0.65411088]\n",
      "Step: 16700 Loss: 11.303233661326173\n",
      "Weight: [[0.61644574]\n",
      " [0.69386824]\n",
      " [0.70627936]]\n",
      "Bias: [0.65410405]\n",
      "Step: 16800 Loss: 11.262459168674184\n",
      "Weight: [[0.61576154]\n",
      " [0.69288516]\n",
      " [0.70790506]]\n",
      "Bias: [0.65409717]\n",
      "Step: 16900 Loss: 11.2220244425753\n",
      "Weight: [[0.6150792 ]\n",
      " [0.69190706]\n",
      " [0.70952409]]\n",
      "Bias: [0.65409024]\n",
      "Step: 17000 Loss: 11.181926580880925\n",
      "Weight: [[0.61439872]\n",
      " [0.69093392]\n",
      " [0.71113646]]\n",
      "Bias: [0.65408327]\n",
      "Step: 17100 Loss: 11.14216270660581\n",
      "Weight: [[0.61372008]\n",
      " [0.68996572]\n",
      " [0.71274222]]\n",
      "Bias: [0.65407625]\n",
      "Step: 17200 Loss: 11.102729967707601\n",
      "Weight: [[0.61304329]\n",
      " [0.68900244]\n",
      " [0.71434139]]\n",
      "Bias: [0.65406918]\n",
      "Step: 17300 Loss: 11.063625536868836\n",
      "Weight: [[0.61236834]\n",
      " [0.68804404]\n",
      " [0.71593399]]\n",
      "Bias: [0.65406206]\n",
      "Step: 17400 Loss: 11.024846611280646\n",
      "Weight: [[0.61169522]\n",
      " [0.6870905 ]\n",
      " [0.71752005]]\n",
      "Bias: [0.6540549]\n",
      "Step: 17500 Loss: 10.986390412428584\n",
      "Weight: [[0.61102392]\n",
      " [0.68614182]\n",
      " [0.71909961]]\n",
      "Bias: [0.65404769]\n",
      "Step: 17600 Loss: 10.948254185879703\n",
      "Weight: [[0.61035445]\n",
      " [0.68519795]\n",
      " [0.72067268]]\n",
      "Bias: [0.65404043]\n",
      "Step: 17700 Loss: 10.910435201072556\n",
      "Weight: [[0.6096868 ]\n",
      " [0.68425888]\n",
      " [0.7222393 ]]\n",
      "Bias: [0.65403313]\n",
      "Step: 17800 Loss: 10.872930751107843\n",
      "Weight: [[0.60902096]\n",
      " [0.68332458]\n",
      " [0.7237995 ]]\n",
      "Bias: [0.65402578]\n",
      "Step: 17900 Loss: 10.8357381525419\n",
      "Weight: [[0.60835692]\n",
      " [0.68239503]\n",
      " [0.7253533 ]]\n",
      "Bias: [0.65401839]\n",
      "Step: 18000 Loss: 10.798854745181496\n",
      "Weight: [[0.60769469]\n",
      " [0.68147022]\n",
      " [0.72690072]]\n",
      "Bias: [0.65401094]\n",
      "Step: 18100 Loss: 10.762277891880476\n",
      "Weight: [[0.60703426]\n",
      " [0.68055011]\n",
      " [0.7284418 ]]\n",
      "Bias: [0.65400346]\n",
      "Step: 18200 Loss: 10.726004978338358\n",
      "Weight: [[0.60637561]\n",
      " [0.67963469]\n",
      " [0.72997656]]\n",
      "Bias: [0.65399592]\n",
      "Step: 18300 Loss: 10.690033412900448\n",
      "Weight: [[0.60571875]\n",
      " [0.67872392]\n",
      " [0.73150503]]\n",
      "Bias: [0.65398834]\n",
      "Step: 18400 Loss: 10.65436062635999\n",
      "Weight: [[0.60506368]\n",
      " [0.6778178 ]\n",
      " [0.73302723]]\n",
      "Bias: [0.65398072]\n",
      "Step: 18500 Loss: 10.618984071761872\n",
      "Weight: [[0.60441038]\n",
      " [0.6769163 ]\n",
      " [0.7345432 ]]\n",
      "Bias: [0.65397305]\n",
      "Step: 18600 Loss: 10.583901224208061\n",
      "Weight: [[0.60375885]\n",
      " [0.67601939]\n",
      " [0.73605295]]\n",
      "Bias: [0.65396534]\n",
      "Step: 18700 Loss: 10.549109580664942\n",
      "Weight: [[0.60310908]\n",
      " [0.67512705]\n",
      " [0.73755652]]\n",
      "Bias: [0.65395758]\n",
      "Step: 18800 Loss: 10.514606659772054\n",
      "Weight: [[0.60246108]\n",
      " [0.67423927]\n",
      " [0.73905393]]\n",
      "Bias: [0.65394978]\n",
      "Step: 18900 Loss: 10.480390001652715\n",
      "Weight: [[0.60181483]\n",
      " [0.67335602]\n",
      " [0.74054521]]\n",
      "Bias: [0.65394193]\n",
      "Step: 19000 Loss: 10.44645716772628\n",
      "Weight: [[0.60117034]\n",
      " [0.67247728]\n",
      " [0.74203037]]\n",
      "Bias: [0.65393404]\n",
      "Step: 19100 Loss: 10.412805740522012\n",
      "Weight: [[0.60052759]\n",
      " [0.67160302]\n",
      " [0.74350946]]\n",
      "Bias: [0.6539261]\n",
      "Step: 19200 Loss: 10.379433323494505\n",
      "Weight: [[0.59988658]\n",
      " [0.67073323]\n",
      " [0.74498249]]\n",
      "Bias: [0.65391812]\n",
      "Step: 19300 Loss: 10.34633754084097\n",
      "Weight: [[0.59924731]\n",
      " [0.66986789]\n",
      " [0.74644949]]\n",
      "Bias: [0.6539101]\n",
      "Step: 19400 Loss: 10.31351603731995\n",
      "Weight: [[0.59860977]\n",
      " [0.66900697]\n",
      " [0.74791049]]\n",
      "Bias: [0.65390203]\n",
      "Step: 19500 Loss: 10.280966478071486\n",
      "Weight: [[0.59797396]\n",
      " [0.66815045]\n",
      " [0.7493655 ]]\n",
      "Bias: [0.65389392]\n",
      "Step: 19600 Loss: 10.248686548439291\n",
      "Weight: [[0.59733986]\n",
      " [0.66729832]\n",
      " [0.75081456]]\n",
      "Bias: [0.65388577]\n",
      "Step: 19700 Loss: 10.216673953793947\n",
      "Weight: [[0.59670749]\n",
      " [0.66645054]\n",
      " [0.7522577 ]]\n",
      "Bias: [0.65387757]\n",
      "Step: 19800 Loss: 10.184926419358357\n",
      "Weight: [[0.59607682]\n",
      " [0.66560711]\n",
      " [0.75369493]]\n",
      "Bias: [0.65386934]\n",
      "Step: 19900 Loss: 10.153441690033874\n",
      "Weight: [[0.59544786]\n",
      " [0.66476799]\n",
      " [0.75512627]]\n",
      "Bias: [0.65386106]\n",
      "Step: 20000 Loss: 10.122217530228552\n",
      "Weight: [[0.59482061]\n",
      " [0.66393317]\n",
      " [0.75655177]]\n",
      "Bias: [0.65385273]\n",
      "Step: 20100 Loss: 10.091251723686868\n",
      "Weight: [[0.59419505]\n",
      " [0.66310263]\n",
      " [0.75797144]]\n",
      "Bias: [0.65384437]\n",
      "Step: 20200 Loss: 10.060542073320592\n",
      "Weight: [[0.59357118]\n",
      " [0.66227635]\n",
      " [0.7593853 ]]\n",
      "Bias: [0.65383596]\n",
      "Step: 20300 Loss: 10.030086401041729\n",
      "Weight: [[0.592949  ]\n",
      " [0.66145431]\n",
      " [0.76079338]]\n",
      "Bias: [0.65382751]\n",
      "Step: 20400 Loss: 9.999882547596098\n",
      "Weight: [[0.59232851]\n",
      " [0.66063648]\n",
      " [0.7621957 ]]\n",
      "Bias: [0.65381902]\n",
      "Step: 20500 Loss: 9.969928372399302\n",
      "Weight: [[0.59170969]\n",
      " [0.65982285]\n",
      " [0.7635923 ]]\n",
      "Bias: [0.65381049]\n",
      "Step: 20600 Loss: 9.940221753373295\n",
      "Weight: [[0.59109254]\n",
      " [0.6590134 ]\n",
      " [0.76498318]]\n",
      "Bias: [0.65380191]\n",
      "Step: 20700 Loss: 9.910760586785099\n",
      "Weight: [[0.59047706]\n",
      " [0.6582081 ]\n",
      " [0.76636838]]\n",
      "Bias: [0.6537933]\n",
      "Step: 20800 Loss: 9.881542787086408\n",
      "Weight: [[0.58986325]\n",
      " [0.65740695]\n",
      " [0.76774793]]\n",
      "Bias: [0.65378464]\n",
      "Step: 20900 Loss: 9.85256628675485\n",
      "Weight: [[0.5892511 ]\n",
      " [0.6566099 ]\n",
      " [0.76912183]]\n",
      "Bias: [0.65377595]\n",
      "Step: 21000 Loss: 9.823829036136631\n",
      "Weight: [[0.5886406 ]\n",
      " [0.65581696]\n",
      " [0.77049013]]\n",
      "Bias: [0.65376721]\n",
      "Step: 21100 Loss: 9.7953290032905\n",
      "Weight: [[0.58803174]\n",
      " [0.6550281 ]\n",
      " [0.77185284]]\n",
      "Bias: [0.65375843]\n",
      "Step: 21200 Loss: 9.76706417383312\n",
      "Weight: [[0.58742454]\n",
      " [0.65424329]\n",
      " [0.77320998]]\n",
      "Bias: [0.65374961]\n",
      "Step: 21300 Loss: 9.739032550785849\n",
      "Weight: [[0.58681897]\n",
      " [0.65346252]\n",
      " [0.77456159]]\n",
      "Bias: [0.65374075]\n",
      "Step: 21400 Loss: 9.71123215442255\n",
      "Weight: [[0.58621504]\n",
      " [0.65268578]\n",
      " [0.77590767]]\n",
      "Bias: [0.65373185]\n",
      "Step: 21500 Loss: 9.68366102211944\n",
      "Weight: [[0.58561274]\n",
      " [0.65191303]\n",
      " [0.77724826]]\n",
      "Bias: [0.65372292]\n",
      "Step: 21600 Loss: 9.65631720820542\n",
      "Weight: [[0.58501207]\n",
      " [0.65114427]\n",
      " [0.77858338]]\n",
      "Bias: [0.65371394]\n",
      "Step: 21700 Loss: 9.629198783814282\n",
      "Weight: [[0.58441302]\n",
      " [0.65037947]\n",
      " [0.77991306]]\n",
      "Bias: [0.65370492]\n",
      "Step: 21800 Loss: 9.602303836737992\n",
      "Weight: [[0.58381558]\n",
      " [0.64961861]\n",
      " [0.7812373 ]]\n",
      "Bias: [0.65369586]\n",
      "Step: 21900 Loss: 9.575630471281384\n",
      "Weight: [[0.58321976]\n",
      " [0.64886167]\n",
      " [0.78255615]]\n",
      "Bias: [0.65368677]\n",
      "Step: 22000 Loss: 9.549176808117918\n",
      "Weight: [[0.58262555]\n",
      " [0.64810865]\n",
      " [0.78386962]]\n",
      "Bias: [0.65367763]\n",
      "Step: 22100 Loss: 9.52294098414707\n",
      "Weight: [[0.58203294]\n",
      " [0.64735951]\n",
      " [0.78517773]]\n",
      "Bias: [0.65366846]\n",
      "Step: 22200 Loss: 9.496921152352437\n",
      "Weight: [[0.58144193]\n",
      " [0.64661424]\n",
      " [0.7864805 ]]\n",
      "Bias: [0.65365924]\n",
      "Step: 22300 Loss: 9.471115481661686\n",
      "Weight: [[0.58085251]\n",
      " [0.64587282]\n",
      " [0.78777797]]\n",
      "Bias: [0.65364999]\n",
      "Step: 22400 Loss: 9.445522156807334\n",
      "Weight: [[0.58026468]\n",
      " [0.64513523]\n",
      " [0.78907014]]\n",
      "Bias: [0.6536407]\n",
      "Step: 22500 Loss: 9.420139378188736\n",
      "Weight: [[0.57967844]\n",
      " [0.64440145]\n",
      " [0.79035705]]\n",
      "Bias: [0.65363138]\n",
      "Step: 22600 Loss: 9.394965361735723\n",
      "Weight: [[0.57909378]\n",
      " [0.64367147]\n",
      " [0.79163871]]\n",
      "Bias: [0.65362201]\n",
      "Step: 22700 Loss: 9.369998338772744\n",
      "Weight: [[0.5785107 ]\n",
      " [0.64294527]\n",
      " [0.79291516]]\n",
      "Bias: [0.6536126]\n",
      "Step: 22800 Loss: 9.345236555884911\n",
      "Weight: [[0.57792918]\n",
      " [0.64222282]\n",
      " [0.7941864 ]]\n",
      "Bias: [0.65360316]\n",
      "Step: 22900 Loss: 9.320678274784676\n",
      "Weight: [[0.57734924]\n",
      " [0.64150412]\n",
      " [0.79545246]]\n",
      "Bias: [0.65359368]\n",
      "Step: 23000 Loss: 9.296321772180043\n",
      "Weight: [[0.57677086]\n",
      " [0.64078914]\n",
      " [0.79671337]]\n",
      "Bias: [0.65358417]\n",
      "Step: 23100 Loss: 9.272165339643603\n",
      "Weight: [[0.57619403]\n",
      " [0.64007786]\n",
      " [0.79796914]]\n",
      "Bias: [0.65357461]\n",
      "Step: 23200 Loss: 9.248207283483099\n",
      "Weight: [[0.57561876]\n",
      " [0.63937028]\n",
      " [0.79921979]]\n",
      "Bias: [0.65356502]\n",
      "Step: 23300 Loss: 9.224445924612716\n",
      "Weight: [[0.57504504]\n",
      " [0.63866636]\n",
      " [0.80046536]]\n",
      "Bias: [0.65355539]\n",
      "Step: 23400 Loss: 9.200879598425965\n",
      "Weight: [[0.57447287]\n",
      " [0.63796609]\n",
      " [0.80170585]]\n",
      "Bias: [0.65354572]\n",
      "Step: 23500 Loss: 9.177506654669239\n",
      "Weight: [[0.57390224]\n",
      " [0.63726946]\n",
      " [0.8029413 ]]\n",
      "Bias: [0.65353602]\n",
      "Step: 23600 Loss: 9.154325457316768\n",
      "Weight: [[0.57333314]\n",
      " [0.63657644]\n",
      " [0.80417172]]\n",
      "Bias: [0.65352628]\n",
      "Step: 23700 Loss: 9.131334384446406\n",
      "Weight: [[0.57276558]\n",
      " [0.63588703]\n",
      " [0.80539713]]\n",
      "Bias: [0.65351651]\n",
      "Step: 23800 Loss: 9.10853182811705\n",
      "Weight: [[0.57219954]\n",
      " [0.6352012 ]\n",
      " [0.80661756]]\n",
      "Bias: [0.6535067]\n",
      "Step: 23900 Loss: 9.085916194246273\n",
      "Weight: [[0.57163503]\n",
      " [0.63451893]\n",
      " [0.80783302]]\n",
      "Bias: [0.65349685]\n",
      "Step: 24000 Loss: 9.06348590248993\n",
      "Weight: [[0.57107204]\n",
      " [0.63384021]\n",
      " [0.80904354]]\n",
      "Bias: [0.65348696]\n",
      "Step: 24100 Loss: 9.041239386122122\n",
      "Weight: [[0.57051056]\n",
      " [0.63316502]\n",
      " [0.81024913]]\n",
      "Bias: [0.65347704]\n",
      "Step: 24200 Loss: 9.019175091916798\n",
      "Weight: [[0.5699506 ]\n",
      " [0.63249335]\n",
      " [0.81144983]]\n",
      "Bias: [0.65346709]\n",
      "Step: 24300 Loss: 8.997291480029808\n",
      "Weight: [[0.56939214]\n",
      " [0.63182517]\n",
      " [0.81264564]]\n",
      "Bias: [0.6534571]\n",
      "Step: 24400 Loss: 8.975587023882337\n",
      "Weight: [[0.56883518]\n",
      " [0.63116047]\n",
      " [0.81383659]]\n",
      "Bias: [0.65344707]\n",
      "Step: 24500 Loss: 8.954060210045437\n",
      "Weight: [[0.56827972]\n",
      " [0.63049924]\n",
      " [0.8150227 ]]\n",
      "Bias: [0.65343701]\n",
      "Step: 24600 Loss: 8.93270953812541\n",
      "Weight: [[0.56772576]\n",
      " [0.62984146]\n",
      " [0.81620399]]\n",
      "Bias: [0.65342691]\n",
      "Step: 24700 Loss: 8.911533520650114\n",
      "Weight: [[0.56717328]\n",
      " [0.6291871 ]\n",
      " [0.81738048]]\n",
      "Bias: [0.65341678]\n",
      "Step: 24800 Loss: 8.890530682956467\n",
      "Weight: [[0.56662229]\n",
      " [0.62853616]\n",
      " [0.81855219]]\n",
      "Bias: [0.65340662]\n",
      "Step: 24900 Loss: 8.869699563078846\n",
      "Weight: [[0.56607279]\n",
      " [0.62788862]\n",
      " [0.81971914]]\n",
      "Bias: [0.65339641]\n",
      "Step: 25000 Loss: 8.84903871163844\n",
      "Weight: [[0.56552475]\n",
      " [0.62724445]\n",
      " [0.82088136]]\n",
      "Bias: [0.65338618]\n",
      "Step: 25100 Loss: 8.828546691733694\n",
      "Weight: [[0.5649782 ]\n",
      " [0.62660366]\n",
      " [0.82203885]]\n",
      "Bias: [0.65337591]\n",
      "Step: 25200 Loss: 8.808222078831465\n",
      "Weight: [[0.56443311]\n",
      " [0.62596621]\n",
      " [0.82319164]]\n",
      "Bias: [0.6533656]\n",
      "Step: 25300 Loss: 8.78806346065939\n",
      "Weight: [[0.56388949]\n",
      " [0.62533209]\n",
      " [0.82433976]]\n",
      "Bias: [0.65335526]\n",
      "Step: 25400 Loss: 8.768069437099108\n",
      "Weight: [[0.56334732]\n",
      " [0.62470129]\n",
      " [0.82548321]]\n",
      "Bias: [0.65334489]\n",
      "Step: 25500 Loss: 8.748238620080373\n",
      "Weight: [[0.56280662]\n",
      " [0.6240738 ]\n",
      " [0.82662202]]\n",
      "Bias: [0.65333448]\n",
      "Step: 25600 Loss: 8.728569633476164\n",
      "Weight: [[0.56226736]\n",
      " [0.62344958]\n",
      " [0.82775621]]\n",
      "Bias: [0.65332404]\n",
      "Step: 25700 Loss: 8.709061112998532\n",
      "Weight: [[0.56172956]\n",
      " [0.62282864]\n",
      " [0.8288858 ]]\n",
      "Bias: [0.65331357]\n",
      "Step: 25800 Loss: 8.68971170609587\n",
      "Weight: [[0.5611932 ]\n",
      " [0.62221095]\n",
      " [0.83001081]]\n",
      "Bias: [0.65330306]\n",
      "Step: 25900 Loss: 8.670520071850305\n",
      "Weight: [[0.56065828]\n",
      " [0.62159649]\n",
      " [0.83113125]]\n",
      "Bias: [0.65329252]\n",
      "Step: 26000 Loss: 8.651484880876685\n",
      "Weight: [[0.56012479]\n",
      " [0.62098526]\n",
      " [0.83224715]]\n",
      "Bias: [0.65328195]\n",
      "Step: 26100 Loss: 8.632604815222036\n",
      "Weight: [[0.55959274]\n",
      " [0.62037723]\n",
      " [0.83335853]]\n",
      "Bias: [0.65327134]\n",
      "Step: 26200 Loss: 8.613878568266138\n",
      "Weight: [[0.55906212]\n",
      " [0.6197724 ]\n",
      " [0.8344654 ]]\n",
      "Bias: [0.6532607]\n",
      "Step: 26300 Loss: 8.595304844622763\n",
      "Weight: [[0.55853292]\n",
      " [0.61917074]\n",
      " [0.83556778]]\n",
      "Bias: [0.65325003]\n",
      "Step: 26400 Loss: 8.576882360042081\n",
      "Weight: [[0.55800514]\n",
      " [0.61857224]\n",
      " [0.8366657 ]]\n",
      "Bias: [0.65323932]\n",
      "Step: 26500 Loss: 8.55860984131353\n",
      "Weight: [[0.55747877]\n",
      " [0.61797689]\n",
      " [0.83775916]]\n",
      "Bias: [0.65322858]\n",
      "Step: 26600 Loss: 8.540486026169768\n",
      "Weight: [[0.55695382]\n",
      " [0.61738466]\n",
      " [0.8388482 ]]\n",
      "Bias: [0.65321781]\n",
      "Step: 26700 Loss: 8.522509663191617\n",
      "Weight: [[0.55643028]\n",
      " [0.61679555]\n",
      " [0.83993282]]\n",
      "Bias: [0.65320701]\n",
      "Step: 26800 Loss: 8.504679511713382\n",
      "Weight: [[0.55590814]\n",
      " [0.61620954]\n",
      " [0.84101305]]\n",
      "Bias: [0.65319618]\n",
      "Step: 26900 Loss: 8.486994341729552\n",
      "Weight: [[0.5553874 ]\n",
      " [0.61562662]\n",
      " [0.8420889 ]]\n",
      "Bias: [0.65318531]\n",
      "Step: 27000 Loss: 8.469452933801882\n",
      "Weight: [[0.55486806]\n",
      " [0.61504676]\n",
      " [0.8431604 ]]\n",
      "Bias: [0.65317441]\n",
      "Step: 27100 Loss: 8.452054078967498\n",
      "Weight: [[0.55435011]\n",
      " [0.61446996]\n",
      " [0.84422756]]\n",
      "Bias: [0.65316348]\n",
      "Step: 27200 Loss: 8.434796578647765\n",
      "Weight: [[0.55383355]\n",
      " [0.6138962 ]\n",
      " [0.8452904 ]]\n",
      "Bias: [0.65315252]\n",
      "Step: 27300 Loss: 8.417679244557911\n",
      "Weight: [[0.55331838]\n",
      " [0.61332547]\n",
      " [0.84634894]]\n",
      "Bias: [0.65314152]\n",
      "Step: 27400 Loss: 8.400700898617552\n",
      "Weight: [[0.55280458]\n",
      " [0.61275774]\n",
      " [0.84740319]]\n",
      "Bias: [0.6531305]\n",
      "Step: 27500 Loss: 8.383860372861948\n",
      "Weight: [[0.55229216]\n",
      " [0.61219302]\n",
      " [0.84845318]]\n",
      "Bias: [0.65311944]\n",
      "Step: 27600 Loss: 8.367156509353848\n",
      "Weight: [[0.55178112]\n",
      " [0.61163127]\n",
      " [0.84949892]]\n",
      "Bias: [0.65310836]\n",
      "Step: 27700 Loss: 8.350588160096574\n",
      "Weight: [[0.55127144]\n",
      " [0.61107249]\n",
      " [0.85054042]]\n",
      "Bias: [0.65309724]\n",
      "Step: 27800 Loss: 8.334154186947295\n",
      "Weight: [[0.55076313]\n",
      " [0.61051667]\n",
      " [0.85157772]]\n",
      "Bias: [0.65308609]\n",
      "Step: 27900 Loss: 8.317853461531504\n",
      "Weight: [[0.55025618]\n",
      " [0.60996378]\n",
      " [0.85261082]]\n",
      "Bias: [0.65307491]\n",
      "Step: 28000 Loss: 8.301684865157997\n",
      "Weight: [[0.54975059]\n",
      " [0.60941382]\n",
      " [0.85363975]]\n",
      "Bias: [0.6530637]\n",
      "Step: 28100 Loss: 8.285647288734713\n",
      "Weight: [[0.54924636]\n",
      " [0.60886677]\n",
      " [0.85466451]]\n",
      "Bias: [0.65305246]\n",
      "Step: 28200 Loss: 8.269739632685297\n",
      "Weight: [[0.54874347]\n",
      " [0.60832262]\n",
      " [0.85568513]]\n",
      "Bias: [0.65304119]\n",
      "Step: 28300 Loss: 8.253960806866361\n",
      "Weight: [[0.54824193]\n",
      " [0.60778135]\n",
      " [0.85670163]]\n",
      "Bias: [0.65302988]\n",
      "Step: 28400 Loss: 8.238309730485463\n",
      "Weight: [[0.54774173]\n",
      " [0.60724294]\n",
      " [0.85771402]]\n",
      "Bias: [0.65301855]\n",
      "Step: 28500 Loss: 8.22278533201987\n",
      "Weight: [[0.54724288]\n",
      " [0.60670739]\n",
      " [0.85872232]]\n",
      "Bias: [0.65300719]\n",
      "Step: 28600 Loss: 8.207386549135952\n",
      "Weight: [[0.54674535]\n",
      " [0.60617469]\n",
      " [0.85972655]]\n",
      "Bias: [0.6529958]\n",
      "Step: 28700 Loss: 8.192112328609342\n",
      "Weight: [[0.54624916]\n",
      " [0.60564481]\n",
      " [0.86072672]]\n",
      "Bias: [0.65298438]\n",
      "Step: 28800 Loss: 8.176961626245614\n",
      "Weight: [[0.5457543 ]\n",
      " [0.60511774]\n",
      " [0.86172285]]\n",
      "Bias: [0.65297293]\n",
      "Step: 28900 Loss: 8.161933406802245\n",
      "Weight: [[0.54526076]\n",
      " [0.60459347]\n",
      " [0.86271496]]\n",
      "Bias: [0.65296145]\n",
      "Step: 29000 Loss: 8.147026643910303\n",
      "Weight: [[0.54476854]\n",
      " [0.60407199]\n",
      " [0.86370306]]\n",
      "Bias: [0.65294994]\n",
      "Step: 29100 Loss: 8.1322403199976\n",
      "Weight: [[0.54427764]\n",
      " [0.60355328]\n",
      " [0.86468718]]\n",
      "Bias: [0.6529384]\n",
      "Step: 29200 Loss: 8.117573426212411\n",
      "Weight: [[0.54378805]\n",
      " [0.60303733]\n",
      " [0.86566732]]\n",
      "Bias: [0.65292683]\n",
      "Step: 29300 Loss: 8.103024962347387\n",
      "Weight: [[0.54329976]\n",
      " [0.60252412]\n",
      " [0.86664351]]\n",
      "Bias: [0.65291523]\n",
      "Step: 29400 Loss: 8.08859393676484\n",
      "Weight: [[0.54281279]\n",
      " [0.60201365]\n",
      " [0.86761576]]\n",
      "Bias: [0.65290361]\n",
      "Step: 29500 Loss: 8.074279366321756\n",
      "Weight: [[0.54232712]\n",
      " [0.6015059 ]\n",
      " [0.86858408]]\n",
      "Bias: [0.65289195]\n",
      "Step: 29600 Loss: 8.060080276296729\n",
      "Weight: [[0.54184274]\n",
      " [0.60100085]\n",
      " [0.8695485 ]]\n",
      "Bias: [0.65288027]\n",
      "Step: 29700 Loss: 8.045995700316217\n",
      "Weight: [[0.54135966]\n",
      " [0.6004985 ]\n",
      " [0.87050904]]\n",
      "Bias: [0.65286855]\n",
      "Step: 29800 Loss: 8.032024680282264\n",
      "Weight: [[0.54087787]\n",
      " [0.59999882]\n",
      " [0.87146569]]\n",
      "Bias: [0.65285681]\n",
      "Step: 29900 Loss: 8.018166266300792\n",
      "Weight: [[0.54039737]\n",
      " [0.59950181]\n",
      " [0.8724185 ]]\n",
      "Bias: [0.65284504]\n",
      "Step: 30000 Loss: 8.004419516610131\n",
      "Weight: [[0.53991815]\n",
      " [0.59900746]\n",
      " [0.87336746]]\n",
      "Bias: [0.65283325]\n",
      "Step: 30100 Loss: 7.990783497510424\n",
      "Weight: [[0.53944022]\n",
      " [0.59851575]\n",
      " [0.87431259]]\n",
      "Bias: [0.65282142]\n",
      "Step: 30200 Loss: 7.977257283293881\n",
      "Weight: [[0.53896356]\n",
      " [0.59802666]\n",
      " [0.87525392]]\n",
      "Bias: [0.65280957]\n",
      "Step: 30300 Loss: 7.963839956175072\n",
      "Weight: [[0.53848817]\n",
      " [0.59754019]\n",
      " [0.87619145]]\n",
      "Bias: [0.65279768]\n",
      "Step: 30400 Loss: 7.95053060622241\n",
      "Weight: [[0.53801405]\n",
      " [0.59705632]\n",
      " [0.87712521]]\n",
      "Bias: [0.65278578]\n",
      "Step: 30500 Loss: 7.937328331289806\n",
      "Weight: [[0.5375412 ]\n",
      " [0.59657505]\n",
      " [0.87805521]]\n",
      "Bias: [0.65277384]\n",
      "Step: 30600 Loss: 7.924232236949206\n",
      "Weight: [[0.53706961]\n",
      " [0.59609635]\n",
      " [0.87898146]]\n",
      "Bias: [0.65276187]\n",
      "Step: 30700 Loss: 7.911241436423563\n",
      "Weight: [[0.53659928]\n",
      " [0.59562021]\n",
      " [0.87990398]]\n",
      "Bias: [0.65274988]\n",
      "Step: 30800 Loss: 7.898355050520478\n",
      "Weight: [[0.53613021]\n",
      " [0.59514663]\n",
      " [0.88082279]]\n",
      "Bias: [0.65273786]\n",
      "Step: 30900 Loss: 7.885572207566297\n",
      "Weight: [[0.53566239]\n",
      " [0.59467559]\n",
      " [0.8817379 ]]\n",
      "Bias: [0.65272582]\n",
      "Step: 31000 Loss: 7.872892043340961\n",
      "Weight: [[0.53519582]\n",
      " [0.59420707]\n",
      " [0.88264932]]\n",
      "Bias: [0.65271374]\n",
      "Step: 31100 Loss: 7.860313701013331\n",
      "Weight: [[0.53473049]\n",
      " [0.59374107]\n",
      " [0.88355708]]\n",
      "Bias: [0.65270164]\n",
      "Step: 31200 Loss: 7.847836331077023\n",
      "Weight: [[0.5342664 ]\n",
      " [0.59327757]\n",
      " [0.88446119]]\n",
      "Bias: [0.65268951]\n",
      "Step: 31300 Loss: 7.835459091286968\n",
      "Weight: [[0.53380355]\n",
      " [0.59281657]\n",
      " [0.88536166]]\n",
      "Bias: [0.65267736]\n",
      "Step: 31400 Loss: 7.823181146596221\n",
      "Weight: [[0.53334194]\n",
      " [0.59235804]\n",
      " [0.8862585 ]]\n",
      "Bias: [0.65266518]\n",
      "Step: 31500 Loss: 7.8110016690938675\n",
      "Weight: [[0.53288156]\n",
      " [0.59190198]\n",
      " [0.88715174]]\n",
      "Bias: [0.65265297]\n",
      "Step: 31600 Loss: 7.79891983794285\n",
      "Weight: [[0.5324224 ]\n",
      " [0.59144837]\n",
      " [0.88804139]]\n",
      "Bias: [0.65264073]\n",
      "Step: 31700 Loss: 7.786934839318709\n",
      "Weight: [[0.53196447]\n",
      " [0.59099721]\n",
      " [0.88892747]]\n",
      "Bias: [0.65262847]\n",
      "Step: 31800 Loss: 7.775045866348694\n",
      "Weight: [[0.53150776]\n",
      " [0.59054848]\n",
      " [0.88980998]]\n",
      "Bias: [0.65261619]\n",
      "Step: 31900 Loss: 7.763252119051686\n",
      "Weight: [[0.53105227]\n",
      " [0.59010216]\n",
      " [0.89068894]]\n",
      "Bias: [0.65260387]\n",
      "Step: 32000 Loss: 7.751552804278326\n",
      "Weight: [[0.530598  ]\n",
      " [0.58965825]\n",
      " [0.89156437]]\n",
      "Bias: [0.65259153]\n",
      "Step: 32100 Loss: 7.739947135651684\n",
      "Weight: [[0.53014493]\n",
      " [0.58921674]\n",
      " [0.89243628]]\n",
      "Bias: [0.65257917]\n",
      "Step: 32200 Loss: 7.728434333508736\n",
      "Weight: [[0.52969307]\n",
      " [0.58877761]\n",
      " [0.8933047 ]]\n",
      "Bias: [0.65256678]\n",
      "Step: 32300 Loss: 7.717013624842123\n",
      "Weight: [[0.52924242]\n",
      " [0.58834086]\n",
      " [0.89416962]]\n",
      "Bias: [0.65255436]\n",
      "Step: 32400 Loss: 7.7056842432422865\n",
      "Weight: [[0.52879297]\n",
      " [0.58790646]\n",
      " [0.89503107]]\n",
      "Bias: [0.65254192]\n",
      "Step: 32500 Loss: 7.694445428840512\n",
      "Weight: [[0.52834471]\n",
      " [0.58747442]\n",
      " [0.89588906]]\n",
      "Bias: [0.65252945]\n",
      "Step: 32600 Loss: 7.683296428252263\n",
      "Weight: [[0.52789765]\n",
      " [0.58704471]\n",
      " [0.89674361]]\n",
      "Bias: [0.65251696]\n",
      "Step: 32700 Loss: 7.67223649452067\n",
      "Weight: [[0.52745178]\n",
      " [0.58661732]\n",
      " [0.89759473]]\n",
      "Bias: [0.65250444]\n",
      "Step: 32800 Loss: 7.661264887061142\n",
      "Weight: [[0.5270071 ]\n",
      " [0.58619225]\n",
      " [0.89844243]]\n",
      "Bias: [0.6524919]\n",
      "Step: 32900 Loss: 7.650380871606208\n",
      "Weight: [[0.5265636 ]\n",
      " [0.58576949]\n",
      " [0.89928673]]\n",
      "Bias: [0.65247933]\n",
      "Step: 33000 Loss: 7.639583720150455\n",
      "Weight: [[0.52612128]\n",
      " [0.58534901]\n",
      " [0.90012764]]\n",
      "Bias: [0.65246673]\n",
      "Step: 33100 Loss: 7.62887271089659\n",
      "Weight: [[0.52568014]\n",
      " [0.58493082]\n",
      " [0.90096518]]\n",
      "Bias: [0.65245411]\n",
      "Step: 33200 Loss: 7.618247128201542\n",
      "Weight: [[0.52524017]\n",
      " [0.5845149 ]\n",
      " [0.90179936]]\n",
      "Bias: [0.65244147]\n",
      "Step: 33300 Loss: 7.60770626252311\n",
      "Weight: [[0.52480138]\n",
      " [0.58410123]\n",
      " [0.90263019]]\n",
      "Bias: [0.6524288]\n",
      "Step: 33400 Loss: 7.597249410367263\n",
      "Weight: [[0.52436375]\n",
      " [0.58368982]\n",
      " [0.9034577 ]]\n",
      "Bias: [0.65241611]\n",
      "Step: 33500 Loss: 7.586875874235631\n",
      "Weight: [[0.52392729]\n",
      " [0.58328064]\n",
      " [0.90428188]]\n",
      "Bias: [0.65240339]\n",
      "Step: 33600 Loss: 7.576584962573736\n",
      "Weight: [[0.52349199]\n",
      " [0.58287368]\n",
      " [0.90510277]]\n",
      "Bias: [0.65239065]\n",
      "Step: 33700 Loss: 7.566375989719312\n",
      "Weight: [[0.52305785]\n",
      " [0.58246894]\n",
      " [0.90592036]]\n",
      "Bias: [0.65237788]\n",
      "Step: 33800 Loss: 7.5562482758514555\n",
      "Weight: [[0.52262486]\n",
      " [0.58206641]\n",
      " [0.90673468]]\n",
      "Bias: [0.65236509]\n",
      "Step: 33900 Loss: 7.546201146940118\n",
      "Weight: [[0.52219303]\n",
      " [0.58166606]\n",
      " [0.90754574]]\n",
      "Bias: [0.65235228]\n",
      "Step: 34000 Loss: 7.536233934695722\n",
      "Weight: [[0.52176234]\n",
      " [0.5812679 ]\n",
      " [0.90835354]]\n",
      "Bias: [0.65233944]\n",
      "Step: 34100 Loss: 7.526345976519771\n",
      "Weight: [[0.5213328 ]\n",
      " [0.58087191]\n",
      " [0.90915811]]\n",
      "Bias: [0.65232657]\n",
      "Step: 34200 Loss: 7.51653661545535\n",
      "Weight: [[0.5209044 ]\n",
      " [0.58047809]\n",
      " [0.90995946]]\n",
      "Bias: [0.65231369]\n",
      "Step: 34300 Loss: 7.506805200138509\n",
      "Weight: [[0.52047714]\n",
      " [0.58008641]\n",
      " [0.91075761]]\n",
      "Bias: [0.65230078]\n",
      "Step: 34400 Loss: 7.497151084749629\n",
      "Weight: [[0.52005102]\n",
      " [0.57969687]\n",
      " [0.91155255]]\n",
      "Bias: [0.65228784]\n",
      "Step: 34500 Loss: 7.487573628965743\n",
      "Weight: [[0.51962603]\n",
      " [0.57930946]\n",
      " [0.91234432]]\n",
      "Bias: [0.65227488]\n",
      "Step: 34600 Loss: 7.478072197912649\n",
      "Weight: [[0.51920217]\n",
      " [0.57892417]\n",
      " [0.91313292]]\n",
      "Bias: [0.6522619]\n",
      "Step: 34700 Loss: 7.468646162118065\n",
      "Weight: [[0.51877943]\n",
      " [0.57854099]\n",
      " [0.91391836]]\n",
      "Bias: [0.6522489]\n",
      "Step: 34800 Loss: 7.4592948974648\n",
      "Weight: [[0.51835782]\n",
      " [0.57815991]\n",
      " [0.91470066]]\n",
      "Bias: [0.65223587]\n",
      "Step: 34900 Loss: 7.450017785144297\n",
      "Weight: [[0.51793733]\n",
      " [0.57778091]\n",
      " [0.91547983]]\n",
      "Bias: [0.65222282]\n",
      "Step: 35000 Loss: 7.440814211610882\n",
      "Weight: [[0.51751796]\n",
      " [0.577404  ]\n",
      " [0.91625589]]\n",
      "Bias: [0.65220974]\n",
      "Step: 35100 Loss: 7.431683568536257\n",
      "Weight: [[0.5170997 ]\n",
      " [0.57702915]\n",
      " [0.91702884]]\n",
      "Bias: [0.65219665]\n",
      "Step: 35200 Loss: 7.422625252764251\n",
      "Weight: [[0.51668255]\n",
      " [0.57665635]\n",
      " [0.91779871]]\n",
      "Bias: [0.65218353]\n",
      "Step: 35300 Loss: 7.413638666266222\n",
      "Weight: [[0.51626651]\n",
      " [0.57628561]\n",
      " [0.91856549]]\n",
      "Bias: [0.65217038]\n",
      "Step: 35400 Loss: 7.4047232160966665\n",
      "Weight: [[0.51585158]\n",
      " [0.5759169 ]\n",
      " [0.91932921]]\n",
      "Bias: [0.65215722]\n",
      "Step: 35500 Loss: 7.395878314349297\n",
      "Weight: [[0.51543774]\n",
      " [0.57555022]\n",
      " [0.92008988]]\n",
      "Bias: [0.65214403]\n",
      "Step: 35600 Loss: 7.387103378113477\n",
      "Weight: [[0.51502501]\n",
      " [0.57518556]\n",
      " [0.92084752]]\n",
      "Bias: [0.65213082]\n",
      "Step: 35700 Loss: 7.378397829430948\n",
      "Weight: [[0.51461337]\n",
      " [0.5748229 ]\n",
      " [0.92160212]]\n",
      "Bias: [0.65211758]\n",
      "Step: 35800 Loss: 7.369761095253278\n",
      "Weight: [[0.51420282]\n",
      " [0.57446224]\n",
      " [0.92235371]]\n",
      "Bias: [0.65210433]\n",
      "Step: 35900 Loss: 7.361192607399102\n",
      "Weight: [[0.51379337]\n",
      " [0.57410357]\n",
      " [0.9231023 ]]\n",
      "Bias: [0.65209105]\n",
      "Step: 36000 Loss: 7.3526918025123384\n",
      "Weight: [[0.513385  ]\n",
      " [0.57374687]\n",
      " [0.92384791]]\n",
      "Bias: [0.65207775]\n",
      "Step: 36100 Loss: 7.344258122020303\n",
      "Weight: [[0.51297771]\n",
      " [0.57339214]\n",
      " [0.92459053]]\n",
      "Bias: [0.65206443]\n",
      "Step: 36200 Loss: 7.335891012092551\n",
      "Weight: [[0.51257151]\n",
      " [0.57303938]\n",
      " [0.9253302 ]]\n",
      "Bias: [0.65205108]\n",
      "Step: 36300 Loss: 7.327589923599765\n",
      "Weight: [[0.51216638]\n",
      " [0.57268856]\n",
      " [0.92606691]]\n",
      "Bias: [0.65203772]\n",
      "Step: 36400 Loss: 7.319354312073142\n",
      "Weight: [[0.51176233]\n",
      " [0.57233968]\n",
      " [0.92680068]]\n",
      "Bias: [0.65202433]\n",
      "Step: 36500 Loss: 7.311183637664356\n",
      "Weight: [[0.51135935]\n",
      " [0.57199272]\n",
      " [0.92753152]]\n",
      "Bias: [0.65201092]\n",
      "Step: 36600 Loss: 7.303077365105367\n",
      "Weight: [[0.51095744]\n",
      " [0.57164769]\n",
      " [0.92825945]]\n",
      "Bias: [0.65199748]\n",
      "Step: 36700 Loss: 7.295034963669059\n",
      "Weight: [[0.5105566 ]\n",
      " [0.57130457]\n",
      " [0.92898448]]\n",
      "Bias: [0.65198403]\n",
      "Step: 36800 Loss: 7.287055907129911\n",
      "Weight: [[0.51015681]\n",
      " [0.57096335]\n",
      " [0.92970662]]\n",
      "Bias: [0.65197056]\n",
      "Step: 36900 Loss: 7.279139673725274\n",
      "Weight: [[0.50975809]\n",
      " [0.57062402]\n",
      " [0.93042588]]\n",
      "Bias: [0.65195706]\n",
      "Step: 37000 Loss: 7.271285746116613\n",
      "Weight: [[0.50936043]\n",
      " [0.57028658]\n",
      " [0.93114227]]\n",
      "Bias: [0.65194354]\n",
      "Step: 37100 Loss: 7.26349361135155\n",
      "Weight: [[0.50896382]\n",
      " [0.56995101]\n",
      " [0.93185581]]\n",
      "Bias: [0.65193]\n",
      "Step: 37200 Loss: 7.255762760825881\n",
      "Weight: [[0.50856826]\n",
      " [0.5696173 ]\n",
      " [0.9325665 ]]\n",
      "Bias: [0.65191644]\n",
      "Step: 37300 Loss: 7.248092690246108\n",
      "Weight: [[0.50817375]\n",
      " [0.56928544]\n",
      " [0.93327436]]\n",
      "Bias: [0.65190286]\n",
      "Step: 37400 Loss: 7.240482899592096\n",
      "Weight: [[0.50778028]\n",
      " [0.56895543]\n",
      " [0.93397941]]\n",
      "Bias: [0.65188926]\n",
      "Step: 37500 Loss: 7.232932893080468\n",
      "Weight: [[0.50738786]\n",
      " [0.56862726]\n",
      " [0.93468165]]\n",
      "Bias: [0.65187564]\n",
      "Step: 37600 Loss: 7.225442179127681\n",
      "Weight: [[0.50699647]\n",
      " [0.56830092]\n",
      " [0.93538109]]\n",
      "Bias: [0.65186199]\n",
      "Step: 37700 Loss: 7.218010270314071\n",
      "Weight: [[0.50660613]\n",
      " [0.56797639]\n",
      " [0.93607774]]\n",
      "Bias: [0.65184833]\n",
      "Step: 37800 Loss: 7.210636683348025\n",
      "Weight: [[0.50621682]\n",
      " [0.56765367]\n",
      " [0.93677163]]\n",
      "Bias: [0.65183464]\n",
      "Step: 37900 Loss: 7.203320939029831\n",
      "Weight: [[0.50582854]\n",
      " [0.56733275]\n",
      " [0.93746275]]\n",
      "Bias: [0.65182094]\n",
      "Step: 38000 Loss: 7.196062562217105\n",
      "Weight: [[0.50544128]\n",
      " [0.56701363]\n",
      " [0.93815112]]\n",
      "Bias: [0.65180721]\n",
      "Step: 38100 Loss: 7.18886108178924\n",
      "Weight: [[0.50505506]\n",
      " [0.56669629]\n",
      " [0.93883676]]\n",
      "Bias: [0.65179346]\n",
      "Step: 38200 Loss: 7.181716030612943\n",
      "Weight: [[0.50466985]\n",
      " [0.56638072]\n",
      " [0.93951966]]\n",
      "Bias: [0.6517797]\n",
      "Step: 38300 Loss: 7.174626945507946\n",
      "Weight: [[0.50428567]\n",
      " [0.56606691]\n",
      " [0.94019985]]\n",
      "Bias: [0.65176591]\n",
      "Step: 38400 Loss: 7.1675933672126675\n",
      "Weight: [[0.5039025 ]\n",
      " [0.56575486]\n",
      " [0.94087734]]\n",
      "Bias: [0.6517521]\n",
      "Step: 38500 Loss: 7.160614840350723\n",
      "Weight: [[0.50352035]\n",
      " [0.56544456]\n",
      " [0.94155214]]\n",
      "Bias: [0.65173827]\n",
      "Step: 38600 Loss: 7.153690913397148\n",
      "Weight: [[0.50313921]\n",
      " [0.565136  ]\n",
      " [0.94222425]]\n",
      "Bias: [0.65172443]\n",
      "Step: 38700 Loss: 7.146821138645402\n",
      "Weight: [[0.50275908]\n",
      " [0.56482917]\n",
      " [0.94289369]]\n",
      "Bias: [0.65171056]\n",
      "Step: 38800 Loss: 7.140005072174391\n",
      "Weight: [[0.50237995]\n",
      " [0.56452406]\n",
      " [0.94356047]]\n",
      "Bias: [0.65169667]\n",
      "Step: 38900 Loss: 7.1332422738158865\n",
      "Weight: [[0.50200183]\n",
      " [0.56422066]\n",
      " [0.9442246 ]]\n",
      "Bias: [0.65168276]\n",
      "Step: 39000 Loss: 7.126532307122101\n",
      "Weight: [[0.5016247 ]\n",
      " [0.56391897]\n",
      " [0.9448861 ]]\n",
      "Bias: [0.65166884]\n",
      "Step: 39100 Loss: 7.119874739333679\n",
      "Weight: [[0.50124858]\n",
      " [0.56361897]\n",
      " [0.94554496]]\n",
      "Bias: [0.65165489]\n",
      "Step: 39200 Loss: 7.113269141347982\n",
      "Weight: [[0.50087345]\n",
      " [0.56332066]\n",
      " [0.94620122]]\n",
      "Bias: [0.65164092]\n",
      "Step: 39300 Loss: 7.10671508768745\n",
      "Weight: [[0.50049931]\n",
      " [0.56302403]\n",
      " [0.94685486]]\n",
      "Bias: [0.65162694]\n",
      "Step: 39400 Loss: 7.100212156468535\n",
      "Weight: [[0.50012616]\n",
      " [0.56272907]\n",
      " [0.94750591]]\n",
      "Bias: [0.65161293]\n",
      "Step: 39500 Loss: 7.093759929370602\n",
      "Weight: [[0.499754  ]\n",
      " [0.56243578]\n",
      " [0.94815438]]\n",
      "Bias: [0.65159891]\n",
      "Step: 39600 Loss: 7.0873579916053595\n",
      "Weight: [[0.49938283]\n",
      " [0.56214414]\n",
      " [0.94880028]]\n",
      "Bias: [0.65158486]\n",
      "Step: 39700 Loss: 7.081005931886367\n",
      "Weight: [[0.49901263]\n",
      " [0.56185414]\n",
      " [0.94944361]]\n",
      "Bias: [0.6515708]\n",
      "Step: 39800 Loss: 7.0747033423989425\n",
      "Weight: [[0.49864341]\n",
      " [0.56156578]\n",
      " [0.95008439]]\n",
      "Bias: [0.65155672]\n",
      "Step: 39900 Loss: 7.068449818770242\n",
      "Weight: [[0.49827517]\n",
      " [0.56127906]\n",
      " [0.95072263]]\n",
      "Bias: [0.65154262]\n",
      "Step: 40000 Loss: 7.062244960039636\n",
      "Weight: [[0.4979079 ]\n",
      " [0.56099395]\n",
      " [0.95135834]]\n",
      "Bias: [0.6515285]\n",
      "Step: 40100 Loss: 7.05608836862928\n",
      "Weight: [[0.49754161]\n",
      " [0.56071046]\n",
      " [0.95199153]]\n",
      "Bias: [0.65151436]\n",
      "Step: 40200 Loss: 7.049979650315189\n",
      "Weight: [[0.49717628]\n",
      " [0.56042857]\n",
      " [0.95262221]]\n",
      "Bias: [0.6515002]\n",
      "Step: 40300 Loss: 7.0439184141980755\n",
      "Weight: [[0.49681191]\n",
      " [0.56014829]\n",
      " [0.95325039]]\n",
      "Bias: [0.65148603]\n",
      "Step: 40400 Loss: 7.03790427267509\n",
      "Weight: [[0.49644851]\n",
      " [0.55986959]\n",
      " [0.95387609]]\n",
      "Bias: [0.65147183]\n",
      "Step: 40500 Loss: 7.031936841411145\n",
      "Weight: [[0.49608607]\n",
      " [0.55959247]\n",
      " [0.9544993 ]]\n",
      "Bias: [0.65145762]\n",
      "Step: 40600 Loss: 7.026015739311023\n",
      "Weight: [[0.49572459]\n",
      " [0.55931693]\n",
      " [0.95512004]]\n",
      "Bias: [0.65144338]\n",
      "Step: 40700 Loss: 7.020140588491406\n",
      "Weight: [[0.49536406]\n",
      " [0.55904295]\n",
      " [0.95573833]]\n",
      "Bias: [0.65142913]\n",
      "Step: 40800 Loss: 7.014311014253215\n",
      "Weight: [[0.49500448]\n",
      " [0.55877053]\n",
      " [0.95635417]]\n",
      "Bias: [0.65141487]\n",
      "Step: 40900 Loss: 7.008526645054391\n",
      "Weight: [[0.49464586]\n",
      " [0.55849967]\n",
      " [0.95696757]]\n",
      "Bias: [0.65140058]\n",
      "Step: 41000 Loss: 7.002787112482506\n",
      "Weight: [[0.49428818]\n",
      " [0.55823034]\n",
      " [0.95757854]]\n",
      "Bias: [0.65138627]\n",
      "Step: 41100 Loss: 6.997092051228078\n",
      "Weight: [[0.49393144]\n",
      " [0.55796255]\n",
      " [0.9581871 ]]\n",
      "Bias: [0.65137195]\n",
      "Step: 41200 Loss: 6.9914410990577425\n",
      "Weight: [[0.49357565]\n",
      " [0.55769629]\n",
      " [0.95879325]]\n",
      "Bias: [0.65135761]\n",
      "Step: 41300 Loss: 6.985833896787953\n",
      "Weight: [[0.49322079]\n",
      " [0.55743155]\n",
      " [0.959397  ]]\n",
      "Bias: [0.65134325]\n",
      "Step: 41400 Loss: 6.9802700882585915\n",
      "Weight: [[0.49286687]\n",
      " [0.55716832]\n",
      " [0.95999836]]\n",
      "Bias: [0.65132887]\n",
      "Step: 41500 Loss: 6.974749320307086\n",
      "Weight: [[0.49251389]\n",
      " [0.55690659]\n",
      " [0.96059734]]\n",
      "Bias: [0.65131448]\n",
      "Step: 41600 Loss: 6.969271242742657\n",
      "Weight: [[0.49216184]\n",
      " [0.55664637]\n",
      " [0.96119396]]\n",
      "Bias: [0.65130006]\n",
      "Step: 41700 Loss: 6.963835508320771\n",
      "Weight: [[0.49181071]\n",
      " [0.55638763]\n",
      " [0.96178822]]\n",
      "Bias: [0.65128563]\n",
      "Step: 41800 Loss: 6.958441772717772\n",
      "Weight: [[0.49146052]\n",
      " [0.55613037]\n",
      " [0.96238013]]\n",
      "Bias: [0.65127118]\n",
      "Step: 41900 Loss: 6.953089694505893\n",
      "Weight: [[0.49111124]\n",
      " [0.55587459]\n",
      " [0.9629697 ]]\n",
      "Bias: [0.65125672]\n",
      "Step: 42000 Loss: 6.947778935128229\n",
      "Weight: [[0.49076289]\n",
      " [0.55562028]\n",
      " [0.96355694]]\n",
      "Bias: [0.65124224]\n",
      "Step: 42100 Loss: 6.942509158874328\n",
      "Weight: [[0.49041546]\n",
      " [0.55536743]\n",
      " [0.96414186]]\n",
      "Bias: [0.65122773]\n",
      "Step: 42200 Loss: 6.9372800328553925\n",
      "Weight: [[0.49006894]\n",
      " [0.55511602]\n",
      " [0.96472447]]\n",
      "Bias: [0.65121322]\n",
      "Step: 42300 Loss: 6.932091226980459\n",
      "Weight: [[0.48972334]\n",
      " [0.55486607]\n",
      " [0.96530478]]\n",
      "Bias: [0.65119868]\n",
      "Step: 42400 Loss: 6.926942413932003\n",
      "Weight: [[0.48937865]\n",
      " [0.55461755]\n",
      " [0.9658828 ]]\n",
      "Bias: [0.65118413]\n",
      "Step: 42500 Loss: 6.9218332691423505\n",
      "Weight: [[0.48903486]\n",
      " [0.55437047]\n",
      " [0.96645854]]\n",
      "Bias: [0.65116956]\n",
      "Step: 42600 Loss: 6.916763470769999\n",
      "Weight: [[0.48869199]\n",
      " [0.55412481]\n",
      " [0.967032  ]]\n",
      "Bias: [0.65115497]\n",
      "Step: 42700 Loss: 6.911732699676301\n",
      "Weight: [[0.48835002]\n",
      " [0.55388056]\n",
      " [0.9676032 ]]\n",
      "Bias: [0.65114037]\n",
      "Step: 42800 Loss: 6.906740639402025\n",
      "Weight: [[0.48800894]\n",
      " [0.55363773]\n",
      " [0.96817215]]\n",
      "Bias: [0.65112575]\n",
      "Step: 42900 Loss: 6.9017869761448\n",
      "Weight: [[0.48766877]\n",
      " [0.5533963 ]\n",
      " [0.96873886]]\n",
      "Bias: [0.65111111]\n",
      "Step: 43000 Loss: 6.896871398735804\n",
      "Weight: [[0.4873295 ]\n",
      " [0.55315626]\n",
      " [0.96930333]]\n",
      "Bias: [0.65109645]\n",
      "Step: 43100 Loss: 6.891993598617595\n",
      "Weight: [[0.48699112]\n",
      " [0.55291761]\n",
      " [0.96986557]]\n",
      "Bias: [0.65108178]\n",
      "Step: 43200 Loss: 6.887153269821413\n",
      "Weight: [[0.48665363]\n",
      " [0.55268035]\n",
      " [0.9704256 ]]\n",
      "Bias: [0.65106709]\n",
      "Step: 43300 Loss: 6.882350108945192\n",
      "Weight: [[0.48631702]\n",
      " [0.55244446]\n",
      " [0.97098342]]\n",
      "Bias: [0.65105239]\n",
      "Step: 43400 Loss: 6.877583815131482\n",
      "Weight: [[0.48598131]\n",
      " [0.55220993]\n",
      " [0.97153904]]\n",
      "Bias: [0.65103767]\n",
      "Step: 43500 Loss: 6.8728540900454425\n",
      "Weight: [[0.48564648]\n",
      " [0.55197677]\n",
      " [0.97209248]]\n",
      "Bias: [0.65102293]\n",
      "Step: 43600 Loss: 6.8681606378535385\n",
      "Weight: [[0.48531253]\n",
      " [0.55174496]\n",
      " [0.97264373]]\n",
      "Bias: [0.65100818]\n",
      "Step: 43700 Loss: 6.863503165201862\n",
      "Weight: [[0.48497947]\n",
      " [0.5515145 ]\n",
      " [0.97319281]]\n",
      "Bias: [0.65099341]\n",
      "Step: 43800 Loss: 6.858881381194941\n",
      "Weight: [[0.48464727]\n",
      " [0.55128538]\n",
      " [0.97373973]]\n",
      "Bias: [0.65097862]\n",
      "Step: 43900 Loss: 6.854294997374743\n",
      "Weight: [[0.48431596]\n",
      " [0.55105759]\n",
      " [0.9742845 ]]\n",
      "Bias: [0.65096382]\n",
      "Step: 44000 Loss: 6.8497437276995985\n",
      "Weight: [[0.48398551]\n",
      " [0.55083113]\n",
      " [0.97482712]]\n",
      "Bias: [0.650949]\n",
      "Step: 44100 Loss: 6.845227288523675\n",
      "Weight: [[0.48365594]\n",
      " [0.550606  ]\n",
      " [0.9753676 ]]\n",
      "Bias: [0.65093416]\n",
      "Step: 44200 Loss: 6.840745398576387\n",
      "Weight: [[0.48332723]\n",
      " [0.55038217]\n",
      " [0.97590596]]\n",
      "Bias: [0.65091931]\n",
      "Step: 44300 Loss: 6.836297778942049\n",
      "Weight: [[0.48299939]\n",
      " [0.55015965]\n",
      " [0.9764422 ]]\n",
      "Bias: [0.65090444]\n",
      "Step: 44400 Loss: 6.831884153039692\n",
      "Weight: [[0.48267241]\n",
      " [0.54993843]\n",
      " [0.97697634]]\n",
      "Bias: [0.65088956]\n",
      "Step: 44500 Loss: 6.82750424660309\n",
      "Weight: [[0.48234629]\n",
      " [0.54971851]\n",
      " [0.97750837]]\n",
      "Bias: [0.65087466]\n",
      "Step: 44600 Loss: 6.823157787660851\n",
      "Weight: [[0.48202103]\n",
      " [0.54949988]\n",
      " [0.97803831]]\n",
      "Bias: [0.65085974]\n",
      "Step: 44700 Loss: 6.818844506516848\n",
      "Weight: [[0.48169663]\n",
      " [0.54928252]\n",
      " [0.97856616]]\n",
      "Bias: [0.65084481]\n",
      "Step: 44800 Loss: 6.814564135730907\n",
      "Weight: [[0.48137308]\n",
      " [0.54906644]\n",
      " [0.97909194]]\n",
      "Bias: [0.65082987]\n",
      "Step: 44900 Loss: 6.8103164100990865\n",
      "Weight: [[0.48105038]\n",
      " [0.54885163]\n",
      " [0.97961566]]\n",
      "Bias: [0.65081491]\n",
      "Step: 45000 Loss: 6.806101066634792\n",
      "Weight: [[0.48072853]\n",
      " [0.54863808]\n",
      " [0.98013732]]\n",
      "Bias: [0.65079993]\n",
      "Step: 45100 Loss: 6.80191784454992\n",
      "Weight: [[0.48040753]\n",
      " [0.54842578]\n",
      " [0.98065692]]\n",
      "Bias: [0.65078494]\n",
      "Step: 45200 Loss: 6.797766485235696\n",
      "Weight: [[0.48008737]\n",
      " [0.54821474]\n",
      " [0.98117449]]\n",
      "Bias: [0.65076993]\n",
      "Step: 45300 Loss: 6.793646732244419\n",
      "Weight: [[0.47976805]\n",
      " [0.54800494]\n",
      " [0.98169002]]\n",
      "Bias: [0.6507549]\n",
      "Step: 45400 Loss: 6.789558331270614\n",
      "Weight: [[0.47944957]\n",
      " [0.54779637]\n",
      " [0.98220353]]\n",
      "Bias: [0.65073986]\n",
      "Step: 45500 Loss: 6.785501030132883\n",
      "Weight: [[0.47913193]\n",
      " [0.54758903]\n",
      " [0.98271503]]\n",
      "Bias: [0.65072481]\n",
      "Step: 45600 Loss: 6.781474578755869\n",
      "Weight: [[0.47881512]\n",
      " [0.54738292]\n",
      " [0.98322452]]\n",
      "Bias: [0.65070974]\n",
      "Step: 45700 Loss: 6.777478729151905\n",
      "Weight: [[0.47849915]\n",
      " [0.54717803]\n",
      " [0.983732  ]]\n",
      "Bias: [0.65069466]\n",
      "Step: 45800 Loss: 6.773513235403507\n",
      "Weight: [[0.47818401]\n",
      " [0.54697434]\n",
      " [0.9842375 ]]\n",
      "Bias: [0.65067956]\n",
      "Step: 45900 Loss: 6.769577853645405\n",
      "Weight: [[0.47786969]\n",
      " [0.54677187]\n",
      " [0.98474101]]\n",
      "Bias: [0.65066444]\n",
      "Step: 46000 Loss: 6.765672342047195\n",
      "Weight: [[0.4775562 ]\n",
      " [0.54657059]\n",
      " [0.98524255]]\n",
      "Bias: [0.65064931]\n",
      "Step: 46100 Loss: 6.761796460795788\n",
      "Weight: [[0.47724354]\n",
      " [0.5463705 ]\n",
      " [0.98574213]]\n",
      "Bias: [0.65063417]\n",
      "Step: 46200 Loss: 6.757949972078299\n",
      "Weight: [[0.4769317 ]\n",
      " [0.54617161]\n",
      " [0.98623974]]\n",
      "Bias: [0.65061901]\n",
      "Step: 46300 Loss: 6.754132640064886\n",
      "Weight: [[0.47662067]\n",
      " [0.54597389]\n",
      " [0.9867354 ]]\n",
      "Bias: [0.65060383]\n",
      "Step: 46400 Loss: 6.750344230891826\n",
      "Weight: [[0.47631047]\n",
      " [0.54577735]\n",
      " [0.98722912]]\n",
      "Bias: [0.65058864]\n",
      "Step: 46500 Loss: 6.746584512644636\n",
      "Weight: [[0.47600107]\n",
      " [0.54558198]\n",
      " [0.98772091]]\n",
      "Bias: [0.65057344]\n",
      "Step: 46600 Loss: 6.742853255341567\n",
      "Weight: [[0.4756925 ]\n",
      " [0.54538777]\n",
      " [0.98821077]]\n",
      "Bias: [0.65055822]\n",
      "Step: 46700 Loss: 6.739150230917002\n",
      "Weight: [[0.47538473]\n",
      " [0.54519472]\n",
      " [0.98869871]]\n",
      "Bias: [0.65054299]\n",
      "Step: 46800 Loss: 6.735475213205092\n",
      "Weight: [[0.47507777]\n",
      " [0.54500282]\n",
      " [0.98918474]]\n",
      "Bias: [0.65052774]\n",
      "Step: 46900 Loss: 6.731827977923581\n",
      "Weight: [[0.47477161]\n",
      " [0.54481207]\n",
      " [0.98966887]]\n",
      "Bias: [0.65051248]\n",
      "Step: 47000 Loss: 6.728208302657648\n",
      "Weight: [[0.47446626]\n",
      " [0.54462246]\n",
      " [0.99015111]]\n",
      "Bias: [0.6504972]\n",
      "Step: 47100 Loss: 6.724615966844022\n",
      "Weight: [[0.47416171]\n",
      " [0.54443398]\n",
      " [0.99063145]]\n",
      "Bias: [0.65048191]\n",
      "Step: 47200 Loss: 6.721050751755241\n",
      "Weight: [[0.47385796]\n",
      " [0.54424663]\n",
      " [0.99110992]]\n",
      "Bias: [0.65046661]\n",
      "Step: 47300 Loss: 6.717512440483837\n",
      "Weight: [[0.47355501]\n",
      " [0.5440604 ]\n",
      " [0.99158651]]\n",
      "Bias: [0.65045129]\n",
      "Step: 47400 Loss: 6.714000817926816\n",
      "Weight: [[0.47325285]\n",
      " [0.54387529]\n",
      " [0.99206124]]\n",
      "Bias: [0.65043596]\n",
      "Step: 47500 Loss: 6.710515670770441\n",
      "Weight: [[0.47295149]\n",
      " [0.54369129]\n",
      " [0.99253412]]\n",
      "Bias: [0.65042061]\n",
      "Step: 47600 Loss: 6.707056787474772\n",
      "Weight: [[0.47265092]\n",
      " [0.5435084 ]\n",
      " [0.99300514]]\n",
      "Bias: [0.65040525]\n",
      "Step: 47700 Loss: 6.703623958258622\n",
      "Weight: [[0.47235113]\n",
      " [0.5433266 ]\n",
      " [0.99347432]]\n",
      "Bias: [0.65038987]\n",
      "Step: 47800 Loss: 6.70021697508462\n",
      "Weight: [[0.47205213]\n",
      " [0.54314591]\n",
      " [0.99394167]]\n",
      "Bias: [0.65037449]\n",
      "Step: 47900 Loss: 6.696835631644148\n",
      "Weight: [[0.47175392]\n",
      " [0.5429663 ]\n",
      " [0.9944072 ]]\n",
      "Bias: [0.65035908]\n",
      "Step: 48000 Loss: 6.693479723342744\n",
      "Weight: [[0.47145649]\n",
      " [0.54278777]\n",
      " [0.9948709 ]]\n",
      "Bias: [0.65034367]\n",
      "Step: 48100 Loss: 6.690149047285525\n",
      "Weight: [[0.47115984]\n",
      " [0.54261032]\n",
      " [0.99533279]]\n",
      "Bias: [0.65032824]\n",
      "Step: 48200 Loss: 6.6868434022626\n",
      "Weight: [[0.47086397]\n",
      " [0.54243394]\n",
      " [0.99579288]]\n",
      "Bias: [0.65031279]\n",
      "Step: 48300 Loss: 6.683562588734681\n",
      "Weight: [[0.47056887]\n",
      " [0.54225863]\n",
      " [0.99625118]]\n",
      "Bias: [0.65029733]\n",
      "Step: 48400 Loss: 6.680306408818998\n",
      "Weight: [[0.47027455]\n",
      " [0.54208439]\n",
      " [0.99670768]]\n",
      "Bias: [0.65028186]\n",
      "Step: 48500 Loss: 6.677074666275076\n",
      "Weight: [[0.46998099]\n",
      " [0.54191119]\n",
      " [0.9971624 ]]\n",
      "Bias: [0.65026638]\n",
      "Step: 48600 Loss: 6.673867166490677\n",
      "Weight: [[0.46968821]\n",
      " [0.54173905]\n",
      " [0.99761535]]\n",
      "Bias: [0.65025088]\n",
      "Step: 48700 Loss: 6.67068371646811\n",
      "Weight: [[0.4693962 ]\n",
      " [0.54156796]\n",
      " [0.99806653]]\n",
      "Bias: [0.65023537]\n",
      "Step: 48800 Loss: 6.667524124810349\n",
      "Weight: [[0.46910495]\n",
      " [0.5413979 ]\n",
      " [0.99851595]]\n",
      "Bias: [0.65021984]\n",
      "Step: 48900 Loss: 6.664388201707416\n",
      "Weight: [[0.46881446]\n",
      " [0.54122888]\n",
      " [0.99896362]]\n",
      "Bias: [0.6502043]\n",
      "Step: 49000 Loss: 6.661275758922884\n",
      "Weight: [[0.46852474]\n",
      " [0.54106088]\n",
      " [0.99940954]]\n",
      "Bias: [0.65018875]\n",
      "Step: 49100 Loss: 6.658186609780546\n",
      "Weight: [[0.46823578]\n",
      " [0.54089392]\n",
      " [0.99985372]]\n",
      "Bias: [0.65017319]\n",
      "Step: 49200 Loss: 6.655120569150958\n",
      "Weight: [[0.46794757]\n",
      " [0.54072797]\n",
      " [1.00029618]]\n",
      "Bias: [0.65015761]\n",
      "Step: 49300 Loss: 6.652077453438531\n",
      "Weight: [[0.46766012]\n",
      " [0.54056303]\n",
      " [1.0007369 ]]\n",
      "Bias: [0.65014202]\n",
      "Step: 49400 Loss: 6.649057080568192\n",
      "Weight: [[0.46737342]\n",
      " [0.5403991 ]\n",
      " [1.00117591]]\n",
      "Bias: [0.65012641]\n",
      "Step: 49500 Loss: 6.646059269972614\n",
      "Weight: [[0.46708747]\n",
      " [0.54023618]\n",
      " [1.00161322]]\n",
      "Bias: [0.65011079]\n",
      "Step: 49600 Loss: 6.643083842579404\n",
      "Weight: [[0.46680227]\n",
      " [0.54007425]\n",
      " [1.00204881]]\n",
      "Bias: [0.65009516]\n",
      "Step: 49700 Loss: 6.640130620798321\n",
      "Weight: [[0.46651782]\n",
      " [0.53991332]\n",
      " [1.00248271]]\n",
      "Bias: [0.65007952]\n",
      "Step: 49800 Loss: 6.637199428508738\n",
      "Weight: [[0.46623411]\n",
      " [0.53975337]\n",
      " [1.00291493]]\n",
      "Bias: [0.65006386]\n",
      "Step: 49900 Loss: 6.634290091046969\n",
      "Weight: [[0.46595115]\n",
      " [0.53959441]\n",
      " [1.00334546]]\n",
      "Bias: [0.65004819]\n",
      "Step: 50000 Loss: 6.631402435194096\n",
      "Weight: [[0.46566893]\n",
      " [0.53943642]\n",
      " [1.00377431]]\n",
      "Bias: [0.65003251]\n",
      "Step: 50100 Loss: 6.62853628916369\n",
      "Weight: [[0.46538744]\n",
      " [0.53927941]\n",
      " [1.00420149]]\n",
      "Bias: [0.65001682]\n",
      "Step: 50200 Loss: 6.625691482589323\n",
      "Weight: [[0.46510669]\n",
      " [0.53912337]\n",
      " [1.00462702]]\n",
      "Bias: [0.65000111]\n",
      "Step: 50300 Loss: 6.622867846512881\n",
      "Weight: [[0.46482668]\n",
      " [0.53896829]\n",
      " [1.00505089]]\n",
      "Bias: [0.64998539]\n",
      "Step: 50400 Loss: 6.620065213372417\n",
      "Weight: [[0.4645474 ]\n",
      " [0.53881416]\n",
      " [1.00547311]]\n",
      "Bias: [0.64996966]\n",
      "Step: 50500 Loss: 6.617283416990257\n",
      "Weight: [[0.46426886]\n",
      " [0.53866099]\n",
      " [1.00589369]]\n",
      "Bias: [0.64995391]\n",
      "Step: 50600 Loss: 6.614522292561245\n",
      "Weight: [[0.46399104]\n",
      " [0.53850877]\n",
      " [1.00631263]]\n",
      "Bias: [0.64993815]\n",
      "Step: 50700 Loss: 6.61178167664128\n",
      "Weight: [[0.46371395]\n",
      " [0.53835749]\n",
      " [1.00672995]]\n",
      "Bias: [0.64992238]\n",
      "Step: 50800 Loss: 6.609061407135483\n",
      "Weight: [[0.46343758]\n",
      " [0.53820715]\n",
      " [1.00714564]]\n",
      "Bias: [0.6499066]\n",
      "Step: 50900 Loss: 6.606361323286917\n",
      "Weight: [[0.46316194]\n",
      " [0.53805774]\n",
      " [1.00755972]]\n",
      "Bias: [0.6498908]\n",
      "Step: 51000 Loss: 6.603681265665103\n",
      "Weight: [[0.46288701]\n",
      " [0.53790926]\n",
      " [1.00797219]]\n",
      "Bias: [0.649875]\n",
      "Step: 51100 Loss: 6.601021076154891\n",
      "Weight: [[0.46261281]\n",
      " [0.53776171]\n",
      " [1.00838306]]\n",
      "Bias: [0.64985918]\n",
      "Step: 51200 Loss: 6.59838059794522\n",
      "Weight: [[0.46233933]\n",
      " [0.53761507]\n",
      " [1.00879233]]\n",
      "Bias: [0.64984335]\n",
      "Step: 51300 Loss: 6.5957596755180585\n",
      "Weight: [[0.46206656]\n",
      " [0.53746935]\n",
      " [1.00920002]]\n",
      "Bias: [0.6498275]\n",
      "Step: 51400 Loss: 6.593158154637409\n",
      "Weight: [[0.4617945 ]\n",
      " [0.53732454]\n",
      " [1.00960612]]\n",
      "Bias: [0.64981165]\n",
      "Step: 51500 Loss: 6.590575882338532\n",
      "Weight: [[0.46152315]\n",
      " [0.53718063]\n",
      " [1.01001065]]\n",
      "Bias: [0.64979578]\n",
      "Step: 51600 Loss: 6.588012706917023\n",
      "Weight: [[0.46125252]\n",
      " [0.53703762]\n",
      " [1.01041361]]\n",
      "Bias: [0.6497799]\n",
      "Step: 51700 Loss: 6.585468477918214\n",
      "Weight: [[0.46098259]\n",
      " [0.53689551]\n",
      " [1.010815  ]]\n",
      "Bias: [0.64976401]\n",
      "Step: 51800 Loss: 6.582943046126548\n",
      "Weight: [[0.46071337]\n",
      " [0.53675429]\n",
      " [1.01121484]]\n",
      "Bias: [0.6497481]\n",
      "Step: 51900 Loss: 6.580436263555088\n",
      "Weight: [[0.46044485]\n",
      " [0.53661396]\n",
      " [1.01161313]]\n",
      "Bias: [0.64973219]\n",
      "Step: 52000 Loss: 6.577947983435088\n",
      "Weight: [[0.46017703]\n",
      " [0.53647451]\n",
      " [1.01200987]]\n",
      "Bias: [0.64971626]\n",
      "Step: 52100 Loss: 6.575478060205636\n",
      "Weight: [[0.45990992]\n",
      " [0.53633593]\n",
      " [1.01240508]]\n",
      "Bias: [0.64970032]\n",
      "Step: 52200 Loss: 6.573026349503502\n",
      "Weight: [[0.4596435 ]\n",
      " [0.53619823]\n",
      " [1.01279876]]\n",
      "Bias: [0.64968437]\n",
      "Step: 52300 Loss: 6.570592708152925\n",
      "Weight: [[0.45937778]\n",
      " [0.5360614 ]\n",
      " [1.01319091]]\n",
      "Bias: [0.6496684]\n",
      "Step: 52400 Loss: 6.568176994155554\n",
      "Weight: [[0.45911275]\n",
      " [0.53592543]\n",
      " [1.01358154]]\n",
      "Bias: [0.64965243]\n",
      "Step: 52500 Loss: 6.565779066680535\n",
      "Weight: [[0.45884842]\n",
      " [0.53579032]\n",
      " [1.01397066]]\n",
      "Bias: [0.64963644]\n",
      "Step: 52600 Loss: 6.563398786054506\n",
      "Weight: [[0.45858477]\n",
      " [0.53565606]\n",
      " [1.01435827]]\n",
      "Bias: [0.64962045]\n",
      "Step: 52700 Loss: 6.561036013751818\n",
      "Weight: [[0.45832182]\n",
      " [0.53552266]\n",
      " [1.01474438]]\n",
      "Bias: [0.64960444]\n",
      "Step: 52800 Loss: 6.558690612385016\n",
      "Weight: [[0.45805955]\n",
      " [0.5353901 ]\n",
      " [1.015129  ]]\n",
      "Bias: [0.64958842]\n",
      "Step: 52900 Loss: 6.556362445694983\n",
      "Weight: [[0.45779797]\n",
      " [0.53525838]\n",
      " [1.01551213]]\n",
      "Bias: [0.64957238]\n",
      "Step: 53000 Loss: 6.5540513785414145\n",
      "Weight: [[0.45753707]\n",
      " [0.5351275 ]\n",
      " [1.01589378]]\n",
      "Bias: [0.64955634]\n",
      "Step: 53100 Loss: 6.551757276893479\n",
      "Weight: [[0.45727685]\n",
      " [0.53499746]\n",
      " [1.01627395]]\n",
      "Bias: [0.64954029]\n",
      "Step: 53200 Loss: 6.549480007820259\n",
      "Weight: [[0.45701731]\n",
      " [0.53486824]\n",
      " [1.01665265]]\n",
      "Bias: [0.64952422]\n",
      "Step: 53300 Loss: 6.547219439481531\n",
      "Weight: [[0.45675845]\n",
      " [0.53473984]\n",
      " [1.01702989]]\n",
      "Bias: [0.64950814]\n",
      "Step: 53400 Loss: 6.54497544111868\n",
      "Weight: [[0.45650026]\n",
      " [0.53461227]\n",
      " [1.01740567]]\n",
      "Bias: [0.64949205]\n",
      "Step: 53500 Loss: 6.542747883045222\n",
      "Weight: [[0.45624275]\n",
      " [0.53448551]\n",
      " [1.01778   ]]\n",
      "Bias: [0.64947595]\n",
      "Step: 53600 Loss: 6.540536636638061\n",
      "Weight: [[0.45598591]\n",
      " [0.53435957]\n",
      " [1.01815288]]\n",
      "Bias: [0.64945984]\n",
      "Step: 53700 Loss: 6.538341574328357\n",
      "Weight: [[0.45572975]\n",
      " [0.53423443]\n",
      " [1.01852432]]\n",
      "Bias: [0.64944372]\n",
      "Step: 53800 Loss: 6.536162569592502\n",
      "Weight: [[0.45547425]\n",
      " [0.53411009]\n",
      " [1.01889433]]\n",
      "Bias: [0.64942759]\n",
      "Step: 53900 Loss: 6.533999496943583\n",
      "Weight: [[0.45521942]\n",
      " [0.53398655]\n",
      " [1.0192629 ]]\n",
      "Bias: [0.64941144]\n",
      "Step: 54000 Loss: 6.531852231922309\n",
      "Weight: [[0.45496525]\n",
      " [0.53386381]\n",
      " [1.01963006]]\n",
      "Bias: [0.64939529]\n",
      "Step: 54100 Loss: 6.529720651088562\n",
      "Weight: [[0.45471174]\n",
      " [0.53374186]\n",
      " [1.0199958 ]]\n",
      "Bias: [0.64937912]\n",
      "Step: 54200 Loss: 6.527604632012639\n",
      "Weight: [[0.4544589 ]\n",
      " [0.53362069]\n",
      " [1.02036012]]\n",
      "Bias: [0.64936295]\n",
      "Step: 54300 Loss: 6.525504053266753\n",
      "Weight: [[0.45420672]\n",
      " [0.53350031]\n",
      " [1.02072304]]\n",
      "Bias: [0.64934676]\n",
      "Step: 54400 Loss: 6.523418794416675\n",
      "Weight: [[0.45395519]\n",
      " [0.5333807 ]\n",
      " [1.02108456]]\n",
      "Bias: [0.64933056]\n",
      "Step: 54500 Loss: 6.5213487360131515\n",
      "Weight: [[0.45370433]\n",
      " [0.53326187]\n",
      " [1.02144469]]\n",
      "Bias: [0.64931435]\n",
      "Step: 54600 Loss: 6.519293759583826\n",
      "Weight: [[0.45345411]\n",
      " [0.53314381]\n",
      " [1.02180343]]\n",
      "Bias: [0.64929813]\n",
      "Step: 54700 Loss: 6.5172537476247046\n",
      "Weight: [[0.45320455]\n",
      " [0.53302652]\n",
      " [1.02216078]]\n",
      "Bias: [0.6492819]\n",
      "Step: 54800 Loss: 6.515228583592279\n",
      "Weight: [[0.45295564]\n",
      " [0.53290999]\n",
      " [1.02251676]]\n",
      "Bias: [0.64926566]\n",
      "Step: 54900 Loss: 6.51321815189523\n",
      "Weight: [[0.45270738]\n",
      " [0.53279421]\n",
      " [1.02287137]]\n",
      "Bias: [0.64924941]\n",
      "Step: 55000 Loss: 6.511222337886468\n",
      "Weight: [[0.45245977]\n",
      " [0.53267919]\n",
      " [1.02322461]]\n",
      "Bias: [0.64923315]\n",
      "Step: 55100 Loss: 6.5092410278551736\n",
      "Weight: [[0.4522128 ]\n",
      " [0.53256492]\n",
      " [1.02357649]]\n",
      "Bias: [0.64921687]\n",
      "Step: 55200 Loss: 6.507274109018841\n",
      "Weight: [[0.45196647]\n",
      " [0.5324514 ]\n",
      " [1.02392701]]\n",
      "Bias: [0.64920059]\n",
      "Step: 55300 Loss: 6.505321469515527\n",
      "Weight: [[0.45172079]\n",
      " [0.53233862]\n",
      " [1.02427618]]\n",
      "Bias: [0.6491843]\n",
      "Step: 55400 Loss: 6.503382998395994\n",
      "Weight: [[0.45147575]\n",
      " [0.53222658]\n",
      " [1.02462401]]\n",
      "Bias: [0.64916799]\n",
      "Step: 55500 Loss: 6.501458585616178\n",
      "Weight: [[0.45123135]\n",
      " [0.53211527]\n",
      " [1.02497051]]\n",
      "Bias: [0.64915168]\n",
      "Step: 55600 Loss: 6.499548122029365\n",
      "Weight: [[0.45098758]\n",
      " [0.53200469]\n",
      " [1.02531566]]\n",
      "Bias: [0.64913536]\n",
      "Step: 55700 Loss: 6.497651499378832\n",
      "Weight: [[0.45074445]\n",
      " [0.53189484]\n",
      " [1.0256595 ]]\n",
      "Bias: [0.64911902]\n",
      "Step: 55800 Loss: 6.49576861029014\n",
      "Weight: [[0.45050196]\n",
      " [0.53178572]\n",
      " [1.026002  ]]\n",
      "Bias: [0.64910268]\n",
      "Step: 55900 Loss: 6.493899348263839\n",
      "Weight: [[0.45026009]\n",
      " [0.53167731]\n",
      " [1.02634319]]\n",
      "Bias: [0.64908632]\n",
      "Step: 56000 Loss: 6.492043607668056\n",
      "Weight: [[0.45001886]\n",
      " [0.53156962]\n",
      " [1.02668307]]\n",
      "Bias: [0.64906996]\n",
      "Step: 56100 Loss: 6.490201283731287\n",
      "Weight: [[0.44977825]\n",
      " [0.53146264]\n",
      " [1.02702165]]\n",
      "Bias: [0.64905358]\n",
      "Step: 56200 Loss: 6.488372272534935\n",
      "Weight: [[0.44953827]\n",
      " [0.53135637]\n",
      " [1.02735892]]\n",
      "Bias: [0.6490372]\n",
      "Step: 56300 Loss: 6.486556471006361\n",
      "Weight: [[0.44929892]\n",
      " [0.5312508 ]\n",
      " [1.0276949 ]]\n",
      "Bias: [0.6490208]\n",
      "Step: 56400 Loss: 6.484753776911606\n",
      "Weight: [[0.44906019]\n",
      " [0.53114594]\n",
      " [1.02802958]]\n",
      "Bias: [0.6490044]\n",
      "Step: 56500 Loss: 6.482964088848458\n",
      "Weight: [[0.44882208]\n",
      " [0.53104177]\n",
      " [1.02836298]]\n",
      "Bias: [0.64898798]\n",
      "Step: 56600 Loss: 6.481187306239268\n",
      "Weight: [[0.4485846 ]\n",
      " [0.53093829]\n",
      " [1.0286951 ]]\n",
      "Bias: [0.64897155]\n",
      "Step: 56700 Loss: 6.479423329324334\n",
      "Weight: [[0.44834773]\n",
      " [0.5308355 ]\n",
      " [1.02902595]]\n",
      "Bias: [0.64895512]\n",
      "Step: 56800 Loss: 6.477672059154678\n",
      "Weight: [[0.44811147]\n",
      " [0.5307334 ]\n",
      " [1.02935552]]\n",
      "Bias: [0.64893867]\n",
      "Step: 56900 Loss: 6.475933397585443\n",
      "Weight: [[0.44787584]\n",
      " [0.53063199]\n",
      " [1.02968383]]\n",
      "Bias: [0.64892222]\n",
      "Step: 57000 Loss: 6.474207247269\n",
      "Weight: [[0.44764081]\n",
      " [0.53053125]\n",
      " [1.03001088]]\n",
      "Bias: [0.64890576]\n",
      "Step: 57100 Loss: 6.47249351164839\n",
      "Weight: [[0.4474064 ]\n",
      " [0.53043118]\n",
      " [1.03033668]]\n",
      "Bias: [0.64888928]\n",
      "Step: 57200 Loss: 6.470792094950613\n",
      "Weight: [[0.4471726 ]\n",
      " [0.53033179]\n",
      " [1.03066123]]\n",
      "Bias: [0.6488728]\n",
      "Step: 57300 Loss: 6.469102902179995\n",
      "Weight: [[0.44693941]\n",
      " [0.53023307]\n",
      " [1.03098453]]\n",
      "Bias: [0.6488563]\n",
      "Step: 57400 Loss: 6.467425839111615\n",
      "Weight: [[0.44670682]\n",
      " [0.53013501]\n",
      " [1.03130659]]\n",
      "Bias: [0.6488398]\n",
      "Step: 57500 Loss: 6.465760812285176\n",
      "Weight: [[0.44647484]\n",
      " [0.53003761]\n",
      " [1.03162742]]\n",
      "Bias: [0.64882329]\n",
      "Step: 57600 Loss: 6.464107728998042\n",
      "Weight: [[0.44624346]\n",
      " [0.52994087]\n",
      " [1.03194702]]\n",
      "Bias: [0.64880677]\n",
      "Step: 57700 Loss: 6.462466497299297\n",
      "Weight: [[0.44601269]\n",
      " [0.52984478]\n",
      " [1.0322654 ]]\n",
      "Bias: [0.64879023]\n",
      "Step: 57800 Loss: 6.460837025983303\n",
      "Weight: [[0.44578252]\n",
      " [0.52974935]\n",
      " [1.03258256]]\n",
      "Bias: [0.64877369]\n",
      "Step: 57900 Loss: 6.459219224583353\n",
      "Weight: [[0.44555294]\n",
      " [0.52965456]\n",
      " [1.0328985 ]]\n",
      "Bias: [0.64875714]\n",
      "Step: 58000 Loss: 6.457613003365672\n",
      "Weight: [[0.44532396]\n",
      " [0.52956041]\n",
      " [1.03321323]]\n",
      "Bias: [0.64874058]\n",
      "Step: 58100 Loss: 6.456018273323076\n",
      "Weight: [[0.44509558]\n",
      " [0.52946691]\n",
      " [1.03352676]]\n",
      "Bias: [0.64872401]\n",
      "Step: 58200 Loss: 6.454434946168959\n",
      "Weight: [[0.44486779]\n",
      " [0.52937404]\n",
      " [1.03383909]]\n",
      "Bias: [0.64870744]\n",
      "Step: 58300 Loss: 6.452862934331249\n",
      "Weight: [[0.4446406 ]\n",
      " [0.52928181]\n",
      " [1.03415022]]\n",
      "Bias: [0.64869085]\n",
      "Step: 58400 Loss: 6.451302150946509\n",
      "Weight: [[0.44441399]\n",
      " [0.52919021]\n",
      " [1.03446016]]\n",
      "Bias: [0.64867425]\n",
      "Step: 58500 Loss: 6.449752509853698\n",
      "Weight: [[0.44418798]\n",
      " [0.52909923]\n",
      " [1.03476892]]\n",
      "Bias: [0.64865764]\n",
      "Step: 58600 Loss: 6.4482139255886795\n",
      "Weight: [[0.44396255]\n",
      " [0.52900888]\n",
      " [1.0350765 ]]\n",
      "Bias: [0.64864103]\n",
      "Step: 58700 Loss: 6.446686313378143\n",
      "Weight: [[0.44373771]\n",
      " [0.52891914]\n",
      " [1.0353829 ]]\n",
      "Bias: [0.6486244]\n",
      "Step: 58800 Loss: 6.445169589133762\n",
      "Weight: [[0.44351346]\n",
      " [0.52883003]\n",
      " [1.03568813]]\n",
      "Bias: [0.64860777]\n",
      "Step: 58900 Loss: 6.443663669446752\n",
      "Weight: [[0.44328978]\n",
      " [0.52874152]\n",
      " [1.0359922 ]]\n",
      "Bias: [0.64859113]\n",
      "Step: 59000 Loss: 6.442168471581754\n",
      "Weight: [[0.44306669]\n",
      " [0.52865363]\n",
      " [1.0362951 ]]\n",
      "Bias: [0.64857448]\n",
      "Step: 59100 Loss: 6.440683913471571\n",
      "Weight: [[0.44284418]\n",
      " [0.52856635]\n",
      " [1.03659684]]\n",
      "Bias: [0.64855782]\n",
      "Step: 59200 Loss: 6.4392099137114345\n",
      "Weight: [[0.44262225]\n",
      " [0.52847967]\n",
      " [1.03689744]]\n",
      "Bias: [0.64854115]\n",
      "Step: 59300 Loss: 6.437746391553417\n",
      "Weight: [[0.44240089]\n",
      " [0.52839359]\n",
      " [1.03719689]]\n",
      "Bias: [0.64852447]\n",
      "Step: 59400 Loss: 6.436293266900931\n",
      "Weight: [[0.44218011]\n",
      " [0.5283081 ]\n",
      " [1.03749519]]\n",
      "Bias: [0.64850778]\n",
      "Step: 59500 Loss: 6.434850460303433\n",
      "Weight: [[0.4419599 ]\n",
      " [0.52822322]\n",
      " [1.03779235]]\n",
      "Bias: [0.64849108]\n",
      "Step: 59600 Loss: 6.4334178929508425\n",
      "Weight: [[0.44174027]\n",
      " [0.52813892]\n",
      " [1.03808838]]\n",
      "Bias: [0.64847438]\n",
      "Step: 59700 Loss: 6.431995486668223\n",
      "Weight: [[0.4415212 ]\n",
      " [0.52805521]\n",
      " [1.03838329]]\n",
      "Bias: [0.64845766]\n",
      "Step: 59800 Loss: 6.430583163910529\n",
      "Weight: [[0.44130271]\n",
      " [0.52797208]\n",
      " [1.03867706]]\n",
      "Bias: [0.64844094]\n",
      "Step: 59900 Loss: 6.429180847757382\n",
      "Weight: [[0.44108478]\n",
      " [0.52788954]\n",
      " [1.03896972]]\n",
      "Bias: [0.64842421]\n",
      "Step: 60000 Loss: 6.427788461907671\n",
      "Weight: [[0.44086742]\n",
      " [0.52780758]\n",
      " [1.03926126]]\n",
      "Bias: [0.64840747]\n",
      "Step: 60100 Loss: 6.426405930674527\n",
      "Weight: [[0.44065062]\n",
      " [0.52772619]\n",
      " [1.0395517 ]]\n",
      "Bias: [0.64839072]\n",
      "Step: 60200 Loss: 6.425033178980212\n",
      "Weight: [[0.44043439]\n",
      " [0.52764537]\n",
      " [1.03984102]]\n",
      "Bias: [0.64837396]\n",
      "Step: 60300 Loss: 6.423670132350789\n",
      "Weight: [[0.44021872]\n",
      " [0.52756513]\n",
      " [1.04012924]]\n",
      "Bias: [0.6483572]\n",
      "Step: 60400 Loss: 6.422316716911495\n",
      "Weight: [[0.44000361]\n",
      " [0.52748545]\n",
      " [1.04041637]]\n",
      "Bias: [0.64834042]\n",
      "Step: 60500 Loss: 6.420972859381368\n",
      "Weight: [[0.43978905]\n",
      " [0.52740633]\n",
      " [1.0407024 ]]\n",
      "Bias: [0.64832364]\n",
      "Step: 60600 Loss: 6.419638487068381\n",
      "Weight: [[0.43957506]\n",
      " [0.52732777]\n",
      " [1.04098734]]\n",
      "Bias: [0.64830685]\n",
      "Step: 60700 Loss: 6.418313527864724\n",
      "Weight: [[0.43936162]\n",
      " [0.52724977]\n",
      " [1.0412712 ]]\n",
      "Bias: [0.64829005]\n",
      "Step: 60800 Loss: 6.416997910241592\n",
      "Weight: [[0.43914873]\n",
      " [0.52717233]\n",
      " [1.04155398]]\n",
      "Bias: [0.64827324]\n",
      "Step: 60900 Loss: 6.415691563244661\n",
      "Weight: [[0.4389364 ]\n",
      " [0.52709543]\n",
      " [1.04183568]]\n",
      "Bias: [0.64825642]\n",
      "Step: 61000 Loss: 6.414394416489177\n",
      "Weight: [[0.43872462]\n",
      " [0.52701909]\n",
      " [1.04211631]]\n",
      "Bias: [0.6482396]\n",
      "Step: 61100 Loss: 6.4131064001551215\n",
      "Weight: [[0.43851339]\n",
      " [0.52694328]\n",
      " [1.04239587]]\n",
      "Bias: [0.64822276]\n",
      "Step: 61200 Loss: 6.411827444982602\n",
      "Weight: [[0.4383027 ]\n",
      " [0.52686803]\n",
      " [1.04267437]]\n",
      "Bias: [0.64820592]\n",
      "Step: 61300 Loss: 6.410557482267225\n",
      "Weight: [[0.43809257]\n",
      " [0.52679331]\n",
      " [1.04295181]]\n",
      "Bias: [0.64818907]\n",
      "Step: 61400 Loss: 6.4092964438553475\n",
      "Weight: [[0.43788298]\n",
      " [0.52671913]\n",
      " [1.0432282 ]]\n",
      "Bias: [0.64817221]\n",
      "Step: 61500 Loss: 6.408044262139522\n",
      "Weight: [[0.43767393]\n",
      " [0.52664548]\n",
      " [1.04350354]]\n",
      "Bias: [0.64815534]\n",
      "Step: 61600 Loss: 6.406800870054078\n",
      "Weight: [[0.43746542]\n",
      " [0.52657236]\n",
      " [1.04377783]]\n",
      "Bias: [0.64813847]\n",
      "Step: 61700 Loss: 6.405566201070421\n",
      "Weight: [[0.43725746]\n",
      " [0.52649977]\n",
      " [1.04405108]]\n",
      "Bias: [0.64812159]\n",
      "Step: 61800 Loss: 6.4043401891925695\n",
      "Weight: [[0.43705003]\n",
      " [0.52642771]\n",
      " [1.04432329]]\n",
      "Bias: [0.6481047]\n",
      "Step: 61900 Loss: 6.403122768952908\n",
      "Weight: [[0.43684315]\n",
      " [0.52635616]\n",
      " [1.04459447]]\n",
      "Bias: [0.6480878]\n",
      "Step: 62000 Loss: 6.401913875407636\n",
      "Weight: [[0.4366368 ]\n",
      " [0.52628514]\n",
      " [1.04486462]]\n",
      "Bias: [0.64807089]\n",
      "Step: 62100 Loss: 6.40071344413248\n",
      "Weight: [[0.43643099]\n",
      " [0.52621463]\n",
      " [1.04513375]]\n",
      "Bias: [0.64805397]\n",
      "Step: 62200 Loss: 6.3995214112182115\n",
      "Weight: [[0.4362257 ]\n",
      " [0.52614464]\n",
      " [1.04540185]]\n",
      "Bias: [0.64803705]\n",
      "Step: 62300 Loss: 6.398337713266647\n",
      "Weight: [[0.43602096]\n",
      " [0.52607516]\n",
      " [1.04566894]]\n",
      "Bias: [0.64802012]\n",
      "Step: 62400 Loss: 6.397162287386119\n",
      "Weight: [[0.43581674]\n",
      " [0.52600619]\n",
      " [1.04593502]]\n",
      "Bias: [0.64800318]\n",
      "Step: 62500 Loss: 6.395995071187382\n",
      "Weight: [[0.43561305]\n",
      " [0.52593772]\n",
      " [1.04620008]]\n",
      "Bias: [0.64798623]\n",
      "Step: 62600 Loss: 6.394836002779559\n",
      "Weight: [[0.43540989]\n",
      " [0.52586976]\n",
      " [1.04646414]]\n",
      "Bias: [0.64796928]\n",
      "Step: 62700 Loss: 6.393685020765751\n",
      "Weight: [[0.43520726]\n",
      " [0.52580229]\n",
      " [1.04672721]]\n",
      "Bias: [0.64795232]\n",
      "Step: 62800 Loss: 6.392542064239132\n",
      "Weight: [[0.43500516]\n",
      " [0.52573532]\n",
      " [1.04698927]]\n",
      "Bias: [0.64793534]\n",
      "Step: 62900 Loss: 6.391407072778714\n",
      "Weight: [[0.43480357]\n",
      " [0.52566885]\n",
      " [1.04725034]]\n",
      "Bias: [0.64791837]\n",
      "Step: 63000 Loss: 6.390279986445523\n",
      "Weight: [[0.43460251]\n",
      " [0.52560287]\n",
      " [1.04751043]]\n",
      "Bias: [0.64790138]\n",
      "Step: 63100 Loss: 6.389160745778403\n",
      "Weight: [[0.43440197]\n",
      " [0.52553738]\n",
      " [1.04776952]]\n",
      "Bias: [0.64788439]\n",
      "Step: 63200 Loss: 6.388049291790107\n",
      "Weight: [[0.43420195]\n",
      " [0.52547238]\n",
      " [1.04802764]]\n",
      "Bias: [0.64786738]\n",
      "Step: 63300 Loss: 6.386945565963422\n",
      "Weight: [[0.43400245]\n",
      " [0.52540786]\n",
      " [1.04828478]]\n",
      "Bias: [0.64785038]\n",
      "Step: 63400 Loss: 6.385849510247205\n",
      "Weight: [[0.43380347]\n",
      " [0.52534382]\n",
      " [1.04854095]]\n",
      "Bias: [0.64783336]\n",
      "Step: 63500 Loss: 6.384761067052524\n",
      "Weight: [[0.433605  ]\n",
      " [0.52528026]\n",
      " [1.04879615]]\n",
      "Bias: [0.64781633]\n",
      "Step: 63600 Loss: 6.3836801792488815\n",
      "Weight: [[0.43340705]\n",
      " [0.52521717]\n",
      " [1.04905039]]\n",
      "Bias: [0.6477993]\n",
      "Step: 63700 Loss: 6.382606790160265\n",
      "Weight: [[0.43320961]\n",
      " [0.52515456]\n",
      " [1.04930366]]\n",
      "Bias: [0.64778226]\n",
      "Step: 63800 Loss: 6.381540843561606\n",
      "Weight: [[0.43301268]\n",
      " [0.52509242]\n",
      " [1.04955598]]\n",
      "Bias: [0.64776522]\n",
      "Step: 63900 Loss: 6.380482283674818\n",
      "Weight: [[0.43281626]\n",
      " [0.52503075]\n",
      " [1.04980734]]\n",
      "Bias: [0.64774816]\n",
      "Step: 64000 Loss: 6.379431055165257\n",
      "Weight: [[0.43262035]\n",
      " [0.52496954]\n",
      " [1.05005775]]\n",
      "Bias: [0.6477311]\n",
      "Step: 64100 Loss: 6.378387103137946\n",
      "Weight: [[0.43242495]\n",
      " [0.5249088 ]\n",
      " [1.05030722]]\n",
      "Bias: [0.64771403]\n",
      "Step: 64200 Loss: 6.377350373133989\n",
      "Weight: [[0.43223005]\n",
      " [0.52484852]\n",
      " [1.05055574]]\n",
      "Bias: [0.64769695]\n",
      "Step: 64300 Loss: 6.376320811126878\n",
      "Weight: [[0.43203566]\n",
      " [0.5247887 ]\n",
      " [1.05080333]]\n",
      "Bias: [0.64767987]\n",
      "Step: 64400 Loss: 6.375298363519051\n",
      "Weight: [[0.43184177]\n",
      " [0.52472933]\n",
      " [1.05104998]]\n",
      "Bias: [0.64766278]\n",
      "Step: 64500 Loss: 6.374282977138257\n",
      "Weight: [[0.43164839]\n",
      " [0.52467042]\n",
      " [1.0512957 ]]\n",
      "Bias: [0.64764568]\n",
      "Step: 64600 Loss: 6.373274599233947\n",
      "Weight: [[0.4314555 ]\n",
      " [0.52461195]\n",
      " [1.0515405 ]]\n",
      "Bias: [0.64762857]\n"
     ]
    }
   ],
   "source": [
    "w = np.random.rand(3, 1)\n",
    "b = np.random.rand(1)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "cost_list = []\n",
    "\n",
    "f = lambda x: loss_func(x_data, t_data)\n",
    "print(\"Initial Loss:\", loss_func(x_data, t_data), \"Weight:\", w, \"Bias:\", b)\n",
    "\n",
    "# Gradient Descent\n",
    "step = 0\n",
    "while True:\n",
    "    step += 1\n",
    "    w -= learning_rate * numerical_derivative(f, w)\n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "    cost = loss_func(x_data, t_data)\n",
    "    cost_list.append([step, cost])\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(\"Step:\", step, \"Loss:\", cost)\n",
    "        print(\"Weight:\", w)\n",
    "        print(\"Bias:\", b)\n",
    "\n",
    "    if step > 2 and cost_list[-2][1] - cost_list[-1][1] < 0.00001: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75dc921d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Epoch')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(cost_list)[:, 0], np.array(cost_list)[:, 1])\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Epoch')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
