{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7f9c48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3aba48d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d79f6859",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]], dtype=np.float32) \n",
    "y_data = np.array([[3], [5], [7], [9], [11]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2be1f9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(tf.Module):\n",
    "    def __init__(self):\n",
    "        self.W = tf.Variable(tf.random.normal([2, 1]), name='weight')   # tf 변수 이름을 weight로 짓겠다는 거임. 아래도 마찬가지 \n",
    "        self.b = tf.Variable(tf.random.normal([1]), name='bias')\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return tf.matmul(x, self.W) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2505abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, x, y):\n",
    "    y_pred = model(x)\n",
    "    return tf.reduce_mean(tf.square(y_pred - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5285bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:0, Loss:0.8794978260993958, W: [0.5485629 0.7905137], b: [2.1295009]\n",
      "Step:1000, Loss:0.666898787021637, W: [0.6330525  0.82759356], b: [2.0820837]\n",
      "Step:2000, Loss:0.6152917146682739, W: [0.6724768 0.8097006], b: [2.024768]\n",
      "Step:3000, Loss:0.5676774978637695, W: [0.71023816 0.7923793 ], b: [1.9696813]\n",
      "Step:4000, Loss:0.5237485766410828, W: [0.74650896 0.7757403 ], b: [1.9167703]\n",
      "Step:5000, Loss:0.48321977257728577, W: [0.7813476  0.75975883], b: [1.8659478]\n",
      "Step:6000, Loss:0.44582653045654297, W: [0.8148112 0.7444078], b: [1.8171312]\n",
      "Step:7000, Loss:0.41132673621177673, W: [0.8469543 0.7296627], b: [1.770241]\n",
      "Step:8000, Loss:0.3794974684715271, W: [0.8778281  0.71550035], b: [1.7252027]\n",
      "Step:9000, Loss:0.3501308560371399, W: [0.90748346 0.70189625], b: [1.6819414]\n",
      "Step:10000, Loss:0.3230368494987488, W: [0.93596786 0.68882996], b: [1.6403873]\n",
      "Step:11000, Loss:0.2980394959449768, W: [0.963328  0.6762787], b: [1.6004744]\n",
      "Step:12000, Loss:0.2749764919281006, W: [0.9896082  0.66422355], b: [1.5621363]\n",
      "Step:13000, Loss:0.2536984086036682, W: [1.0148504  0.65264475], b: [1.5253112]\n",
      "Step:14000, Loss:0.23406729102134705, W: [1.0390947 0.6415238], b: [1.4899398]\n",
      "Step:15000, Loss:0.21595481038093567, W: [1.062384  0.6308404], b: [1.4559642]\n",
      "Step:16000, Loss:0.199244886636734, W: [1.0847504 0.6205809], b: [1.4233297]\n",
      "Step:17000, Loss:0.18382702767848969, W: [1.1062379 0.6107253], b: [1.3919835]\n",
      "Step:18000, Loss:0.16960251331329346, W: [1.1268744  0.60125864], b: [1.3618735]\n",
      "Step:19000, Loss:0.1564791202545166, W: [1.1466962 0.5921658], b: [1.3329538]\n",
      "Step:20000, Loss:0.1443706601858139, W: [1.1657381 0.5834322], b: [1.3051741]\n",
      "Step:21000, Loss:0.1331998109817505, W: [1.184025  0.5750453], b: [1.2784914]\n",
      "Step:22000, Loss:0.12289305031299591, W: [1.2015922 0.5669859], b: [1.252862]\n",
      "Step:23000, Loss:0.11338397115468979, W: [1.2184637 0.5592489], b: [1.2282432]\n",
      "Step:24000, Loss:0.10461103916168213, W: [1.2346693 0.5518151], b: [1.2045966]\n",
      "Step:25000, Loss:0.09651664644479752, W: [1.2502357 0.544675 ], b: [1.181884]\n",
      "Step:26000, Loss:0.0890490934252739, W: [1.2651856  0.53781915], b: [1.1600667]\n",
      "Step:27000, Loss:0.08215869218111038, W: [1.279549  0.5312304], b: [1.1391115]\n",
      "Step:28000, Loss:0.07580159604549408, W: [1.2933431 0.5249063], b: [1.118981]\n",
      "Step:29000, Loss:0.06993715465068817, W: [1.3065912 0.5188286], b: [1.0996487]\n",
      "Step:30000, Loss:0.06452560424804688, W: [1.3193206 0.5129918], b: [1.0810769]\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegressionModel()\n",
    "optimizer = tf.optimizers.SGD(learning_rate=0.0001)\n",
    "\n",
    "for epoch in range(5001):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fn(model, x_data, y_data)\n",
    "        gradients = tape.gradient(loss, [model.W, model.b])\n",
    "        optimizer.apply_gradients(zip(gradients, [model.W, model.b]))\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Step:{epoch}, Loss:{loss.numpy()}, W: {model.W.numpy().flatten()}, b: {model.b.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc6f365c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.587942 14.420255 16.252567]\n"
     ]
    }
   ],
   "source": [
    "pred = model(np.array([[6, 7], [7, 8], [8, 9]], dtype=np.float32))\n",
    "print(pred.numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4022197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/data-01-test-score.csv', header=None)\n",
    "\n",
    "x_frame = df.values[:, :-1].astype('float32')\n",
    "y_frame = df.values[:, -1].reshape(-1, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11011786",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(tf.Module):\n",
    "    def __init__(self):\n",
    "        self.W = tf.Variable(tf.random.normal([3, 1]), name='weight')\n",
    "        self.b = tf.Variable(tf.random.normal([1]), name='bias')\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return tf.matmul(x, self.W) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b396fdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LinearRegressionModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegressionModel()\n\u001b[0;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.00001\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5001\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LinearRegressionModel' is not defined"
     ]
    }
   ],
   "source": [
    "model = LinearRegressionModel()\n",
    "optimizer = tf.optimizers.SGD(learning_rate=0.00001)\n",
    "\n",
    "for epoch in range(5001):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fn(model, x_frame, y_frame)\n",
    "        gradients = tape.gradient(loss, [model.W, model.b])\n",
    "        optimizer.apply_gradients(zip(gradients, [model.W, model.b]))\n",
    "        \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Step:{epoch}, Loss:{loss.numpy()}, W: {model.W.numpy().flatten()}, b: {model.b.numpy()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
